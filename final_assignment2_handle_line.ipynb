{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_assignment2_handle_line.ipynb","provenance":[{"file_id":"1zRMEFgwX7INg5xA7sC1YfRSufWauHsRS","timestamp":1597839901472}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DOIolhBd6TCw","colab_type":"text"},"source":["# PPOとSACを実装し，学習させてみよう！\n","\n","\n"," この演習では，**Proximal Policy Optimization(PPO)**[[1]](#scrollTo=HOq7n-OJboPr)と**Soft Actor-Critic(SAC)**[[2,3]](#scrollTo=HOq7n-OJboPr)を実装し，`InvertedPendulumBulletEnv-v0` と `HalfCheetahBulletEnv-v0` の2つの環境で学習させていきます．\n","\n","0. [準備](#scrollTo=TZIymOlD4K7n)\n","1. [タスクの概要](#scrollTo=c4eanX0pKgcr)\n","2. [予備知識](#scrollTo=_7awwWKC4UXj)\n","3. [Proximal Policy Optimization(PPO)の実装](#scrollTo=e6tuB-Ed4ULy)\n","4. [Soft Actor-Critic(SAC)の実装](#scrollTo=o5ODWC9LMx2Q)\n","5. [参考文献](#scrollTo=HOq7n-OJboPr)\n"]},{"cell_type":"markdown","metadata":{"id":"TZIymOlD4K7n","colab_type":"text"},"source":["## 0.準備\n","\n","演習を行うために必要な準備をしていきましょう．"]},{"cell_type":"code","metadata":{"id":"QYk7QQzJwLSA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600070524350,"user_tz":-540,"elapsed":24553,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"8b5b1a40-2028-4a0b-b4f4-3f2758d0b2e6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SH5JCHGfPHDC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070527888,"user_tz":-540,"elapsed":28071,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["# 必要なライブラリのインポート．\n","from abc import ABC, abstractmethod #抽象基底クラス\n","import os\n","import glob\n","from collections import deque\n","from time import time\n","from datetime import timedelta\n","import pickle\n","from base64 import b64encode\n","import math\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.distributions import Normal\n","import torch.nn.functional as F\n","import gym\n","import matplotlib.pyplot as plt\n","#from IPython.display import HTML\n","\n","#from gym import wrappers\n","\n","# Gymの警告を一部無視する．\n","gym.logger.set_level(40)\n","# matplotlibをColab上で描画するためのコマンド．\n","#%matplotlib inline                  #メモリーの節約に役立つ?"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Uzb7R2c24ZfC","colab_type":"text"},"source":["この課題では，[PyBullet](https://github.com/bulletphysics/bullet3)を用いて物理シミュレーションを行います．PyBulletは `pip` を用いてインストールしましょう．"]},{"cell_type":"code","metadata":{"id":"vrB7DGnRfEbx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1600070544934,"user_tz":-540,"elapsed":45100,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"66d12f80-ddea-4cca-a568-9f2935c39b4d"},"source":["# pipを用いてPyBulletをインストール．\n","!pip install pybullet\n","import pybullet_envs"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pybullet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/6b/b3d2ca6bf856874f0bad2336ab6a524ad7fee8c954875bee0c9144a530ef/pybullet-3.0.1-cp36-cp36m-manylinux1_x86_64.whl (102.0MB)\n","\u001b[K     |████████████████████████████████| 102.0MB 28kB/s \n","\u001b[?25hInstalling collected packages: pybullet\n","Successfully installed pybullet-3.0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AOzZ7OMh6D3F","colab_type":"text"},"source":["ランタイムをGPUに変更していますか？GPUを利用できているか，きちんと確認しましょう．"]},{"cell_type":"markdown","metadata":{"id":"c4eanX0pKgcr","colab_type":"text"},"source":["## 1.タスクの概要\n","\n","この演習で利用するタスク `InvertedPendulumBulletEnv-v0` と `HalfCheetahBulletEnv-v0` の環境を可視化してみましょう！\n","\n","1ステップごとにレンダリングを行い，リアルタイムで可視化することも可能ですが，colab上では非常にカクカクしてしまいます．この演習では1エピソード全体をmp4に保存してから再生することにします．まず可視化のための関数を定義します．"]},{"cell_type":"code","metadata":{"id":"ZkgUuloVKlDq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070544935,"user_tz":-540,"elapsed":45086,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["def wrap_monitor(env):\n","    \"\"\" Gymの環境をmp4に保存するために，環境をラップする関数． \"\"\"\n","    return wrappers.Monitor(env, '/tmp/monitor', video_callable=lambda x: True, force=True)\n","\n","def play_mp4():\n","    \"\"\" 保存したmp4をHTMLに埋め込み再生する関数． \"\"\"\n","    path = glob.glob(os.path.join('/tmp/monitor', '*.mp4'))[0]\n","    mp4 = open(path, 'rb').read()\n","    url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","    return HTML(\"\"\"<video width=400 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % url)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"piL37cHknI-2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600070544937,"user_tz":-540,"elapsed":45075,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"10b359e1-41bb-4d3e-c7f6-4d0cf93fd641"},"source":["%cd /content/drive/My Drive/pybullet/gym-pybullet"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/pybullet/gym-pybullet\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BwbQ9EpZRZNw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1600070549639,"user_tz":-540,"elapsed":49760,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"0a8ccca9-34b1-477b-c77e-0fbf62297e7d"},"source":["import gym_pybullet\n","\n","\n","env = gym.make('pybullet_handle_line-v0')\n","#env = wrap_monitor(env)\n","\n","print('observation space camera: ', env.observation_space_camera)\n","print('observation space cordinate: ', env.observation_space_cordinate)\n","print('action space: ', env.action_space)\n","\n","env.reset()\n","done = False\n","\"\"\"\n","# 終了シグナル(done=True)が返ってくるまで，ランダムに環境を動かす．\n","while (not done):\n","  action = env.action_space.sample()\n","  #_, _, done = env.step(action)\n","  _, _, done, _ = env.step(action)\n","\"\"\"\n","\n","del env\n","\n","#TODO: wrap_monitorしてもmp4ファイルが作られない\n","#play_mp4()\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["observation space camera:  Box(84, 84, 1)\n","observation space cordinate:  Box(2,)\n","action space:  Box(1,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_7awwWKC4UXj","colab_type":"text"},"source":["## 2.予備知識"]},{"cell_type":"markdown","metadata":{"id":"HJnRVbjUsRuz","colab_type":"text"},"source":["### 2.1 講義内容のおさらい"]},{"cell_type":"markdown","metadata":{"id":"i3YVPO9cxqHt","colab_type":"text"},"source":["**TODO: 強化学習全般(方策勾配法・Actor-Critic)やPPO・SACに関する簡単な説明**"]},{"cell_type":"markdown","metadata":{"id":"tSrsyV95sZSw","colab_type":"text"},"source":["### 2.2 実装の概要"]},{"cell_type":"markdown","metadata":{"id":"1CY-FFyFscwx","colab_type":"text"},"source":["この演習では，一定のステップ間データ収集・学習・評価を繰り返す `Trainer` クラスを利用します．今回は実装済みのものを利用しますが，このクラスでは強化学習の大まかな流れを実装しているので，ぜひ参照してみてください．"]},{"cell_type":"code","metadata":{"id":"2csWXzTcsgET","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549641,"user_tz":-540,"elapsed":49747,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["class Trainer:\n","\n","    def __init__(self, env, env_test, algo, seed=0, num_steps=10**6, eval_interval=10**4, num_eval_episodes=3,save_interval=10**6):#####################################num_stepsとeval_stepを小さく\n","\n","        self.env = env #環境\n","        self.env_test = env_test #テスト環境?\n","        self.algo = algo #アルゴリズム\n","\n","        # 環境の乱数シードを設定する．\n","        self.env.seed(seed)\n","        self.env_test.seed(2**31-seed)\n","\n","        # 平均収益を保存するための辞書．\n","        self.returns = {'step': [], 'return': []}\n","\n","        # データ収集を行うステップ数．\n","        self.num_steps = num_steps\n","        # 評価の間のステップ数(インターバル)．\n","        self.eval_interval = eval_interval\n","        # 評価を行うエピソード数．\n","        self.num_eval_episodes = num_eval_episodes\n","        #モデルの重みを保存するステップ数(インターバル)\n","        self.save_interval = save_interval #######################################################\n","\n","    def train(self):\n","        \"\"\" num_stepsステップの間，データ収集・学習・評価を繰り返す． \"\"\"\n","\n","        # 学習開始の時間\n","        self.start_time = time()\n","        # エピソードのステップ数．\n","        t = 0\n","\n","        # 環境を初期化する．\n","        state = self.env.reset() #resetでもstateを返す\n","\n","        for steps in range(1, self.num_steps + 1):#1～num.step\n","            # 環境(self.env)，現在の状態(state)，現在のエピソードのステップ数(t)，今までのトータルのステップ数(steps)を\n","            # アルゴリズムに渡し，状態・エピソードのステップ数を更新する．\n","            state, t = self.algo.step(self.env, state, t, steps)\n","\n","            #print(steps)\n","\n","            # アルゴリズムが準備できていれば，1回学習を行う．\n","            if self.algo.is_update(steps):\n","                self.algo.update()#学習\n","\n","            # 一定のインターバルで評価する．\n","            if steps % self.eval_interval == 0:\n","                self.evaluate(steps)\n","\n","            if steps % self.save_interval == 0:\n","                self.save_model(steps)\n","\n","    def save_model(self,steps):#モデルの重みを保存する関数\n","         torch.save(self.algo.actor.to('cpu').state_dict(), 'weights/PPO_camera_handle_line_'+str(steps)+'steps.pth')#self.algo.actor =PPO.actor\n","         self.algo.actor.to(torch.device('cuda'))############################)\n","\n","\n","\n","\n","\n","    def evaluate(self, steps):#評価\n","        \"\"\" 複数エピソード環境を動かし，平均収益を記録する． \"\"\"\n","\n","        returns = []\n","        for _ in range(self.num_eval_episodes):#num_eval_episodes回episodeを繰り返し、報酬の平均を取る\n","            state = self.env_test.reset()\n","            done = False\n","            episode_return = 0.0\n","\n","            while (not done):\n","                action = self.algo.exploit(state)#最適行動を選択(決定論的な行動)\n","                state, reward, done, _ = self.env_test.step(action)\n","                episode_return += reward\n","\n","            returns.append(episode_return)\n","\n","        mean_return = np.mean(returns)\n","        self.returns['step'].append(steps)#steps(トータルのステップ)\n","        self.returns['return'].append(mean_return)\n","\n","        print(f'Num steps: {steps:<6}   '\n","              f'Return: {mean_return:<5.1f}   '\n","              f'Time: {self.time}')\n","    \"\"\"\n","    #wrap_monitor()が使えないのでvisualize()は使えない\n","    def visualize(self):\n","        # 1エピソード環境を動かし，mp4を再生する．\n","        env = wrap_monitor(gym.make(self.env.unwrapped.spec.id))\n","        state = env.reset()\n","        done = False\n","\n","        while (not done):\n","            action = self.algo.exploit(state)\n","            state, _, done, _ = env.step(action)\n","\n","        del env\n","        return play_mp4()\n","    \"\"\"\n","\n","    def plot(self):\n","        \"\"\" 平均収益のグラフを描画する． \"\"\"\n","        fig = plt.figure(figsize=(8, 6))\n","        plt.plot(self.returns['step'], self.returns['return'])\n","        plt.xlabel('Steps', fontsize=24)\n","        plt.ylabel('Return', fontsize=24)\n","        plt.tick_params(labelsize=18)\n","        plt.title(f'{self.env.unwrapped.spec.id}', fontsize=24)\n","        plt.tight_layout()\n","\n","    @property#timeプロパティを読み取り限定で設定(getter)\n","    def time(self):\n","        \"\"\" 学習開始からの経過時間． \"\"\"\n","        return str(timedelta(seconds=int(time() - self.start_time)))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAFsbIKwxXO_","colab_type":"text"},"source":["次章以降では，以下の抽象クラスを継承して，PPOとSACのアルゴリズムを記述したアルゴリズム(Trainerの `self.algo`の部分)を実装し，強化学習の処理を完成させていきます！"]},{"cell_type":"code","metadata":{"id":"UngEASpOE__V","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549642,"user_tz":-540,"elapsed":49738,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["class Algorithm(ABC):#抽象クラスを作成\n","\n","    def explore(self, state):\n","        \"\"\" 確率論的な行動と，その行動の確率密度の対数 \\log(\\pi(a|s)) を返す． \"\"\"\n","\n","        cam_state = torch.tensor(state[0], dtype=torch.float, device=self.device).unsqueeze_(0).unsqueeze_(0)#(84*84)→(1,1,84,84)  #問題あり\n","        pos_state = torch.tensor(state[1], dtype=torch.float, device=self.device).unsqueeze_(0)\n","\n","        state = [cam_state,pos_state]#########################numpyに替えれる?\n","\n","        with torch.no_grad():\n","            action, log_pi = self.actor.sample(state)         #self.actorはAlgorithmクラスを継承したクラスにある?\n","        return action.cpu().numpy()[0], log_pi.item()\n","\n","    def exploit(self, state):\n","        \"\"\" 決定論的な行動を返す． \"\"\"\n","       \n","        cam_state = torch.tensor(state[0], dtype=torch.float, device=self.device).unsqueeze_(0).unsqueeze_(0)#(84*84)→(1,1,84,84)  #問題あり\n","        pos_state = torch.tensor(state[1], dtype=torch.float, device=self.device).unsqueeze_(0)\n","\n","        #state = [cam_state,pos_state]##############################################\n","\n","        with torch.no_grad():\n","            action = self.actor.forward(cam_state,pos_state)################################\n","        return action.cpu().numpy()[0]\n","\n","    @abstractmethod#抽象メソッドを表すデコレーター\n","    #抽象クラスを継承するクラスは抽象メソッドを実装しなければならなくなるのでクラスを作る際のルールになる\n","    def is_update(self, steps):\n","        \"\"\" 現在のトータルのステップ数(steps)を受け取り，アルゴリズムを学習するか否かを返す． \"\"\"\n","        pass\n","\n","    @abstractmethod\n","    def step(self, env, state, t, steps):\n","        \"\"\" 環境(env)，現在の状態(state)，現在のエピソードのステップ数(t)，今までのトータルのステップ数(steps)を\n","            受け取り，リプレイバッファへの保存などの処理を行い，状態・エピソードのステップ数を更新する．\n","        \"\"\"\n","        pass\n","\n","    @abstractmethod\n","    def update(self):\n","        \"\"\" 1回分の学習を行う． \"\"\"\n","        pass"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e6tuB-Ed4ULy","colab_type":"text"},"source":["## 3.Proximal Policy Optimization(PPO)の実装"]},{"cell_type":"markdown","metadata":{"id":"PBjDdY1sACOO","colab_type":"text"},"source":["#### 3.1 [演習] 方策計算のための関数の実装"]},{"cell_type":"markdown","metadata":{"id":"ByR90JN2ATX5","colab_type":"text"},"source":["今回の演習では **共分散行列が対角なガウス分布に $\\tanh$ を適用した確率分布** をPPO・SACの方策として用います．以下では，共分散行列が対角なガウス分布を単にガウス分布と呼び，共分散行列の対角成分の平方根を単に標準偏差と呼ぶことにします．また，括弧で囲んだ表記 `(...)` は，TensorのSizeを表すことにします．\n","\n","方策は，学習時に探索を行うための**確率論的な行動選択**と，評価時に最適な行動を行うための**決定論的な行動選択**の2種類の行動選択を行います．確率論的な行動選択ではガウス分布からのサンプルに $\\tanh$ を適用したものを，決定論的な行動選択ではガウス分布の最頻値(平均)に $\\tanh$ を適用したものを行動とします．\n","\n","まず，確率論的な行動を計算した際の**行動の確率密度の対数 $\\log \\pi(a|s)$**を求める関数 `calculate_log_pi(log_stds, noises, actions)` を実装しましょう．ただし，引数の `log_stds` (標準偏差(分散の平方根)の対数)，`noises` (Reparametrization Trickにおける標準ガウス分布からのノイズ)，`actions` (行動)はすべて `(batch_size, |A|)` とし，行動の確率密度の対数は `(batch_size, 1)` で返します．\n","\n"]},{"cell_type":"markdown","metadata":{"id":"osqFBGB9muqU","colab_type":"text"},"source":["(ヒント) Reparameterization Trickでは，標準ガウス分布からのノイズ $\\epsilon \\sim \\mathcal N(0, I)$ を用いて，平均 $\\mu$，標準偏差 $\\sigma$ からのサンプルを以下のように計算します．\n","\n","$$ u = \\mu + \\epsilon * \\sigma $$ $$ a = \\tanh(u) $$\n","\n","【余力がある人向け】\n","\n","確率密度関数は平行移動に関して不変なので，ガウス分布からのサンプル $u$ の確率密度 $p(u|s)$ は $\\mathcal N(0, \\sigma I)$ における $\\epsilon * \\sigma$ の確率密度として計算することができます．その後，$\\tanh$ による確率密度の変化を以下のように修正してあげましょう．\n","\n","確率密度関数 $\\pi(a|s)$ は $$ \\pi(a|s) = \\biggl|\\frac{du}{da}\\biggl|p(u|s) = \\frac{1}{1-a^2}p(u|s) $$\n","\n","$\\log$ をとると $$ \\begin{align} \\log\\pi(a|s) &= \\log p(u|s) - \\sum_{i=1}^{|\\mathcal A|} \\log (1 - a^{2}) \\end{align} $$\n","\n","(各actionの要素での確率の積にlogがかかったものを計算するので、総和をとります)"]},{"cell_type":"code","metadata":{"id":"6nFzrtnyABdk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549643,"user_tz":-540,"elapsed":49729,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["def calculate_log_pi(log_stds, noises, actions):#標準偏差の対数(σ)、ノイズ(ε)、行動から行動の確率密度の対数(logπ(a|s))を求める関数\n","    \"\"\" 確率論的な行動の確率密度を返す． \"\"\"\n","\n","    # NOTE: 入力はすべて (batch_size, |A|) となっているので，この関数では　batch_size　分の確率密度の対数 \\log \\pi(a|s) を\n","    # それぞれ独立に計算し (batch_size, 1) で返します．\n","\n","    #from IPython.core.debugger import Pdb; Pdb().set_trace() #ブレークポイント\n","\n","    # ガウス分布 `N(0, stds * I)` における `noises * stds` の確率密度の対数(= \\log \\pi(u|a))を計算する．\n","    stds = log_stds.exp()#標準偏差の対数→標準偏差\n","    gaussian_log_probs = Normal(torch.zeros_like(stds), stds).log_prob(stds * noises).sum(dim=-1, keepdim=True)#logP(u|s)を計算\n","    #平均0、標準変偏差stdの正規分布\n","    # NOTE: gaussian_log_probs には (batch_size, 1) で表された確率密度の対数 \\log p(u|s) が入っています．\n","\n","    # [演習] その後，tanh による確率密度の変化を修正しましょう．\n","    # (例)\n","    # log_pis = gaussian_log_probs - ...\n","    log_pis = gaussian_log_probs - torch.log(1 - actions.pow(2) + 1e-6).sum(dim=-1, keepdim=True)#logπ(a|s)の計算\n","    #Reparameterization Trick　(tanh  による確率密度の変化)(上のテキストの最後の式)\n","\n","    return log_pis"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qjfGow_woKEO","colab_type":"text"},"source":["次に，Reparameterization Trickを用いて，確率的な行動 $a = \\tanh(\\mu + \\epsilon * \\sigma)$ とその行動の確率密度の対数 $\\log \\pi(a|s)$ を計算する関数 `reparameterize(means, log_stds)` を実装しましょう．ただし，引数の `means` (平均)と `log_stds` (標準偏差の対数)は `(batch_size, |A|)` とし，行動は `(batch_size, |A|)`，確率密度の対数は `(batch_size, 1)` で返します．"]},{"cell_type":"code","metadata":{"id":"joEHUfnAoNel","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549644,"user_tz":-540,"elapsed":49721,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["def reparameterize(means, log_stds):\n","    \"\"\" Reparameterization Trickを用いて，確率論的な行動とその確率密度を返す． \"\"\"\n","\n","    # 標準偏差．\n","    stds = log_stds.exp()\n","\n","    # [演習] Reparameterization Trickを用いて，標準ガウス分布からノイズをサンプリングし，確率論的な行動を計算しましょう．\n","    # (例)\n","    # noises = ...\n","    # actions = ...\n","    # 標準ガウス分布から，ノイズをサンプリングする．\n","    noises = torch.randn_like(means)\n","    # Reparameterization Trickを用いたN(means, stds)からのサンプルの計算．\n","    us = means + noises * stds #μ+ϵ∗σ\n","    # tanh　を適用し，確率論的な行動を計算する．\n","    actions = torch.tanh(us) # a=tanh(μ+ϵ∗σ)\n","\n","    # 確率論的な行動の確率密度の対数を計算する．\n","    log_pis = calculate_log_pi(log_stds, noises, actions)#logπ(a|s)\n","\n","    return actions, log_pis"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LFHSQdjHBDNC","colab_type":"text"},"source":["また，のちのち簡単に方策を実装できるように，ある平均・標準偏差の対数でパラメータ化したガウス分布 + $\\tanh$ の方策における，ある行動の確率密度の対数を計算する関数 `evaluate_lop_pi(means, log_stds, actions)` をあらかじめ定義しておきます．"]},{"cell_type":"code","metadata":{"id":"JMabtapvCs2I","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549644,"user_tz":-540,"elapsed":49712,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["def atanh(x):\n","    \"\"\" tanh の逆関数． \"\"\"\n","    return 0.5 * (torch.log(1 + x + 1e-6) - torch.log(1 - x + 1e-6))\n","\n","\n","def evaluate_lop_pi(means, log_stds, actions):\n","    \"\"\" 平均(mean)，標準偏差の対数(log_stds)でパラメータ化した方策における，行動(actions)の確率密度の対数を計算する． \"\"\"\n","    noises = (atanh(actions) - means) / (log_stds.exp() + 1e-8)#atanh(actions)でuを求めて、u=μ+εσからnoiseεを求める\n","    return calculate_log_pi(log_stds, noises, actions)#logπ(a|s)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_aDzmgu88eg6","colab_type":"text"},"source":["### 3.2 [演習] ネットワークの実装"]},{"cell_type":"markdown","metadata":{"id":"HBN4Kke02q8V","colab_type":"text"},"source":["PPOの方策では，ユニット数64の隠れ層を2層もち，中間層の活性化関数に $\\tanh$ を用いたネットワークを構築します．このネットワークは，入力として状態を受け取り，**ガウス分布の平均**を出力します．また**ガウス分布の標準偏差の対数**を，学習するパラメータとして保持します．\n","\n","では早速，PPOの方策を関数近似するネットワークのクラス `PPOActor` を実装しましょう！ここでは，以下の4つのメソッドを実装します．\n","\n","- `__init__(self, state_shape, action_shape)`\n","\n","> 入力として状態を受け取り，**ガウス分布の平均**を出力するネットワークを構築します．また，**ガウス分布の標準偏差の対数**を表すパラメータを作成します．\n","\n","- `forward(self, states)`\n","\n","> `(batch_size, |S|)` の `states` を受け取り，決定論な行動 $a$ を `(batch_size, 1)`で返します．\n","\n","- `sample(self, states)`\n","\n","> `(batch_size, |S|)` の `states` を受け取り，確率論的な行動 $a$ とその行動の確率密度の対数 $\\log(\\pi(a|s))$ をそれぞれ `(batch_size, 1)` で返します．\n","\n","- `evaluate_log_pi(self, states, actions)`\n","\n","> `(batch_size, |S|)` の `states` と，`(batch_size, |A|)` の `actions` を受け取り，現在の方策における行動 `actions` の確率密度の対数を `(batch_size, 1)` で返します．\n"]},{"cell_type":"code","metadata":{"id":"xCRKh-ocX_M_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600070549645,"user_tz":-540,"elapsed":49700,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"addb84da-9402-422b-bb28-190b6409bbd7"},"source":["def calculate_cnn_size(input_size,kernel_size,stride):\n","  output_size = (input_size -kernel_size)/stride + 1\n","  return output_size\n","\n","kernel_size1 = 8\n","stride1 = 4\n","kernel_size2 = 4\n","stride2 =2\n","kernel_size3 = 3\n","stride3 =1\n","input_size = 84\n","\n","output_size = calculate_cnn_size(input_size, kernel_size1, stride1)\n","output_size = calculate_cnn_size(output_size, kernel_size2, stride2)\n","output_size = calculate_cnn_size(output_size, kernel_size3, stride3)\n","output_size = int(output_size)\n","\n","print(output_size)\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KhNUtiaA8le7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549915,"user_tz":-540,"elapsed":49956,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["class PPOActor(nn.Module):\n","    def __init__(self, state_shape, action_shape):\n","        super().__init__()\n","\n","        #from IPython.core.debugger import Pdb; Pdb().set_trace()                        #ブレークポイント\n","        self.kernel_size1 = 8\n","        self.stride1 = 4\n","        self.kernel_size2 = 4\n","        self.stride2 =2\n","        self.kernel_size3 = 3\n","        self.stride3 =1\n","        \n","        self.block1 = nn.Sequential(\n","          nn.Conv2d(state_shape[0][2], 32, kernel_size=self.kernel_size1, stride=self.stride1),  # 3x84x84 -> 32x20x20　 #state_shape[0][2]はcamera_shapeの3(RGB)\n","          nn.ReLU(),\n","          nn.Conv2d(32, 64, kernel_size=self.kernel_size2, stride= self.stride2),  # 32x20x20 -> 64x9x9\n","          nn.ReLU(),\n","          nn.Conv2d(64, 64, kernel_size=self.kernel_size3, stride=self.stride3),  # 64x9x9 -> 64x7x7\n","          nn.ReLU()\n","        )\n","        \"\"\"\n","        output_size = calculate_cnn_size(state_shape[0][2], self.kernel_size1, self.stride1)\n","        output_size = calculate_cnn_size(output_size, self.kernel_size2, self.stride2)\n","        output_size = calculate_cnn_size(output_size, self.kernel_size3, self.stride3)\n","        output_size = int(output_size)\n","        \"\"\"\n","\n","          \n","        self.full_connection = nn.Sequential(\n","           nn.Linear(in_features= 3138, out_features=64), # =64*output_size*output_size+state_shape[1][0]→3138         \n","                                    nn.Tanh(),\n","                                    nn.Linear(64, 64),\n","                                    nn.Tanh(),\n","                                    nn.Linear(64, action_shape[0])\n","                                    )#行動の次元の数だけガウス分布を出力\n","\n","    # ガウス分布の標準偏差の対数を表す，学習するパラメータを作成します．\n","        self.log_stds = nn.Parameter(torch.zeros(1, action_shape[0]))\n","\n","\n","   \n","    def forward(self,camera_state,pos_state):\n","\n","\n","      #from IPython.core.debugger import Pdb; Pdb().set_trace()\n","\n","      x = self.block1(camera_state)#カメラ画像を畳み込み\n","      x = x.view(x.size(0),-1)#　Flatten. 64x7x7　-> 3136 #(batch_size,3136)\n","      \n","      x = torch.cat([x,pos_state],dim=1)#cameraの特徴量とゴールまでの相対座標を統合\n","\n","      #from IPython.core.debugger import Pdb; Pdb().set_trace()#######################\n","      #x.shape = torch.Size([1, 3138]\n","\n","      x = self.full_connection(x)#(batch_num,action_shape)####################################################問題あり\n","\n","      return torch.tanh(x)#ガウス分布の平均にtanhを適用したのが最適手法\n","\n","    def forward2(self,camera_state,pos_state):\n","      x = self.block1(camera_state)#カメラ画像を畳み込み\n","      x = x.view(x.size(0),-1)#　Flatten. 64x7x7　-> 3136 #(batch_size,3136)\n","      \n","      x = torch.cat([x,pos_state],dim=1)#cameraの特徴量とゴールまでの相対座標を統合\n","\n","      #from IPython.core.debugger import Pdb; Pdb().set_trace()#######################\n","      #x.shape = torch.Size([1, 3138]\n","\n","      x = self.full_connection(x)#(batch_num,action_shape)####################################################問題あり\n","\n","      return x\n","\n","\n","        \n","                          \n","    \"\"\"\n","    def __init__(self, state_shape, action_shape):\n","        super().__init__()\n","\n","        # 状態を受け取り，ガウス分布の平均を出力するネットワークを構築します\n","        self.net = nn.Sequential(\n","            nn.Linear(state_shape[0], 64),\n","            nn.Tanh(),\n","            nn.Linear(64, 64),\n","            nn.Tanh(),\n","            nn.Linear(64, action_shape[0]),#行動の次元の数だけガウス分布を出力\n","        )\n","\n","        # ガウス分布の標準偏差の対数を表す，学習するパラメータを作成します．\n","        self.log_stds = nn.Parameter(torch.zeros(1, action_shape[0]))\n","\n","    def forward(self, states):\n","        # [演習] 決定論的な行動を計算し，返します．\n","        # return ...\n","        return torch.tanh(self.net(states))#ガウス分布の平均にtanhを適用したのが最適手法\n","      \"\"\"\n","    def sample(self, states):\n","        # [演習] ガウス分布の平均と標準偏差から確率論的な行動と確率密度の対数を計算し，返します．\n","        # (例)\n","        # actions, log_pis = reparameterize(...)\n","        # return actions, log_pis\n","        means = self.forward2(states[0], states[1])\n","        return reparameterize(means, self.log_stds)\n","\n","    def evaluate_log_pi(self, cam_states, pos_states, actions):\n","        # 現在の方策における行動 actions の確率密度の対数を計算し，返します．\n","        return evaluate_lop_pi(self.forward2(cam_states,pos_states), self.log_stds, actions)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GNC4aOG68end","colab_type":"text"},"source":["続いて，PPOの状態価値を関数近似するネットワークのクラス `PPOCritic` を実装しましょう．このネットワークも，ユニット数64の隠れ層を2層もち，中間層の活性化関数に $\\tanh$ を用います．入力として状態を受け取り，状態価値を出力します．\n","\n","では，以下の2つのメソッドを実装しましょう．\n","\n","- `__init__(self, state_shape)`\n","\n","> 入力として状態受け取り，状態価値を出力するネットワークを構築します．\n","\n","- `forward(self, states)`\n","\n","> `(batch_size, |S|)` の `states` を受け取り，状態価値を `(batch_size, 1)` で返します．\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"is0PicZs-D3a","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549916,"user_tz":-540,"elapsed":49947,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["class PPOCritic(nn.Module):\n","    def __init__(self,state_shape):\n","        super().__init__()\n","\n","        self.kernel_size1 = 8\n","        self.stride1 = 4\n","        self.kernel_size2 = 4\n","        self.stride2 =2\n","        self.kernel_size3 = 3\n","        self.stride3 =1\n","        \n","        self.block1 = nn.Sequential(\n","          nn.Conv2d(state_shape[0][2], 32, kernel_size=self.kernel_size1, stride=self.stride1),  # 3x84x84 -> 32x20x20　 #state_shape[0][2]はcamera_shapeの3(RGB)\n","          nn.ReLU(),\n","          nn.Conv2d(32, 64, kernel_size=self.kernel_size2, stride= self.stride2),  # 32x20x20 -> 64x9x9\n","          nn.ReLU(),\n","          nn.Conv2d(64, 64, kernel_size=self.kernel_size3, stride=self.stride3),  # 64x9x9 -> 64x7x7\n","          nn.ReLU()\n","        )\n","        \"\"\"\n","        output_size = calculate_cnn_size(state_shape[0][2], self.kernel_size1, self.stride1)\n","        output_size = calculate_cnn_size(output_size, self.kernel_size2, self.stride2)\n","        output_size = calculate_cnn_size(output_size, self.kernel_size3, self.stride3)\n","        output_size = int(output_size)\n","        \"\"\"\n","\n","        self.full_connection = nn.Sequential(nn.Linear(in_features=3138, out_features=64),#64*output_size*output_size+state_shape[1][0]→3138\n","                                        nn.Tanh(),\n","                                        nn.Linear(64, 64),\n","                                        nn.Tanh(),\n","                                        nn.Linear(64, 1))#状態を受け取り状態価値を出力\n","\n","      \n","    def forward(self,camera_state,pos_state):\n","        x = self.block1(camera_state)#カメラ画像を畳み込み\n","        x = x.view(x.size(0),-1)#　Flatten. 64x7x7　-> 3136 #(batch_size,3136)\n","        \n","        x = torch.cat([x,pos_state],dim=1)#cameraの特徴量とゴールまでの相対座標を統合\n","\n","        #from IPython.core.debugger import Pdb; Pdb().set_trace()#####################################################\n","\n","        x = self.full_connection(x)#(batch_num,1)\n","\n","        return x\n","\n","\n","\n","    \"\"\"\n","    def __init__(self, state_shape):\n","        super().__init__()\n","\n","        # [演習] 状態を受け取り，状態価値を出力するネットワークを構築しましょう．\n","        # (例)\n","        self.net = nn.Sequential(\n","            nn.Linear(state_shape[0], 64),\n","            nn.Tanh(),\n","            nn.Linear(64, 64),\n","            nn.Tanh(),\n","            nn.Linear(64, 1),\n","        )\n","    def forward(self, states):\n","        # [演習] 状態価値を計算し，返します．\n","        return self.net(states)\n","    \"\"\""],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0gwH2XTaVotk","colab_type":"text"},"source":["### 3.3 Generalized Advantage Estimation(GAE)の実装"]},{"cell_type":"markdown","metadata":{"id":"qmBWfpMuVtUo","colab_type":"text"},"source":["PPOでは，アドバンテージの推定に**Generalized Advantage Estimation**(GAE)[[4]](#scrollTo=HOq7n-OJboPr)を用います．GAEではnステップのアドバンテージ $\\hat A_t^{(n)} = r_t + \\gamma r_{t+1} + \\cdots + \\gamma^n V(s_{t+n}) - V(s_t)$ を用いて，以下のようにアドバンテージを推定します．\n","\n","$$\n","\\hat A_t^{GAE}(\\lambda) = (1-\\lambda)(\\hat A_t^{(1)} + \\lambda \\hat A_t^{(2)} + \\lambda^2 \\hat A_t^{(3)} + \\cdots)\n","$$\n","\n","このとき，TD誤差 $\\delta_t= r_t+ \\gamma V(s_{t+1}) - V(s_t)$ を用いると，以下のように式変形できます．(発展課題で導出に挑戦してみましょう！)\n","\n","$$\n","\\hat A_t^{GAE}(\\lambda) = \\sum_{i=0}^{\\infty} (\\gamma \\lambda)^i \\delta_{t+i}\n","$$\n","\n","従って，GAEは再帰的に計算することが可能です．ただし，実際にはロールアウト長を $T$ としたときに，$t = T + 1$ 以降のGAEをすべて $0$ と近似して計算を行います．\n","\n","$$\n","\\hat A_t^{GAE}(\\lambda) = \\delta_t + (\\gamma \\lambda) \\hat A_{t+1}^{GAE}(\\lambda)\n","$$\n","\n","\\\\\n","またPPOでは，状態価値のターゲットを $\\lambda$-収益 $R_t(\\lambda)$ を用いて推定します．\n","\n","$$\n","R_t(\\lambda) = \\hat A_t^{GAE}(\\lambda) + V(s_t)\n","$$\n"]},{"cell_type":"code","metadata":{"id":"bvbFfmsbVsoS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549917,"user_tz":-540,"elapsed":49938,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["def calculate_advantage(values, rewards, dones, gamma=0.995, lambd=0.997):\n","    \"\"\" GAEを用いて，状態価値のターゲットとGAEを計算する． \"\"\"\n","    #value[0]=V(St), value[-1]=V(T)\n","    # TD誤差を計算する．\n","    deltas = rewards + gamma * values[1:] * (1 - dones) - values[:-1]#δt =rt + γV(St+1)-V(St)より\n","    #value[:-1](最初から最後の一つ前まで)\n","    #deltas[0]=δt, deltas[-1]=δT\n","\n","    # GAEを初期化する．\n","    advantages = torch.empty_like(rewards)\n","\n","    # 終端ステップを計算する．\n","    advantages[-1] = deltas[-1]#AT^GAE(λ)=δT (A(T+1)^GAE(λ)=0より)\n","\n","    # 終端ステップの1つ前から，順番にGAEを計算していく．\n","    for t in reversed(range(rewards.size(0) - 1)):\n","        advantages[t] = deltas[t] + gamma * lambd * (1 - dones[t]) * advantages[t + 1]#At^GAE(λ)=δt+(γλ)A(t+1)^GAE(λ)\n","\n","    # 状態価値のターゲットをλ-収益として計算する．\n","    targets = advantages + values[:-1] #Rt(λ)=A^GAEt(λ)+V(st)\n","\n","    # GAEを標準化する．\n","    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n","\n","    return targets, advantages"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Ag6zR7a8eaE","colab_type":"text"},"source":["### 3.4 [演習] 学習アルゴリズム(PPO)の実装"]},{"cell_type":"markdown","metadata":{"id":"w9ZL471Cvmjb","colab_type":"text"},"source":["まず，収集したデータを保存するためのバッファを用意します．ここでは，状態・行動・即時報酬・終了シグナル・確率密度の対数をロールアウト1回分保存することとします．このとき，状態のみ1つ分多く保存することに注意します(GAEの計算では，1ステップ先の状態価値を計算する必要があるので)．"]},{"cell_type":"code","metadata":{"id":"w1TyJ7mm_Btu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549918,"user_tz":-540,"elapsed":49928,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["class RolloutBuffer:\n","\n","    def __init__(self, buffer_size, state_shape, action_shape, device=torch.device('cuda')):\n","\n","        # GPU上に保存するデータ．\n","        seg_shape = [state_shape[0][2],state_shape[0][0],state_shape[0][1]]\n","\n","        self.states_camera = torch.empty((buffer_size + 1, *seg_shape), dtype=torch.float, device=device)#buffer_size(t～T+1,state_shape)\n","        self.states_pos = torch.empty((buffer_size + 1, *state_shape[1]), dtype=torch.float, device=device)\n","        \n","        self.actions = torch.empty((buffer_size, *action_shape), dtype=torch.float, device=device)\n","        self.rewards = torch.empty((buffer_size, 1), dtype=torch.float, device=device)\n","        self.dones = torch.empty((buffer_size, 1), dtype=torch.float, device=device)\n","        self.log_pis = torch.empty((buffer_size, 1), dtype=torch.float, device=device)\n","\n","        # 次にデータを挿入するインデックス．\n","        self._p = 0\n","        # バッファのサイズ．\n","        self.buffer_size = buffer_size\n","\n","    def append(self, state, action, reward, done, log_pi):\n","        self.states_camera[self._p].copy_(torch.from_numpy(state[0]).unsqueeze(0))\n","        self.states_pos[self._p].copy_(torch.from_numpy(np.array(state[1])))\n","\n","        self.actions[self._p].copy_(torch.from_numpy(action))\n","        self.rewards[self._p] = float(reward)\n","        self.dones[self._p] = float(done)\n","        self.log_pis[self._p] = float(log_pi)\n","        self._p = (self._p + 1) % self.buffer_size\n","\n","    def append_last_state(self, last_state):\n","        assert self._p == 0, 'Buffer needs to be full before appending last_state.'#assert bool値　:bool値がfalseの時エラーが発生する\n","        self.states_camera[self.buffer_size].copy_(torch.from_numpy(last_state[0]))\n","        self.states_pos[self.buffer_size].copy_(torch.from_numpy(np.array(last_state[1])))\n","\n","    def get(self):\n","        assert self._p == 0, 'Buffer needs to be full before training.'\n","        states = [ self.states_camera, self.states_pos]\n","        return states , self.actions, self.rewards, self.dones, self.log_pis"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aXPiwvrewX3_","colab_type":"text"},"source":["では，いよいよPPOの学習アルゴリズムを実装していきましょう！\n","\n","今回の演習では，`update_critic` と `update_actor` の2つのメソッドを実装します．以下では，方策のネットワークのパラメータを $\\phi$，状態価値のネットワークのパラメータを $\\theta$ とします．また，ロールアウト長を $T$ とします．\n","\n","- `update_critic(self, states, targets)`\n","\n","> `(batch_size, |S|)` の `states` (状態)と `(batch_size, 1)` の `targets` (状態価値のターゲット)を受け取り，Criticのネットワークを更新します．\n","\n","> 状態価値のネットワークの損失関数は **平均二乗誤差** を用います．\n","\n","$$\n","\\mathcal L^{PPO}_V(\\theta) = E_{t \\in [1, T]}[ (V_\\theta(s_t) - R_t(\\lambda))^2 ]\n","$$\n","\n","- `update_actor(self, states, actions, log_pis_old, advantages)`\n","\n","> `(batch_size, |S|)` の `states` (状態)と `(batch_size, |A|)` の `actions` (行動)，そして `(batch_size, 1)` の `log_pis_old` (データ収集時の方策における行動の確率密度)と `advantages` (GAE)を受け取り，Actorのネットワークを更新します．\n","\n","> 方策のネットワークの損失関数は，以下の式を用います．ただし，過去の方策のネットワークのパラメータを $\\phi_{old}$ とします．また，損失関数の $\\epsilon$ は `self.clip_eps` に保持されています．\n","\n","$$\n","\\mathcal L^{PPO}_\\pi(\\phi) = E_{t \\in [1, T]}[ \\min(\\frac{\\pi_\\phi(a_t|s_t)}{\\pi_{\\phi_{old}}(a_t|s_t)}\\hat A_t^{GAE}(\\lambda), \\; clip(\\frac{\\pi_\\phi(a_t|s_t)}{\\pi_{\\phi_{old}}(a_t|s_t)}, 1-\\epsilon, 1+\\epsilon) \\hat A_t^{GAE}(\\lambda) ]\n","$$\n","\n"]},{"cell_type":"code","metadata":{"id":"tF2Z46rT-LND","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070549919,"user_tz":-540,"elapsed":49917,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["class PPO(Algorithm):\n","              \n","    def __init__(self, state_shape, action_shape, device=torch.device('cuda'), seed=0,\n","                 batch_size=64, gamma=0.995, lr_actor=3e-4, lr_critic=3e-4,                            # batch_sizeを小さく#################################\n","                 rollout_length=2048, num_updates=10, clip_eps=0.2, lambd=0.97,                          # rollout_length=2048を小さく11111111111111111111111111111111\n","                 coef_ent=0.0, max_grad_norm=0.5):\n","        super().__init__()\n","\n","        # シードを設定する．\n","        np.random.seed(seed)\n","        torch.manual_seed(seed)\n","\n","        # データ保存用のバッファ．\n","        self.buffer = RolloutBuffer(\n","            buffer_size=rollout_length,\n","            state_shape=state_shape,\n","            action_shape=action_shape,\n","            device=device\n","        )\n","\n","        # Actor-Criticのネットワークを構築する．\n","        self.actor = PPOActor(\n","            state_shape=state_shape,\n","            action_shape=action_shape,\n","        ).to(device)#学習するネットワークはGPU上に置く\n","        self.critic = PPOCritic(\n","            state_shape=state_shape,\n","        ).to(device)\n","\n","        # オプティマイザ．\n","        self.optim_actor = torch.optim.Adam(self.actor.parameters(), lr=lr_actor)\n","        self.optim_critic = torch.optim.Adam(self.critic.parameters(), lr=lr_critic)\n","\n","        # その他パラメータ．\n","        self.learning_steps = 0\n","        self.device = device\n","        self.batch_size = batch_size\n","        self.gamma = gamma\n","        self.rollout_length = rollout_length\n","        self.num_updates = num_updates\n","        self.clip_eps = clip_eps\n","        self.lambd = lambd\n","        self.coef_ent = coef_ent\n","        self.max_grad_norm = max_grad_norm\n","\n","    def is_update(self, steps):\n","        # ロールアウト1回分のデータが溜まったら学習する．\n","        return steps % self.rollout_length == 0\n","\n","    def step(self, env, state, t, steps):\n","        t += 1\n","\n","        #from IPython.core.debugger import Pdb; Pdb().set_trace()                                   #ブレークポイント\n","\n","        action, log_pi = self.explore(state)#self.explore=self.actor.sample(確率論的な行動)\n","        next_state, reward, done, _ = env.step(action)\n","\n","        # ゲームオーバーではなく，最大ステップ数に到達したことでエピソードが終了した場合は，\n","        # 本来であればその先もMDPが継続するはず．よって，終了シグナルをFalseにする．\n","        if t == env._max_episode_steps:\n","            done_masked = False\n","        else:\n","            done_masked = done\n","\n","        # バッファにデータを追加する．\n","        self.buffer.append(state, action, reward, done_masked, log_pi)\n","\n","        # ロールアウトの終端Tに達したら，最終状態をバッファに追加する．\n","        if steps % self.rollout_length == 0:\n","            self.buffer.append_last_state(next_state)\n","\n","        # エピソードが終了した場合には，環境をリセットする．\n","        if done:\n","            t = 0\n","            next_state = env.reset()\n","\n","        return next_state, t\n","\n","    def update(self):                                ###############問題あり\n","        self.learning_steps += 1\n","\n","        #from IPython.core.debugger import Pdb; Pdb().set_trace()##########################################################################\n","\n","        states, actions, rewards, dones, log_pis = self.buffer.get()\n","\n","        with torch.no_grad():\n","\n","            values = self.critic(states[0],states[1])\n","            #values = self.critic(states)#状態価値を計算する#111111111111111111111111111111111111111111111111111111111111111111111111111\n","\n","\n","        targets, advantages = calculate_advantage(values, rewards, dones, self.gamma, self.lambd)\n","\n","        # バッファ内のデータを num_updates回ずつ使って，ネットワークを更新する．\n","        for _ in range(self.num_updates):\n","            # インデックスをシャッフルする．\n","            indices = np.arange(self.rollout_length)\n","            np.random.shuffle(indices)\n","\n","            # ミニバッチに分けて学習する．\n","            for start in range(0, self.rollout_length, self.batch_size):\n","                idxes = indices[start:start+self.batch_size]\n","                self.update_critic(states[0][idxes],states[1][idxes], targets[idxes])#11111111111111\n","                self.update_actor(states[0][idxes], states[1][idxes], actions[idxes], log_pis[idxes], advantages[idxes])\n","\n","    def update_critic(self, cam_states, pos_states, targets): #11111111111111111111111111111111111111111111111111111111111111111111111111\n","        # [演習] 状態価値のネットワークの損失関数を計算しましょう．\n","        # (例)\n","        # loss_critic = ... self.critic(...) ...\n","        loss_critic = (self.critic(cam_states,pos_states) - targets).pow_(2).mean()#.pow_(2)は2乗\n","\n","        self.optim_critic.zero_grad()\n","        loss_critic.backward(retain_graph=False)\n","        # 学習を安定させるヒューリスティックとして，(パラメーターの)勾配のノルムをクリッピングする．\n","        nn.utils.clip_grad_norm_(self.critic.parameters(), self.max_grad_norm)#勾配爆発を防ぐために勾配のノルムに上限をかける(クリッピング)\n","        self.optim_critic.step()\n","\n","    def update_actor(self, cam_states, pos_states, actions, log_pis_old, advantages):\n","        # [演習] 方策のネットワークの損失関数を計算しましょう．\n","        # (例)\n","        # loss_actor = ... self.actor ...\n","        log_pis = self.actor.evaluate_log_pi(cam_states, pos_states, actions)#log(πΦ(at|st))\n","        mean_entropy = -log_pis.mean()\n","\n","        ratios = (log_pis - log_pis_old).exp_()#πΦ(at|st)/πΦold(at|st)\n","        loss_actor1 = -ratios * advantages\n","        loss_actor2 = -torch.clamp(\n","            ratios,\n","            1.0 - self.clip_eps,\n","            1.0 + self.clip_eps\n","        ) * advantages\n","        loss_actor = torch.max(loss_actor1, loss_actor2).mean() - self.coef_ent * mean_entropy\n","        #方策のネットワークの損失関数:LPPOπ(ϕ)\n","\n","        self.optim_actor.zero_grad()\n","        loss_actor.backward(retain_graph=False)\n","        # 学習を安定させるヒューリスティックとして，勾配のノルムをクリッピングする．\n","        nn.utils.clip_grad_norm_(self.actor.parameters(), self.max_grad_norm)\n","        self.optim_actor.step()"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6A_Vf5SBHgU","colab_type":"text"},"source":["### 3.5 実験"]},{"cell_type":"markdown","metadata":{"id":"mKHWuYCV1WYI","colab_type":"text"},"source":["それでは，実装したPPOを学習させてみましょう！"]},{"cell_type":"markdown","metadata":{"id":"-B0hc3Q3KqAs","colab_type":"text"},"source":["#### InvertedPendulumBulletEnv-v0\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KIJrWfugiC9v","colab_type":"text"},"source":["まず，`InvertedPendulumBulletEnv-v0` でPPOを $5 \\times 10^4$ ステップ学習させてみましょう！学習には3~5分ほどかかります．うまく学習できると，平均収益が1000に達します．"]},{"cell_type":"code","metadata":{"id":"H1SteWpiLOnH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600070559586,"user_tz":-540,"elapsed":59570,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["ENV_ID = 'pybullet_handle_line-v0'\n","SEED = 0\n","NUM_STEPS = 5*10 ** 5\n","EVAL_INTERVAL = 1000\n","NUM_EVAL_EPISODES = 5\n","SAVE_INTERVAL = 1*10**5\n","\n","env = gym.make(ENV_ID)\n","env_test = gym.make(ENV_ID)\n","\n","algo = PPO(\n","    state_shape=[env.observation_space_camera.shape, env.observation_space_cordinate.shape],\n","    action_shape=env.action_space.shape,\n","    seed=SEED\n",")\n","\n","trainer = Trainer(\n","    env=env,\n","    env_test=env_test,\n","    algo=algo,\n","    seed=SEED,\n","    num_steps=NUM_STEPS,\n","    eval_interval=EVAL_INTERVAL,\n","    num_eval_episodes= NUM_EVAL_EPISODES,\n","    save_interval = SAVE_INTERVAL \n",")"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Hf356-jYtOj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600070559590,"user_tz":-540,"elapsed":59560,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"5259322b-9be9-4dce-8a7d-73e07370098e"},"source":["% debug"],"execution_count":19,"outputs":[{"output_type":"stream","text":["ERROR:root:No traceback has been produced, nothing to debug.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ERisARBfrgVW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600138095821,"user_tz":-540,"elapsed":67595771,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"4b9173db-6a47-4677-e7e6-d290840b78ff"},"source":["trainer.train()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Num steps: 1000     Return: -559.2   Time: 0:01:23\n","Num steps: 2000     Return: -576.7   Time: 0:02:46\n","Num steps: 3000     Return: -574.3   Time: 0:04:12\n","Num steps: 4000     Return: -519.5   Time: 0:05:34\n","Num steps: 5000     Return: -443.3   Time: 0:06:55\n","Num steps: 6000     Return: -563.6   Time: 0:08:13\n","Num steps: 7000     Return: -710.1   Time: 0:09:40\n","Num steps: 8000     Return: -2389.0   Time: 0:12:04\n","Num steps: 9000     Return: -976.5   Time: 0:13:36\n","Num steps: 10000    Return: -560.6   Time: 0:14:55\n","Num steps: 11000    Return: -3980.3   Time: 0:18:19\n","Num steps: 12000    Return: -3920.6   Time: 0:21:46\n","Num steps: 13000    Return: -2275.6   Time: 0:24:14\n","Num steps: 14000    Return: -714.0   Time: 0:25:36\n","Num steps: 15000    Return: -462.1   Time: 0:27:00\n","Num steps: 16000    Return: -305.9   Time: 0:28:16\n","Num steps: 17000    Return: -463.6   Time: 0:29:41\n","Num steps: 18000    Return: -823.7   Time: 0:31:04\n","Num steps: 19000    Return: -265.9   Time: 0:32:27\n","Num steps: 20000    Return: -756.2   Time: 0:33:49\n","Num steps: 21000    Return: -5695.9   Time: 0:38:14\n","Num steps: 22000    Return: -5689.5   Time: 0:42:31\n","Num steps: 23000    Return: -1271.5   Time: 0:44:05\n","Num steps: 24000    Return: -450.5   Time: 0:45:27\n","Num steps: 25000    Return: -572.8   Time: 0:46:54\n","Num steps: 26000    Return: -4034.2   Time: 0:50:23\n","Num steps: 27000    Return: -7731.3   Time: 0:55:57\n","Num steps: 28000    Return: -7842.5   Time: 1:01:26\n","Num steps: 29000    Return: -9303.1   Time: 1:08:08\n","Num steps: 30000    Return: -9350.3   Time: 1:14:43\n","Num steps: 31000    Return: -2332.4   Time: 1:17:14\n","Num steps: 32000    Return: -5666.8   Time: 1:21:43\n","Num steps: 33000    Return: -5746.6   Time: 1:26:18\n","Num steps: 34000    Return: -5717.9   Time: 1:30:45\n","Num steps: 35000    Return: -2428.5   Time: 1:33:17\n","Num steps: 36000    Return: -5636.3   Time: 1:37:54\n","Num steps: 37000    Return: -3835.7   Time: 1:41:29\n","Num steps: 38000    Return: -9063.7   Time: 1:48:09\n","Num steps: 39000    Return: -2088.6   Time: 1:50:34\n","Num steps: 40000    Return: -2102.0   Time: 1:52:53\n","Num steps: 41000    Return: -5572.3   Time: 1:57:16\n","Num steps: 42000    Return: -7458.7   Time: 2:02:45\n","Num steps: 43000    Return: -5607.0   Time: 2:07:17\n","Num steps: 44000    Return: -7790.5   Time: 2:13:08\n","Num steps: 45000    Return: -9298.3   Time: 2:19:59\n","Num steps: 46000    Return: -7519.9   Time: 2:25:47\n","Num steps: 47000    Return: -7747.0   Time: 2:31:32\n","Num steps: 48000    Return: -9408.4   Time: 2:38:31\n","Num steps: 49000    Return: -9401.1   Time: 2:45:33\n","Num steps: 50000    Return: -9372.3   Time: 2:52:31\n","Num steps: 51000    Return: -9463.5   Time: 2:59:33\n","Num steps: 52000    Return: -2359.9   Time: 3:02:13\n","Num steps: 53000    Return: -313.9   Time: 3:03:38\n","Num steps: 54000    Return: -9305.3   Time: 3:10:33\n","Num steps: 55000    Return: -9293.1   Time: 3:17:24\n","Num steps: 56000    Return: -7634.7   Time: 3:23:17\n","Num steps: 57000    Return: -9291.3   Time: 3:30:09\n","Num steps: 58000    Return: -2670.3   Time: 3:32:51\n","Num steps: 59000    Return: -2212.3   Time: 3:35:24\n","Num steps: 60000    Return: -2009.5   Time: 3:38:01\n","Num steps: 61000    Return: -2467.6   Time: 3:40:35\n","Num steps: 62000    Return: -2359.7   Time: 3:43:19\n","Num steps: 63000    Return: -835.6   Time: 3:44:47\n","Num steps: 64000    Return: -351.9   Time: 3:46:15\n","Num steps: 65000    Return: -2427.8   Time: 3:48:52\n","Num steps: 66000    Return: -3066.4   Time: 3:51:45\n","Num steps: 67000    Return: -964.0   Time: 3:53:14\n","Num steps: 68000    Return: -4258.9   Time: 3:57:10\n","Num steps: 69000    Return: -1579.1   Time: 3:58:53\n","Num steps: 70000    Return: -6297.5   Time: 4:03:46\n","Num steps: 71000    Return: -2645.8   Time: 4:06:21\n","Num steps: 72000    Return: -9562.3   Time: 4:13:29\n","Num steps: 73000    Return: -4390.3   Time: 4:17:14\n","Num steps: 74000    Return: -7855.4   Time: 4:23:19\n","Num steps: 75000    Return: -3281.0   Time: 4:26:08\n","Num steps: 76000    Return: -6050.6   Time: 4:31:04\n","Num steps: 77000    Return: -6271.3   Time: 4:35:59\n","Num steps: 78000    Return: -9314.7   Time: 4:43:03\n","Num steps: 79000    Return: -7742.9   Time: 4:48:58\n","Num steps: 80000    Return: -9315.4   Time: 4:56:03\n","Num steps: 81000    Return: -9327.6   Time: 5:03:01\n","Num steps: 82000    Return: -7581.9   Time: 5:09:04\n","Num steps: 83000    Return: -5678.6   Time: 5:13:51\n","Num steps: 84000    Return: -7758.2   Time: 5:19:52\n","Num steps: 85000    Return: -6216.4   Time: 5:24:45\n","Num steps: 86000    Return: -7792.9   Time: 5:30:42\n","Num steps: 87000    Return: -9297.7   Time: 5:37:41\n","Num steps: 88000    Return: -7651.2   Time: 5:43:36\n","Num steps: 89000    Return: -7551.0   Time: 5:49:45\n","Num steps: 90000    Return: -7596.9   Time: 5:55:44\n","Num steps: 91000    Return: -5918.3   Time: 6:00:40\n","Num steps: 92000    Return: -9153.0   Time: 6:07:36\n","Num steps: 93000    Return: -6093.5   Time: 6:12:33\n","Num steps: 94000    Return: -9334.6   Time: 6:19:30\n","Num steps: 95000    Return: -9369.0   Time: 6:26:31\n","Num steps: 96000    Return: -9420.0   Time: 6:33:31\n","Num steps: 97000    Return: -9419.4   Time: 6:40:36\n","Num steps: 98000    Return: -9434.9   Time: 6:47:40\n","Num steps: 99000    Return: -9366.5   Time: 6:54:44\n","Num steps: 100000   Return: -9393.3   Time: 7:01:45\n","Num steps: 101000   Return: -9382.3   Time: 7:08:52\n","Num steps: 102000   Return: -9331.8   Time: 7:15:52\n","Num steps: 103000   Return: -9310.7   Time: 7:22:55\n","Num steps: 104000   Return: -9319.5   Time: 7:29:54\n","Num steps: 105000   Return: -9400.9   Time: 7:36:58\n","Num steps: 106000   Return: -9351.4   Time: 7:43:57\n","Num steps: 107000   Return: -7558.9   Time: 7:49:52\n","Num steps: 108000   Return: -9275.1   Time: 7:56:51\n","Num steps: 109000   Return: -6174.8   Time: 8:01:57\n","Num steps: 110000   Return: -9353.0   Time: 8:08:57\n","Num steps: 111000   Return: -5683.6   Time: 8:13:48\n","Num steps: 112000   Return: -7408.5   Time: 8:19:41\n","Num steps: 113000   Return: -5635.5   Time: 8:24:33\n","Num steps: 114000   Return: -5653.6   Time: 8:29:20\n","Num steps: 115000   Return: -694.0   Time: 8:30:57\n","Num steps: 116000   Return: -5686.5   Time: 8:35:42\n","Num steps: 117000   Return: -2304.7   Time: 8:38:19\n","Num steps: 118000   Return: -288.6   Time: 8:39:43\n","Num steps: 119000   Return: -608.3   Time: 8:41:16\n","Num steps: 120000   Return: -282.8   Time: 8:42:40\n","Num steps: 121000   Return: -3021.3   Time: 8:45:26\n","Num steps: 122000   Return: -1564.2   Time: 8:47:35\n","Num steps: 123000   Return: -437.0   Time: 8:49:02\n","Num steps: 124000   Return: -883.9   Time: 8:50:31\n","Num steps: 125000   Return: -492.1   Time: 8:51:59\n","Num steps: 126000   Return: -783.4   Time: 8:53:28\n","Num steps: 127000   Return: -2799.9   Time: 8:56:21\n","Num steps: 128000   Return: -829.4   Time: 8:58:03\n","Num steps: 129000   Return: -725.4   Time: 8:59:33\n","Num steps: 130000   Return: -259.7   Time: 9:01:00\n","Num steps: 131000   Return: -2033.4   Time: 9:03:34\n","Num steps: 132000   Return: -311.9   Time: 9:05:03\n","Num steps: 133000   Return: -458.6   Time: 9:06:28\n","Num steps: 134000   Return: -559.8   Time: 9:07:59\n","Num steps: 135000   Return: -909.0   Time: 9:09:28\n","Num steps: 136000   Return: -493.6   Time: 9:10:58\n","Num steps: 137000   Return: -3828.9   Time: 9:14:46\n","Num steps: 138000   Return: -454.3   Time: 9:16:16\n","Num steps: 139000   Return: -722.4   Time: 9:17:45\n","Num steps: 140000   Return: -824.4   Time: 9:19:17\n","Num steps: 141000   Return: -382.8   Time: 9:20:45\n","Num steps: 142000   Return: -2069.3   Time: 9:23:20\n","Num steps: 143000   Return: -330.3   Time: 9:24:44\n","Num steps: 144000   Return: -2122.4   Time: 9:27:22\n","Num steps: 145000   Return: -2204.0   Time: 9:29:56\n","Num steps: 146000   Return: -403.0   Time: 9:31:28\n","Num steps: 147000   Return: -334.9   Time: 9:32:54\n","Num steps: 148000   Return: -769.4   Time: 9:34:30\n","Num steps: 149000   Return: -324.6   Time: 9:35:53\n","Num steps: 150000   Return: -2148.1   Time: 9:38:26\n","Num steps: 151000   Return: -259.7   Time: 9:39:51\n","Num steps: 152000   Return: -301.1   Time: 9:41:21\n","Num steps: 153000   Return: -2068.4   Time: 9:43:54\n","Num steps: 154000   Return: -2076.6   Time: 9:46:31\n","Num steps: 155000   Return: -285.3   Time: 9:47:54\n","Num steps: 156000   Return: -268.2   Time: 9:49:24\n","Num steps: 157000   Return: -4099.8   Time: 9:53:13\n","Num steps: 158000   Return: -430.9   Time: 9:54:44\n","Num steps: 159000   Return: -312.5   Time: 9:56:07\n","Num steps: 160000   Return: -848.4   Time: 9:57:42\n","Num steps: 161000   Return: -723.4   Time: 9:59:11\n","Num steps: 162000   Return: -476.2   Time: 10:00:41\n","Num steps: 163000   Return: -570.5   Time: 10:02:07\n","Num steps: 164000   Return: -414.0   Time: 10:03:40\n","Num steps: 165000   Return: -291.8   Time: 10:05:05\n","Num steps: 166000   Return: -229.8   Time: 10:06:33\n","Num steps: 167000   Return: -347.5   Time: 10:07:57\n","Num steps: 168000   Return: -478.5   Time: 10:09:29\n","Num steps: 169000   Return: -256.7   Time: 10:10:53\n","Num steps: 170000   Return: -330.2   Time: 10:12:24\n","Num steps: 171000   Return: -2127.8   Time: 10:14:58\n","Num steps: 172000   Return: -386.0   Time: 10:16:25\n","Num steps: 173000   Return: -327.9   Time: 10:17:54\n","Num steps: 174000   Return: -2130.1   Time: 10:20:28\n","Num steps: 175000   Return: -314.1   Time: 10:22:00\n","Num steps: 176000   Return: -2072.6   Time: 10:24:32\n","Num steps: 177000   Return: -649.8   Time: 10:26:09\n","Num steps: 178000   Return: -353.8   Time: 10:27:34\n","Num steps: 179000   Return: -685.4   Time: 10:29:08\n","Num steps: 180000   Return: -537.2   Time: 10:30:35\n","Num steps: 181000   Return: -561.9   Time: 10:32:08\n","Num steps: 182000   Return: -515.1   Time: 10:33:33\n","Num steps: 183000   Return: -471.2   Time: 10:35:03\n","Num steps: 184000   Return: -409.6   Time: 10:36:28\n","Num steps: 185000   Return: -652.5   Time: 10:38:01\n","Num steps: 186000   Return: -384.6   Time: 10:39:27\n","Num steps: 187000   Return: -815.3   Time: 10:41:03\n","Num steps: 188000   Return: -687.1   Time: 10:42:33\n","Num steps: 189000   Return: -789.6   Time: 10:44:10\n","Num steps: 190000   Return: -713.4   Time: 10:45:41\n","Num steps: 191000   Return: -593.3   Time: 10:47:16\n","Num steps: 192000   Return: -835.4   Time: 10:48:49\n","Num steps: 193000   Return: -429.3   Time: 10:50:22\n","Num steps: 194000   Return: -669.9   Time: 10:51:51\n","Num steps: 195000   Return: -320.6   Time: 10:53:21\n","Num steps: 196000   Return: -469.3   Time: 10:54:49\n","Num steps: 197000   Return: -605.3   Time: 10:56:22\n","Num steps: 198000   Return: -657.0   Time: 10:57:51\n","Num steps: 199000   Return: -389.8   Time: 10:59:22\n","Num steps: 200000   Return: -403.1   Time: 11:00:48\n","Num steps: 201000   Return: -811.5   Time: 11:02:25\n","Num steps: 202000   Return: -679.1   Time: 11:03:56\n","Num steps: 203000   Return: -523.2   Time: 11:05:26\n","Num steps: 204000   Return: -615.7   Time: 11:06:56\n","Num steps: 205000   Return: -387.9   Time: 11:08:26\n","Num steps: 206000   Return: -631.6   Time: 11:09:52\n","Num steps: 207000   Return: -563.8   Time: 11:11:23\n","Num steps: 208000   Return: -1050.9   Time: 11:12:55\n","Num steps: 209000   Return: -1087.1   Time: 11:14:32\n","Num steps: 210000   Return: -494.2   Time: 11:15:57\n","Num steps: 211000   Return: -439.5   Time: 11:17:27\n","Num steps: 212000   Return: -255.4   Time: 11:18:51\n","Num steps: 213000   Return: -574.2   Time: 11:20:24\n","Num steps: 214000   Return: -593.6   Time: 11:21:52\n","Num steps: 215000   Return: -505.9   Time: 11:23:20\n","Num steps: 216000   Return: -413.9   Time: 11:24:50\n","Num steps: 217000   Return: -441.2   Time: 11:26:17\n","Num steps: 218000   Return: -558.1   Time: 11:27:49\n","Num steps: 219000   Return: -542.3   Time: 11:29:18\n","Num steps: 220000   Return: -602.3   Time: 11:30:52\n","Num steps: 221000   Return: -581.3   Time: 11:32:21\n","Num steps: 222000   Return: -391.0   Time: 11:33:50\n","Num steps: 223000   Return: -416.3   Time: 11:35:17\n","Num steps: 224000   Return: -393.9   Time: 11:36:47\n","Num steps: 225000   Return: -428.4   Time: 11:38:14\n","Num steps: 226000   Return: -417.6   Time: 11:39:44\n","Num steps: 227000   Return: -400.0   Time: 11:41:09\n","Num steps: 228000   Return: -386.6   Time: 11:42:39\n","Num steps: 229000   Return: -523.2   Time: 11:44:05\n","Num steps: 230000   Return: -483.2   Time: 11:45:36\n","Num steps: 231000   Return: -468.2   Time: 11:47:04\n","Num steps: 232000   Return: -262.5   Time: 11:48:33\n","Num steps: 233000   Return: -391.7   Time: 11:49:58\n","Num steps: 234000   Return: -410.5   Time: 11:51:29\n","Num steps: 235000   Return: -632.5   Time: 11:52:57\n","Num steps: 236000   Return: -486.5   Time: 11:54:30\n","Num steps: 237000   Return: -505.4   Time: 11:55:56\n","Num steps: 238000   Return: -368.8   Time: 11:57:27\n","Num steps: 239000   Return: -294.3   Time: 11:58:52\n","Num steps: 240000   Return: -251.7   Time: 12:00:22\n","Num steps: 241000   Return: -577.7   Time: 12:01:50\n","Num steps: 242000   Return: -621.3   Time: 12:03:24\n","Num steps: 243000   Return: -511.3   Time: 12:04:51\n","Num steps: 244000   Return: -480.1   Time: 12:06:24\n","Num steps: 245000   Return: -356.1   Time: 12:07:50\n","Num steps: 246000   Return: -491.7   Time: 12:09:21\n","Num steps: 247000   Return: -525.1   Time: 12:10:49\n","Num steps: 248000   Return: -2317.1   Time: 12:13:32\n","Num steps: 249000   Return: -272.1   Time: 12:14:59\n","Num steps: 250000   Return: -369.9   Time: 12:16:30\n","Num steps: 251000   Return: -381.8   Time: 12:17:58\n","Num steps: 252000   Return: -488.4   Time: 12:19:30\n","Num steps: 253000   Return: -268.2   Time: 12:20:58\n","Num steps: 254000   Return: -490.0   Time: 12:22:31\n","Num steps: 255000   Return: -317.2   Time: 12:23:58\n","Num steps: 256000   Return: -277.6   Time: 12:25:28\n","Num steps: 257000   Return: -296.9   Time: 12:26:53\n","Num steps: 258000   Return: -242.9   Time: 12:28:17\n","Num steps: 259000   Return: -716.9   Time: 12:29:51\n","Num steps: 260000   Return: -295.4   Time: 12:31:17\n","Num steps: 261000   Return: -303.1   Time: 12:32:47\n","Num steps: 262000   Return: -377.0   Time: 12:34:12\n","Num steps: 263000   Return: -267.4   Time: 12:35:41\n","Num steps: 264000   Return: -244.6   Time: 12:37:04\n","Num steps: 265000   Return: -356.0   Time: 12:38:34\n","Num steps: 266000   Return: -289.3   Time: 12:40:00\n","Num steps: 267000   Return: -305.9   Time: 12:41:31\n","Num steps: 268000   Return: -605.3   Time: 12:43:00\n","Num steps: 269000   Return: -254.8   Time: 12:44:29\n","Num steps: 270000   Return: -631.6   Time: 12:45:59\n","Num steps: 271000   Return: -381.1   Time: 12:47:30\n","Num steps: 272000   Return: -498.0   Time: 12:48:58\n","Num steps: 273000   Return: -443.5   Time: 12:50:29\n","Num steps: 274000   Return: -463.8   Time: 12:51:56\n","Num steps: 275000   Return: -540.0   Time: 12:53:30\n","Num steps: 276000   Return: -616.5   Time: 12:54:59\n","Num steps: 277000   Return: -309.4   Time: 12:56:31\n","Num steps: 278000   Return: -500.5   Time: 12:57:59\n","Num steps: 279000   Return: -677.8   Time: 12:59:34\n","Num steps: 280000   Return: -341.4   Time: 13:01:01\n","Num steps: 281000   Return: -236.1   Time: 13:02:33\n","Num steps: 282000   Return: -501.0   Time: 13:04:02\n","Num steps: 283000   Return: -538.5   Time: 13:05:36\n","Num steps: 284000   Return: -294.2   Time: 13:07:03\n","Num steps: 285000   Return: -694.8   Time: 13:08:38\n","Num steps: 286000   Return: -516.7   Time: 13:10:07\n","Num steps: 287000   Return: -323.8   Time: 13:11:40\n","Num steps: 288000   Return: -438.6   Time: 13:13:09\n","Num steps: 289000   Return: -497.1   Time: 13:14:42\n","Num steps: 290000   Return: -521.8   Time: 13:16:12\n","Num steps: 291000   Return: -506.2   Time: 13:17:47\n","Num steps: 292000   Return: -297.8   Time: 13:19:15\n","Num steps: 293000   Return: -244.1   Time: 13:20:46\n","Num steps: 294000   Return: -497.8   Time: 13:22:15\n","Num steps: 295000   Return: -261.7   Time: 13:23:45\n","Num steps: 296000   Return: -271.8   Time: 13:25:12\n","Num steps: 297000   Return: -555.3   Time: 13:26:46\n","Num steps: 298000   Return: -589.3   Time: 13:28:16\n","Num steps: 299000   Return: -318.5   Time: 13:29:44\n","Num steps: 300000   Return: -376.1   Time: 13:31:16\n","Num steps: 301000   Return: -404.7   Time: 13:32:45\n","Num steps: 302000   Return: -404.8   Time: 13:34:19\n","Num steps: 303000   Return: -466.1   Time: 13:35:47\n","Num steps: 304000   Return: -272.8   Time: 13:37:19\n","Num steps: 305000   Return: -328.0   Time: 13:38:45\n","Num steps: 306000   Return: -229.5   Time: 13:40:15\n","Num steps: 307000   Return: -383.8   Time: 13:41:44\n","Num steps: 308000   Return: -409.3   Time: 13:43:17\n","Num steps: 309000   Return: -396.7   Time: 13:44:45\n","Num steps: 310000   Return: -338.6   Time: 13:46:16\n","Num steps: 311000   Return: -579.8   Time: 13:47:46\n","Num steps: 312000   Return: -395.9   Time: 13:49:19\n","Num steps: 313000   Return: -459.4   Time: 13:50:50\n","Num steps: 314000   Return: -375.5   Time: 13:52:24\n","Num steps: 315000   Return: -626.1   Time: 13:53:55\n","Num steps: 316000   Return: -404.3   Time: 13:55:28\n","Num steps: 317000   Return: -548.4   Time: 13:56:59\n","Num steps: 318000   Return: -320.7   Time: 13:58:31\n","Num steps: 319000   Return: -385.2   Time: 13:59:59\n","Num steps: 320000   Return: -420.7   Time: 14:01:33\n","Num steps: 321000   Return: -739.6   Time: 14:03:06\n","Num steps: 322000   Return: -363.8   Time: 14:04:39\n","Num steps: 323000   Return: -517.5   Time: 14:06:09\n","Num steps: 324000   Return: -599.9   Time: 14:07:45\n","Num steps: 325000   Return: -370.1   Time: 14:09:14\n","Num steps: 326000   Return: -398.3   Time: 14:10:47\n","Num steps: 327000   Return: -381.8   Time: 14:12:16\n","Num steps: 328000   Return: -523.8   Time: 14:13:51\n","Num steps: 329000   Return: -729.7   Time: 14:15:23\n","Num steps: 330000   Return: -641.1   Time: 14:16:59\n","Num steps: 331000   Return: -461.0   Time: 14:18:30\n","Num steps: 332000   Return: -572.2   Time: 14:20:02\n","Num steps: 333000   Return: -627.3   Time: 14:21:31\n","Num steps: 334000   Return: -420.8   Time: 14:23:03\n","Num steps: 335000   Return: -748.3   Time: 14:24:34\n","Num steps: 336000   Return: -390.4   Time: 14:26:05\n","Num steps: 337000   Return: -495.3   Time: 14:27:33\n","Num steps: 338000   Return: -579.0   Time: 14:29:07\n","Num steps: 339000   Return: -372.9   Time: 14:30:33\n","Num steps: 340000   Return: -745.9   Time: 14:32:11\n","Num steps: 341000   Return: -725.5   Time: 14:33:42\n","Num steps: 342000   Return: -376.4   Time: 14:35:09\n","Num steps: 343000   Return: -416.2   Time: 14:36:43\n","Num steps: 344000   Return: -949.8   Time: 14:38:19\n","Num steps: 345000   Return: -648.0   Time: 14:39:56\n","Num steps: 346000   Return: -837.7   Time: 14:41:29\n","Num steps: 347000   Return: -556.3   Time: 14:43:04\n","Num steps: 348000   Return: -701.2   Time: 14:44:36\n","Num steps: 349000   Return: -516.9   Time: 14:46:09\n","Num steps: 350000   Return: -764.2   Time: 14:47:41\n","Num steps: 351000   Return: -835.4   Time: 14:49:16\n","Num steps: 352000   Return: -557.7   Time: 14:50:42\n","Num steps: 353000   Return: -455.9   Time: 14:52:12\n","Num steps: 354000   Return: -676.7   Time: 14:53:40\n","Num steps: 355000   Return: -610.4   Time: 14:55:14\n","Num steps: 356000   Return: -655.8   Time: 14:56:42\n","Num steps: 357000   Return: -2334.9   Time: 14:59:23\n","Num steps: 358000   Return: -748.5   Time: 15:00:54\n","Num steps: 359000   Return: -539.3   Time: 15:02:26\n","Num steps: 360000   Return: -659.5   Time: 15:03:55\n","Num steps: 361000   Return: -2295.6   Time: 15:06:37\n","Num steps: 362000   Return: -593.6   Time: 15:08:06\n","Num steps: 363000   Return: -2254.9   Time: 15:10:47\n","Num steps: 364000   Return: -508.2   Time: 15:12:16\n","Num steps: 365000   Return: -2248.5   Time: 15:14:57\n","Num steps: 366000   Return: -2312.3   Time: 15:17:37\n","Num steps: 367000   Return: -540.1   Time: 15:19:09\n","Num steps: 368000   Return: -2318.5   Time: 15:21:46\n","Num steps: 369000   Return: -2229.9   Time: 15:24:28\n","Num steps: 370000   Return: -2305.1   Time: 15:27:03\n","Num steps: 371000   Return: -490.5   Time: 15:28:35\n","Num steps: 372000   Return: -525.9   Time: 15:30:02\n","Num steps: 373000   Return: -613.4   Time: 15:31:35\n","Num steps: 374000   Return: -566.5   Time: 15:33:03\n","Num steps: 375000   Return: -797.8   Time: 15:34:42\n","Num steps: 376000   Return: -626.2   Time: 15:36:10\n","Num steps: 377000   Return: -635.8   Time: 15:37:44\n","Num steps: 378000   Return: -502.6   Time: 15:39:11\n","Num steps: 379000   Return: -520.4   Time: 15:40:44\n","Num steps: 380000   Return: -520.7   Time: 15:42:12\n","Num steps: 381000   Return: -523.6   Time: 15:43:43\n","Num steps: 382000   Return: -672.2   Time: 15:45:13\n","Num steps: 383000   Return: -447.9   Time: 15:46:43\n","Num steps: 384000   Return: -398.5   Time: 15:48:10\n","Num steps: 385000   Return: -489.5   Time: 15:49:37\n","Num steps: 386000   Return: -736.0   Time: 15:51:10\n","Num steps: 387000   Return: -491.4   Time: 15:52:36\n","Num steps: 388000   Return: -511.4   Time: 15:54:09\n","Num steps: 389000   Return: -534.7   Time: 15:55:35\n","Num steps: 390000   Return: -601.4   Time: 15:57:07\n","Num steps: 391000   Return: -571.1   Time: 15:58:35\n","Num steps: 392000   Return: -614.5   Time: 16:00:07\n","Num steps: 393000   Return: -628.0   Time: 16:01:35\n","Num steps: 394000   Return: -406.8   Time: 16:03:07\n","Num steps: 395000   Return: -627.9   Time: 16:04:36\n","Num steps: 396000   Return: -537.1   Time: 16:06:10\n","Num steps: 397000   Return: -566.6   Time: 16:07:39\n","Num steps: 398000   Return: -514.6   Time: 16:09:12\n","Num steps: 399000   Return: -638.0   Time: 16:10:43\n","Num steps: 400000   Return: -663.6   Time: 16:12:19\n","Num steps: 401000   Return: -619.2   Time: 16:13:50\n","Num steps: 402000   Return: -474.8   Time: 16:15:22\n","Num steps: 403000   Return: -529.1   Time: 16:16:51\n","Num steps: 404000   Return: -613.3   Time: 16:18:25\n","Num steps: 405000   Return: -662.7   Time: 16:19:56\n","Num steps: 406000   Return: -465.9   Time: 16:21:30\n","Num steps: 407000   Return: -674.2   Time: 16:23:00\n","Num steps: 408000   Return: -476.0   Time: 16:24:33\n","Num steps: 409000   Return: -388.0   Time: 16:26:01\n","Num steps: 410000   Return: -489.1   Time: 16:27:35\n","Num steps: 411000   Return: -442.1   Time: 16:29:03\n","Num steps: 412000   Return: -641.3   Time: 16:30:38\n","Num steps: 413000   Return: -500.8   Time: 16:32:06\n","Num steps: 414000   Return: -489.6   Time: 16:33:39\n","Num steps: 415000   Return: -501.5   Time: 16:35:07\n","Num steps: 416000   Return: -580.4   Time: 16:36:40\n","Num steps: 417000   Return: -529.1   Time: 16:38:07\n","Num steps: 418000   Return: -629.9   Time: 16:39:40\n","Num steps: 419000   Return: -427.3   Time: 16:41:06\n","Num steps: 420000   Return: -538.8   Time: 16:42:38\n","Num steps: 421000   Return: -494.3   Time: 16:44:05\n","Num steps: 422000   Return: -487.3   Time: 16:45:37\n","Num steps: 423000   Return: -521.0   Time: 16:47:04\n","Num steps: 424000   Return: -563.6   Time: 16:48:36\n","Num steps: 425000   Return: -387.3   Time: 16:50:01\n","Num steps: 426000   Return: -467.5   Time: 16:51:33\n","Num steps: 427000   Return: -460.8   Time: 16:53:00\n","Num steps: 428000   Return: -427.2   Time: 16:54:25\n","Num steps: 429000   Return: -422.9   Time: 16:55:56\n","Num steps: 430000   Return: -784.5   Time: 16:57:29\n","Num steps: 431000   Return: -595.0   Time: 16:59:04\n","Num steps: 432000   Return: -503.9   Time: 17:00:33\n","Num steps: 433000   Return: -537.0   Time: 17:02:06\n","Num steps: 434000   Return: -438.6   Time: 17:03:34\n","Num steps: 435000   Return: -497.8   Time: 17:05:07\n","Num steps: 436000   Return: -511.1   Time: 17:06:36\n","Num steps: 437000   Return: -443.1   Time: 17:08:10\n","Num steps: 438000   Return: -478.8   Time: 17:09:38\n","Num steps: 439000   Return: -699.3   Time: 17:11:15\n","Num steps: 440000   Return: -462.2   Time: 17:12:43\n","Num steps: 441000   Return: -593.7   Time: 17:14:17\n","Num steps: 442000   Return: -488.3   Time: 17:15:48\n","Num steps: 443000   Return: -600.8   Time: 17:17:24\n","Num steps: 444000   Return: -528.7   Time: 17:18:54\n","Num steps: 445000   Return: -798.9   Time: 17:20:30\n","Num steps: 446000   Return: -565.5   Time: 17:21:59\n","Num steps: 447000   Return: -603.8   Time: 17:23:34\n","Num steps: 448000   Return: -543.6   Time: 17:25:06\n","Num steps: 449000   Return: -504.3   Time: 17:26:40\n","Num steps: 450000   Return: -588.4   Time: 17:28:11\n","Num steps: 451000   Return: -480.4   Time: 17:29:44\n","Num steps: 452000   Return: -407.3   Time: 17:31:12\n","Num steps: 453000   Return: -411.2   Time: 17:32:45\n","Num steps: 454000   Return: -682.5   Time: 17:34:16\n","Num steps: 455000   Return: -570.2   Time: 17:35:51\n","Num steps: 456000   Return: -625.6   Time: 17:37:21\n","Num steps: 457000   Return: -503.5   Time: 17:38:53\n","Num steps: 458000   Return: -483.3   Time: 17:40:22\n","Num steps: 459000   Return: -501.4   Time: 17:41:55\n","Num steps: 460000   Return: -598.6   Time: 17:43:26\n","Num steps: 461000   Return: -570.6   Time: 17:45:01\n","Num steps: 462000   Return: -647.3   Time: 17:46:31\n","Num steps: 463000   Return: -484.4   Time: 17:48:05\n","Num steps: 464000   Return: -467.4   Time: 17:49:32\n","Num steps: 465000   Return: -539.3   Time: 17:51:05\n","Num steps: 466000   Return: -538.3   Time: 17:52:34\n","Num steps: 467000   Return: -409.7   Time: 17:54:06\n","Num steps: 468000   Return: -486.8   Time: 17:55:34\n","Num steps: 469000   Return: -475.0   Time: 17:57:07\n","Num steps: 470000   Return: -533.2   Time: 17:58:35\n","Num steps: 471000   Return: -525.6   Time: 18:00:04\n","Num steps: 472000   Return: -632.8   Time: 18:01:38\n","Num steps: 473000   Return: -650.1   Time: 18:03:09\n","Num steps: 474000   Return: -534.2   Time: 18:04:42\n","Num steps: 475000   Return: -594.7   Time: 18:06:12\n","Num steps: 476000   Return: -486.3   Time: 18:07:44\n","Num steps: 477000   Return: -611.7   Time: 18:09:14\n","Num steps: 478000   Return: -653.4   Time: 18:10:49\n","Num steps: 479000   Return: -453.7   Time: 18:12:18\n","Num steps: 480000   Return: -532.3   Time: 18:13:52\n","Num steps: 481000   Return: -562.9   Time: 18:15:21\n","Num steps: 482000   Return: -695.6   Time: 18:16:57\n","Num steps: 483000   Return: -587.4   Time: 18:18:27\n","Num steps: 484000   Return: -608.7   Time: 18:20:01\n","Num steps: 485000   Return: -630.7   Time: 18:21:32\n","Num steps: 486000   Return: -703.8   Time: 18:23:06\n","Num steps: 487000   Return: -508.6   Time: 18:24:34\n","Num steps: 488000   Return: -456.5   Time: 18:26:06\n","Num steps: 489000   Return: -652.7   Time: 18:27:36\n","Num steps: 490000   Return: -570.2   Time: 18:29:09\n","Num steps: 491000   Return: -583.0   Time: 18:30:38\n","Num steps: 492000   Return: -2284.3   Time: 18:33:22\n","Num steps: 493000   Return: -596.9   Time: 18:34:51\n","Num steps: 494000   Return: -565.2   Time: 18:36:26\n","Num steps: 495000   Return: -770.1   Time: 18:37:56\n","Num steps: 496000   Return: -699.3   Time: 18:39:33\n","Num steps: 497000   Return: -335.6   Time: 18:40:59\n","Num steps: 498000   Return: -511.9   Time: 18:42:32\n","Num steps: 499000   Return: -471.1   Time: 18:44:01\n","Num steps: 500000   Return: -662.9   Time: 18:45:36\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x8qybjQvdXgv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600138095830,"user_tz":-540,"elapsed":67595764,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"cdba0488-b043-4966-8374-1ee099661e3b"},"source":["% debug"],"execution_count":21,"outputs":[{"output_type":"stream","text":["ERROR:root:No traceback has been produced, nothing to debug.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sXz2BSmSEF0P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"status":"ok","timestamp":1600138096771,"user_tz":-540,"elapsed":67596691,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}},"outputId":"48fc1787-8cd1-472b-96ba-68033968da16"},"source":["trainer.plot()"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjkAAAGoCAYAAACkOfQWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd7wcVfn/P8/u3l7T200hhBSSkBBCh4ACEkApIlIURb+IiDQBERUUEIEfIkVEBBHpndBrCIQQkpAGqYQkpLebm3J73Z3z++PMmTkzO7Pl3r13d2+ed1557d6ZMzNnZnfnfOZph4QQYBiGYRiG6W4E0t0BhmEYhmGYzoBFDsMwDMMw3RIWOQzDMAzDdEtY5DAMwzAM0y1hkcMwDMMwTLeERQ7DMAzDMN0SFjkM00UQ0UVEJIhoZhqOvcE89vGu5cebyzd0dZ+ShYhuNvv6eLr7kkqI6HHzvG52LR9mLk9rnQ8immn24yLX8ozoH8PEgkUOwzAph4iuNkXJsHT3hWFSBREFiOgSIppLRNVEVEdEXxDRb4koN939Y6IJpbsDDMN0S64GMBTATAAb0toTprNoA/B1ujvRVRBRDoDXAJxqLmoFEAEw0fx/DhF9WwhRn6YuMh6wJYdhGIZJGiHEViHEaCHE6HT3pYu4DVLgNAO4CEAhgCIA3wOwB8ChAB5OV+cYb1jkMAzDMEwMiKg/gKvMP38nhHhCCBERkrcA/Nxcdz4RHZSeXjJesMhh9ln0YFwiGkJEjxLRZiJqJqL1RHQ3EZVp7YmI1prbXB5n35+Y7W6P0eanRDSPiGqJqIaIZhDRVJ+2cQOEOyuw2QwwfYCIviaiRjMOYRER/Y6IilxtbzYDUYeaiz5Wwamp7pt5/T43+1NLRB8T0Ukx2k8hovvNbbYRUSsR7SSi94joBzG2swKDiShoxhstMa/FHiJ6i4gmx+nr4UT0ptm+noi+JKKriKhD92Ai6kNEdxDRMnO/DUS0nIj+SkQ9O7LvBI7tG3icomtWTER/IKIF5u+jmYjWENE/iGhwkn3NN78jgoi+G6ftKrPdVdriswHkAagB8Ih7GyHE6wBWAyAAFyTTN6aTEULwf/6/T/6HjBURAC4GsNN8XwegyXwvAKwBMEDb5g/m8kUx9rs/AMNsd4C2/CJz2UwA95rvIwD2au0FgOs89nm8uW5DjONa+49xrscns18A33ddjwbIWAT191IA/bT21wHYYZ6XgDTj79D+T+vA53Wzuc/HATxqvg9DDjyqPxEAZ3tsW6y1EQBqXdsJAA/7HPdxc/1tAN4z37ea3xW1bROAI322P8/sp2q7FzKeRQB4Wdv/za7thqltfPZ7DIDd2n5bXJ/VJgCjUvA7mWnu76JE+5eCazZG+84K83rVa3/vAXB0kufxhLntszHaTNK+V/215S+by9+Ise0DZpv5Hb3m/D91/9mSwzDA3ZAD3rFCiBJIP/uZAHYBGAF5c1Q8DjmQTophlv4Z5BPdp0KINR7rD4YMzP1/AHoKIXoAGATgGXP9XUR0TIfOKAUQ0aEAnodMUPgrgAohRBGAAgBHAVgIYDyAJ9U2Qoi7hRD9AWw2F31fCNFf+//9FHTtDAA/AvArAKVCiDIAwwHMgrROP0BE7qQKA3KgOgtALyGE2q4HgMshB9BLiOicGMf9NWTcxbkAis3vygQAywHkA7jfvQER7Q/gfwCCAD4AsL/5eZcBuBbye3ZmsheAiIYCeBNATwAPATgA8nMpgvxMPgAwGMA0Igomu/8U0p5rVgbgHUhr4Etm+3whRDHkA8SzkJ/bK0RUnkRfnjVfTyeiQp8255uvHwshdmjLDzRfV8TY/0rzdQwRURL9YjqTdKss/s//0/Uf9pNiE4ARHuu/BfvJ8Rht+evmsns9tglADvBeT74Xafv7j8e2BOAjc/2HrnXHo4stOQBmm+t+6XO8ngC2mW0mJ3K8Dn5eN2vX70ce6wdCWjMEgClJ7vtCc7uPPdY97vU90NYfoq0f4lr3X3P5KsiB2r3tjdq2N7vWDVPrPLZ72lx3h8/55AJYYrb5QQev+0yf73Os/nXkmt2G+BaXd+Fj9YyxTRBApbnd+R7rCdL6JQD8zLVur7n8ihj7P0M7p5JUfe/5f8f+syWHYYAXhRBr3QuFEB8DmGP+qcdsPGq+/phkWqnOSQAqIM3yL8U4ZlSsjpB3yjvMP7/d2TEVsTAtEEcDqIYcqKMQQuyBHGwAed5dxSbYT+V6f7YBmG/+OS7Jfb5pvh4Rw/LxqRBitsdxFwHY4j6u+TSvLFf3CiGaPfZ5H4DGZDpqWiHOgbRO3ePVRgjRCmm5Arr2s3GT1DUz+an5+vcY+1Wff8LnJoSIAHjR/PN8jybHQFq/mgFMc61TsWdNMQ6hf47FifaL6Vy4Tg7DyCdVPz6BdM1M0pa9A2nBGAiZPqrfEFWWxQtCiAaffW4SQqz3WTcb0h0WhKy98VHMnnceR5mvxQC2xLC+q5t5UoGgHWShKQi92Gq+9nCvMF1YP4UUCBMgLVHuAm755ra7PPa9IEaftkKKW/24wwEod8onXhsJIeqJaBGAY2Ps280hkP0WAJbF+GwKzNeu/GzcJHXNzIDiCvPPd7yCmk3U55bsuT0L6Z48mYh6mkJdoQKG3xFC1CS5XyZDYZHDMPbAGGtdH7VACBEhObXAHyDjb6YBgGl5OcNs9lh7jieEaCKivQB668dMAwPM1xCAfgm094tx6AzqYqxT1hKHhY2IigG8D1u8AfKpvArSIgLY51kEb5GT7HH1z29bjG1jff+8UJ8NIfM+GzfJXrMB2vu+CezfOjcimgbn56t4QQhxFQAIIeYS0XoA+0FmTP3H3DYE21obZSWEDLgvhy0cY/YFMsaLyQDYXcUw7UPFWkwlWUMDkE+CeQC+EkLMTVvPUoO6NywRQlAC/y9KZ2cT4CbIAXAXpDWnnxCiUAjRV8hA6UFa20wPGlWfTU2Cn83x6exskuhjUo8Ezm2Y1r4npOhz/y+Dk+fMVz3V+yTIB4taAG979EuJ1IEx+q7W1QshYok7pgthkcMwid24qvSFQoh1kK6kEGTQKmC7qv7X3uMRkXKXuI8ZNl/zY+zXfTPvCJXmazpdHalEZU1dIYR4Ugix07U+EYtIsuifXyLfsURRn00paXWcugmV2vshyWwohDg+QQGuLDVTiEhdexWjM80ndkplTo2N0QWVgfVVMv1mOhcWOQwDHJfAusUe61QA8s+IaAJkangYWkq1D0PJf+LKYyDjcQSAL7Xl1eZrX/KfCPDQOMdNBmWJ6klEh7dje+UCyhSriIrz+MJn/YmdcMx1sD+3KV4NzGKKMYviebAQ8ntGADyLR2YrZqyaEjqndNIxVkDWdwoAOM98sFBp/F6uKgD42Hw91mzvhQqCnpGSjjIpgUUOwwDnEtFw90IimgKZYQR4Z0q9ClmMbQyAB81lbwshKj3auvm9x/EIwA3mnzNcQZGrIdOjCTLY2b3tCMgYg5QghFgFYJ75510eWWT6sQuIKM+1uNZ8TaaOSWeiAknHu1eY8Tp/TPUBzeDoV8w/r/a4RgBwJZKMmTFdIWq/txJRiV9bIgqZ55dNPG6+XkdEg/wakaS93y8lZs6H/D2VQBar9Av0nwb5+yuHLB7q7sv3AIyCfDh5zr2eSR8schhGVmJ9l4iOAgAiCpg3LZWCO10I8Zl7IyFEC4CnzD+VGIoVcKyohSw8d7tyN5hxPU8AOAHyRnmL61itkPV5AOBeIjrG7GeAiL4DYDpip7e2hyshb+xTAMxQxzT7GySi8UT0J0iLxQDXtqpo2vkxnny7kunm6z1EdJwq1mYWPJwBoFcnHfcOyADbMQBeI6L9zOMWENHVAP4CW4Alww2QVX9HAphDRFOVEDUH/wOI6BrI+jzJWorSzZ2Q36nekOf2QyKyAn5JTsFyCaR1NelCiibPwazvBPuB40UzzTwKIQsDqsKFdxHRharUABGdCttF/ZwQYmk7+8R0AixyGEZORdADwGdEVAeZGfEGZHbMWth1O7x4VHu/AzK9PB5fQNZH+T2A3US0BzKwUcX2XO9VW0S1h4yT+RQyc6UBMmuoGrJYXsoQQiyArBBcA5ni/CmARiLaBSmolkKKsf6QA4aOqq1zDoAaknOCbSCi51PZxyS4ETLoeDBkyYBGIqqHrKszHp0035AQ4hvIDLwIpGtpnZk9Vws5tcdrsMVrMvvdYO5vG2SdmXcBNJifTTOk5e/vkBWC/dKwMxIhRDWAkyFjW4YAeAFAHRHtIqJGABshZ/ueiHaemxBiEwD14HKw+ernqlLcCPn7LoB0STcQUQNkoHIvyHT5S9vTH6bzYJHDMFLITIa0wtRAxsRsgBwkJgshtvttaPr3V5t/PiWECPu1dW33G8jBbxFk8HI9pN//FCHE3T7brANwOORTaJXZzy2QUy4cDdtFlDKEEO9CWgtug3xyVib7WshCiXcCOEQIsdG13UeQAukTSEE0CLJMf3+kAfPaHQZZKXgn5LWrhpxK41AhxAedeOznIT+ft81j5kIGsl4N4Ido/0C9AMBoAL+D/CzqIT+bRsi4nX8AOE4I4VmjJ5Mxi3MeDOAyyN/FXsjA+jCkuH4EwGmQn2d70UXNN0KIz+P0qQ3StXUppCtXVdf+EvIzOIazqjIP8q+pxTDdG5Izeg8F8C0hxMx27mMwpCAKABhjxrIwDMMwGQBbchimY1wC+Tv6lAUOwzBMZsEih2HaCREdDOAq88/70tkXhmEYJhqe1oFhkoSIZkPOS9QfMqV7FmQ6OcMwDJNBsMhhmOSpgEyZrgTwFoDfxZgwknFBRAuQXCVla+4hpn2Y5RHcM2vH4/tCiDmd0R+G6So48Lib0Lt3bzFs2LB0d4Nh4rJs2TK0trYm3L5Xr17g73bHqKurw+rVq+M31Bg5ciRKSnzrDDJMylm0aNEuIURKJyZmS043YdiwYVi4cGG6u8EwDMMw7YKINsZvlRwceMwwDMMwTLeERU6GYJbn/w0RrSKiZrNC7N/NCfwYhmEYhkkSFjmZw70A7oGshHoF5ISQVwJ4U80XxDAMwzBM4nBMTgZARGMhhc00IcTZ2vL1kKXZz0P8eVUYhmEYhtFgC0FmcD5kvRV3Qbn/QM5D8+Mu7xHDMAzDZDkscjKDQwEYkDMiWwghmiEnfzs0HZ1iGIZhmGyGRU5mMBDALiFEi8e6rQB6E1GuewURXUJEC4loYVVVVad3kmEYhmGyCRY5mUEhAC+BAwDNWhsHQohHhBCThRCT+/RJaf0khmEYhsl6WORkBo0A8nzW5WttGIZhGIZJEBY5mcE2SJeUl9AZBOnKSrwOPsMwDMMwLHIyhAWQn8Vh+kIiygcwEQDP18AwDMMwScIiJzN4AYAAcLVr+S8gY3Ge6fIeMQzDMEyWw8UAMwAhxDIiehDA5UQ0DcA7AMZAVjz+BFwIkEkDNY1tAAFlBTnp7gqTJDtqmlFemIP8nGC6u8IwaYUtOZnD1QCuAzAWwIOQVY4fAPBdIYSRzo4xmcH6XQ0d2r6+JYwdNc3xG5pMuPUDnHLfLLSEI1i0cU+Hjp0KWsMGPl3T/lIJ4YiBuua2qOUt4QiemrsBTa2RpPYnhMDvXl6KT1bbfVpXVY9rX1yCqjqZLGkYAh+urIQQIua+zvn3HFzyZGyv9PaaJvz62cXYUdOM6kb/EL3mtgiOuGMGfj9tWRJnwzDdExY5GYIQIiKE+LsQYpQQIk8IMUgIcY0Qoj7dfUuEhpYwht3wNh7/bH26u5J1VNY2Y3tNE15auBmNrWHPNtNXVuJbd8/Ee8u3t/s4v31pCY64Ywb2NLRib0Mrvv+vz3DZM4s82y7bUgMA2FbTjH/PXIezH5qL+evTK3TufHcVLvzvfCzfWtOu7W98bTnG3/wBIoZTcNz8xkrc9PoKvL9iR9Q24YiBnzw2H3O/2Q0A+Olj8/Hk3A2Yv34Ppt73KV5YuBm3v/0VWsIRhCMGpt7/KV5ZvAXPzd+EDbsa8Pn6Pbj4yYVYsGGvb7/CEQMLNuzFB6YY8vsOXPbMYry9dDu+c+8nmHjrdDzz+caoNu8t34ET/v4JAOCNJdsSvTQM021hkcN0iBXbanDDK0tRWSstBI/O7nyRI4TAy4u2oLktuSfvTOXw22fgyDs+wm9fXoq73vvas80Xm+Qg+crirfhwZWXSx6hrbsPmvbIKwUMz12LaF1uxeFM13lm2A02tETw2e71j8H9zqT1ALtggxc2HX8njCiHwTVU95q3bnXQ/FJW1zdjTkFzC4CLzGtQ1e4uAeDy/YDMAp0WssTWM5+ZvMt9Hf5/2NLRi1uoqnP+feWiLGJi1pgrTV1bikqcW4uvKOgDAzrpmjLrxPRz3t5loDUuj6z3TV+P4u2fi4VnfAAB210eXwXp63kZ8ubkaq3bUWcv+99kGHPin97GzVlprwhG5v+a2CL7YVA0AqDXPf87a3ahpanOIvj++ugxbq5sAAD0Ko+qHOmhui3TYOsgwmQ6LHKZDvLlkO55fsBnrquTNMo5VPiV8sroK1720BHe+u8q3TUs4gk27s6+0UEOL9wDeZAq66SsrcXEct8ZPH5uPaYu3AADunb4a17z4Jcbf/AHW7pRGwU17Gi2BWNGjALe/8xVufWslZn6909rHl5urkZ8TsN4DUuR8vm439vv9O7jyuS9wwytLAcASuMlw2TOLre0TRbmaaj1cTolQnCdDEFdss0XBJ1/brqa9mgtIfQ7617mqrgVCAJ+u2YXqxjbceNoYczvZHyUuBpTlW9vMNPdf0xTd59veXokn5mzAwg22hez5BVJwbaluwsRbp+Om11fIv/c2RW2/q74Ff3p9Ob77wGxsM489sLzAcT6tYQNPzt3gaQG8452v8K27Z7br82P2Xe7/cA1e+2JruruRMCxymA7xTZUcOJebA4fRBSpHPcnu8ng6Vlz/8lJM+dvHScdZpJtSnyBft9XKywrS1BrB1uomfL5+N1Zsq0V1Yyvun7EG0xZvNfchrQIRQ1hWGyLbUpMTlLcDwxBYsbUG359UgdxQAPXmgL+3oRV/MgfdFdtq0Ro2MOOrShx++wzMWh0dK7O3odXX2ra9uimm2ykcMWC43Er1zXY//HDHvrSGDasPKgh35fZaa/07y3egV1EucoMBK85l+dYaHHTLB1i+tcZh3Xp50RbrfYCAC48cioOHlEf14ZRxAwAA/UrtslfrdjVg8x5bdDe1RtDcZmDTnkZ8U2VbU7ZVS8HxjSlIlZVJiRid3Q2t2FkrfwNPzZOuq511zThwQCkuPW5/RAyBhRv24E+vr8ClTy8GAKzaUYvP1u4y30sL0qtfbMXanfX4zr2fYFd9C/4xYw0+WLEDq3bURh3TzTvLtmPJ5mpU1jbj3WXtd6VmIkIItISTu3+0hg20Rbp3COW9H67G1S98me5uJAyLHKZDWCLHHLC6wpKjBr8AkW+b95bL+IpIV3QohZT7ihznjXNNZV1Um58+Nh9H3/mRJWLe9hl0IoZAWLuGygqnrEXrdjWgoTWCgweXY0z/Emu7cERYLprcYABhQ1ixJss0wbK3oRWfr9uNg/8yHRc/4W11qm5qw7aaZtQ2t+Ge6atx0M3v43PN/XXWv+bgvg9XO7ZRbiplOdm0u9EhhN5bvgOT/jId5z8yD/dMX433V+zAlLs+xv89sQBtEQN7GqQg+GBFpWW9WLRhD445oDd6Feda+/18/R5EDIEFG/Y4RM490+3+9CvNR14oaFmH8nMCOHRYD5w9qQLXTx2FaZcdhaP27221f2TWOhx718fW37vNvmza04hqzcqjBOWKbbbAEEJYIqdAy5baXd+CPNPa9sisdbjmxS9RWduCqeP646yDBwEALnj0c6v9eY/MxdT7PsWPHv0cT8zZYD0sPDFnA/4xYw1WV9bjtS+24p7pq3HJU4sw9b5PscHDnbV2Zx2G3fA2Fm3ci8ueWYwzHvwMf3v/a/zqmcX4WLMGdjXbqptw2TOLPF2DgHRNvrJoS9wgcMX9M9Zg1I3vJeUWn3LXxzj7oTkJt0+EnXXNeGz2eny1Pb7oBKRlVVlfGRY5TByWbamJCtRUtIYNbDRdQmqQE5qB3/0kniqUtSgY8Bc5LWHbapFNlBXmYNHGPVi6xXmTclukVu+Mjkefb1pkwqbI8bsphg1hfTatYQOt5pOnCnhV7pxxg8owdlCZtV2L9oTaGjFgCGENGLrenHr/LJz7yDwAwGzTaqBYV1WPq57/wop/WVNZh3nrdqO2OYzH52wAID+zldtrHRaX+pawJcL2NrZi6ZZqTPnbx7hKe6KcvbYKexvbMHfdbvxjxhr88qlF2N3QgoUb9mJbdRMMAZx20ABs3duER2atQ02jFFpjBpSivDDXYckBgFXb66zv2pkTBzrOozBXio2iXClySvJz8NKlR+HvP5yA/JwgJg3pgZ5F0TEx89btRnNbBHsbpLCpqmvBdg8rzUpN5Gze04Rt1U0IEDDe/DzGDizF3sY27KhpxuShPXDw4HLLYlfRowCj+pfg8m+NQE7Q/mDmrbPdYn9+YwW+2l6L3sW5qKxttoKUV7q+M7rYAoBj/t9HOPGeWQCABz9eay1XP8WHPv4m6ly6ij++ugzvLNuB17/0Drh+e+l2XPvSEkcMVCzu+3ANAOCFBZs9rcbvLd/hyGATQmBHbTOWbqnBu8u249C/fohfP7vYWv/V9los2rgXEUNg0cY9CYutf360Fre+tRJXPf9FQu0v+M88nPngZ51ixdYtWyr+LNNhkcP4smDDHnzvn7Px6KfrPNdv2tNgiYhK02yuNEV1YyuG/+EdPD0vOgOko6hjxDDk2G2zTOSEAgGc/dBcnP7PzxzLm1xPk7olZ+p9s/C39+34JCFsoeOFIWxLTnWjbUVobI2gsrYZy7fWIEDA8D5FGDdQDqoBir6phQ1hiQB1v65pbLO+C178ftoyxyD09Y56y0KjYm121bcgYgjsrLP3M0cTS3sbWjHjK2kxeHPJNsvaUFXXgp5FufjgN1Nw4RFDcduZ43DbmePQEjas9ucdOhjDehdiy95Gyx0zqn8JehblWC5AS+TsqLWu4SHDejrOIy9kipw8JXKiS455iZzzHpmHk++bhS17bdfVim21GN6nyNFOjxua/lUltlY3o19pPgaUy3ifAweUAgBWV9ZheJ8ivPyro1BkCi8Vl3PdyaOw4papuH7qqKh+KKaO649hve1jLzWz6h68YBICBHxdWYeGlrBpJWp2xAbpLkolWpWFyovfT1uGB2as8V3fERpbw/h0jfyOLNjgnQWoXIHba6JF5ZrKOsti897yHY7v25/fWIHLNbGiuPTpRXhu/ibLcrSr3naj/uqZxaiqa3Hs55T7P8XZD83Bf2fLbMVnPt+EBz9e64jJchMxBN41rdLbtfIPQnvAAIC2iIHnzYw+5f789yff+FqhGlvDOPSvH+IdD2tvOGLgov/N94zj0mPLHvtsfVbcX7kYIOOLyqZZ5hM7sdm84e3Xu8jK0lA/PDVg3PXeKvz4iKEp7ZcaWGO5qxTZ5q7SY5quf3kJfnvyaPQpyYsSOV9ursbXO+owfeUOrNpRF/V0ahjCYVXTCUdscaJfn8aWCA6/fQYAYFivQuSFglbMyfA+xVbgsiJiCGtwqzVvfsoa40duyPlctbqyznpKVmJH1fLRA2If+2w9BpUXoCgviL2NrVi3qwF5oQBawga+3FyNYb2LsHlPEw6qKMPIfiX4y5njANhi4da3VqIkL4QxA0rRv6wAM77aifdXyO/3mP7SkrO9uhYrttXgm6p65AYD+Lqyzjo/d0HEXsVSwChxU5If7Wbs5SFyAGDj7kY8a8baAFLAHtC32HIbAkBDawT79ylCaUEOnp63Eb2KcjGwvAB9S2Scz9iBpXhpkRT8vYvlssd/fhhueXMFDhxY6rje/UrsQOj+pfnYoV3X/qX56FmYi3WQx1af8dBehRjWqwird9Thw68qMW3x1qig+LA2wKnBzytDDZCDsIovuuKEAzzbALZQ1a20s1ZX4e2l2/HXs8YhFLS/P4s37UVFjwL0LcnHtupmhA2BvFAAn63dhbveW4X+Zfm48IihIPM+saNW3q+2u2pFNbSEcdK9s3Dk8F547pIjcNPry9HsOo+1Oxvwl7dWYsOuBlxxwgGYONiOxTr3kXkgAD84pMJaNnloD/QpycNHq3YiYgjM+MrOiLz9HflA8rf3v7au29EjeuGRCydbohmQoQBf76hDVV0LRvcvwaodUog1tITxq6cXo7a5Df/+8SEY1rsIf3x1GV5cuAVHj+hlbX//jDWoaWrDzaePtZZNX1mJf81ciz9990BU1bXg188uxvo7TnOc69vLtmPm11XYtLsRU834MkWtJnLufHcVxg8qw9EjeiOTYUsO44kQAh+Yg4AeMKlTZT6xH9C3WNtOvqobYG07031jYcfkJN42W9Cfzl5cuAV3vy9Tyt1PZMu31uDk+2bh7g+ccSsKacnxPoYhBMIRU+Ro10fPLtq/j/xMxwwoxZuXH4OTx/aL2k/EEJaYXberAcu21OCRWd+gokdBVFuFHlNCJN0juzWRs2xLjWXir6prsfq3ZHMNTh7bH31K8rBxdyO+3FyNnx+zH/JzAli8aS/CEQOb9zZicI9Cx/FGaN/Nt648Br2L8zCgNN/6fvYsykW/0jz0KMzB3sZW/OHV5ehbko/7zpuI5jYDt7/zFQAgSIT//exQPHD+wbj4mP3w/84+CABQlCfPpyQv+nmxh4fIueakkRhQlm9ZHRQDywuQG3Tejgf3LMSvjtsf63c1YOHGvTigbzGO3L8XDhvWE6P620JGiZxDh/XEW1cci1KX4OpXaoucf5x/cFQfyz1SzfuV5mNkvxJ8XVln/YYXxqj1owZrtxA67R+f4pnPN0a5vRT6Z1zfEsaxd32Ed5dvR3NbxHK3PPbZerywcDMenmVblOua2/D9f83BYX+dgXP+PQc3vbYcAHDimH6obQ7joU++wZ9eX4Fb31pp/aaUJWfJ5mp8tnYXxt/8PpZsrsYaU9jNXbcbO2qaUVXXgjrzPJRY3lXfgv/OXo/5G/bg188sxv8+W2/df9burMeanfW4w8z2/Oja4zfrAIsAACAASURBVPDyr47CuEFlaAkbePWLrbjkKWc9qt7FuQ6ryGdrd+Pe6autoptVdS044e+f4LJn5G/hdNNduruhFf/5dD0Wb9qLLXubrDixOWYdp8/WytfvmzFZj8/ZgJvfWAHDEJi/fg9+8eRCfLGpGrNWy++fENH3FiVG+5ZGzxftzhLULZKZCoscxkFVXQuue2kJXlq4Bet3NaB3cR6+2l6H1rABIQSen7/J+lFUmYPTAf00kWO+tmiBsuEUZxuocTlWTI4iGyw5ys0A2OemaDZ94O4bUTztZgiBiOF93XU3ky5yNmop97rFZXxFGUKB6FtF2BDYbYqc6Ssr8b1/zkZDawR/+8EEez+ugbtAO9fR/Usxf/0e61xqm9pw1fNfWC4RQ8h4CMMQaGqLoDg/hPLCXKzZWY+IIXD8yD4Y0bcYT87diIufXIi65jAG93QKrLxQEL86fn/884KDMbSXdMv0N1O8+5TkYeZvjwcRoUehDDxesrka5x02GKeOH4ATx/S1Bo9gAPjWqL743oSBuPG7B1ouIfXk7bZQAdGWnH9ecDCuPOEAnDy2v7lPsmJ7ehTm4pYzxjraD+lZiO+M7Y+7fnAQfnb0MPz+lDH49uh+ePHSIx0DUO+S6MFIR8/y6utqmxsMoGeRtxVqeJ8ibN7TaLkDd8fIalMCWVkcl2+twX0frsaKbbX446vLMX+9HVTepsWAHfrXD3HLmzJjr6EljOY2A7vqWvDHV5dbLqJh5uf2zLyN+MIUtMpyWZofwo7aZsw1g9YnDJbuVSFkbNL/PtuAD7/aiabWiGUhfHHhFvzo0c9R1xzGW0u3YXWlXqfIrvMVChAuOGwILjt+f+vv3548Clurm3DLmysdv8GXLz3Sel9hCm1l/Xtbqzm15M/fwRM/Pww3nnZg1DV8dPZ6nP3QXMxZu8t6uAHk5zeyb4l1Xb/cvBcHDizFCWP6Yu663aisbcbW6iYcN7KPtc013xmJNy8/BoAUOrPWVOGHD8+11uuFL921uTbskveBrdVNVsB7xBD4dE0VdpsuuWtOGglAxotlOixyGAdfbq7GG19uw/WvLEWfkjz84dTRaI0YWLOzDm8t3Y4bpi3DPz+SAYc7a5tRmh9CX80crgRNa8QelDf6WILai2EFuyYgcrLAkqO7Qtz9VQOC7q6aUFGGeIQNgYjPqRuGQNhDAOmF4cYNch4j5CEoDc2So7j0uP1x2H49rafcPG3w/3RNFbZqMR2HDethvR/SsxB1zeGoOKs/vLoMn5uVlgtzg+hTbA/SBw/pgQtNV6iqR+O25ADA76aOxncPsgOHVR2bXkW5ltVDL5w3aYjsl+468HONquwqr7XumBz1O5k6rr91zCE9ZX/LC3Nw/mFDMOPa4zCsl1ym1v1w8mD8+XtjUVZof090a1lvH7eY+7gVPQoc4uj6qaNwxsRBlsVppPawEggQBpYXIGwILNwYbcFRfVMoK0lbRKA1bODch+dagbsAsKbSdnWqWCs1gD45dyM27Gqwih2GDYGddc2orGs2/5bf1W01zTjrX3PwxpJtVlD9+7+Zgl9O2d/a9/hBthtJBV7/4smFOOtfn3laHTbtacSayjrkhgLoW5LniCEcWF6AYIAwyLzWJfkhS6AqfnvyKCy+6SRMHtYTJ47ph9H9SyzBq37XH39dhRPH9MO835+AsoIcHDeyD4b0iv6eKi549HO8sHAzhppthLCF7C+fWoR56/Zg/KAyHDm8F6rqWnD47TMgBHD2IRV45VdH4e0rj0FFj0KMryjDjGuPAwA89tkGxzFWbq9FYW4QP5xcgcfnrMfDn3yDj7/eiZZwxLrum/c04ag7P8KNry3DH6Ytw4X/nY83l8o4ne9NGIhB5QVsyWGyj5MO7Ic3rzgGN5wyGs9efLg12K2prLeehJTffWddC/qU5DkGaZXqrFtyWtpSbclJxl2V0kN3CroVwF1nqM1UKk2t9omUF+bGtWIZRmxLjpdxbcNuKXL+fs4E/HLKcMe6gMfxwoZwpOteecIBuOGU0QgGyHKhqIyshpYwLvzvfMeAefhwO35geJ8itEYMz6J5ykpQkBPExcfuh9H9S3Du5MHIDQVw7qFD8On13wIghcJRCcQH9DEHDD1Y+Nuj+1rvJ5jxFvo1DgW9r7fKrvIS3NEix3Yr9SzKRc+iHAy2RI5su3+fYpSZ7ys8BJsiLxTEs784HGMHlmL0gFLfdoDM2PvLmePw7MVHoDDXPufLjh+B3FDAEnjquijLohrcl2yuxrhBzmOUFeRg2mVH4cQx8rpFDIFS83o2toatjD2Fnp109J0fYfnWGmyttmNj7pm+Gr99aQkA251qu1Sd57NiWy0e/mQdSvJC6G+61RS6+KvoUWjFyazaUYcGLc7m6f87HN89aACWb63F15X1GNGnGCeM6edoM8i01g3SrHb9SvNxq2ZxO6iizPqc//OTQ/DOlcc6rpF1ziN6WRZEABhY5rQ4emnoe8+diONG9sE9P5yI3sXO79LoAaVRsTDDexfhkKE9MHZgmWNZv9I8R5C4sh4OKi/AiWP6wRDAHe+uws8fX4A7310FIYBJWv2nt5ZuxwsLZbVwFeNWVpCDwT0LrLjMTIZFDhPFqP4luPS4/XFAvxIM61WEUICwurLOquFRbMYh7KxrQd+SfMcTZmvEQGvYcKQbp7pAoIqzCXaTwOOIENaA6u5um1bWX5ETpLgzg4cNw9eKFfERQEq8ThnZxxHgCXhbcgC7Zg3gtASoOJDWsIGWcCQqNRlwCovhveW2u+pbMbx3ES49zn46VwNkQW4QFT0K8d7VU3Dn2eOt9YN7FuL9q6dg9u++ndCM6Wqw0c37w3oX4TcnjsTUsf2tfejfLz9LjhowvC5PeWEunr34cEw1n/7V03gwQPjNSSNx7qFDLItID+03pMSC21ri5qj9e+PtK4/1zOJyc+ERQy3rQShAjnPvaYocwwC+/NNJ+OyGbwOwB3dACrPD9rMzzMoLczBpiKwLpFAuvD++utwS54D8vu5uaHXs7zcvfOmw6m2rbkK9WcJAWiFtl6phCPQvzcdVZsDyf2evx9bqJoyvKAMROWICdUtVv9I83HL6OMy87ngrRmWg+dkfuX8vHFRRhq3VTZi1ugqHD+8ZVSZACSZlCdvPzEL7yZHDcMMpowE4PyMicjwM6N9FPYMNkIIyGCAEA4R1t5+KZTefjB9Otq/lgxdMwqQhPfDEzw/DMQf0th4aFEfv3wuDexZijvlZeR1D9emw/eTDxKDyAnxz+6m4/mSZbbd5b6MjSH1En2L8z7T4TBxsW1n1h1QVHF+aH8LgHoW+8ZqZBGdXMTHJDQUwrHcR1uysx1DzB11s3oR31jVj0pAeUQNLQ0vY8cNItc6wU8iz2121p6EV5QU5iEQEpo7rj7eXbo8SZSrjSHdXBYhQXpATc+4nqY1iiRzv7YIB8swKSiT+6YC+9hP18aP6YOV2mYL9+hfbPKdiyM8J4soTDsA/ZqxxCKTrTh6FU8cPwMFDyvHLpxZZM3oX5upBy87+jNKKFsZj7MAyvHPlsRjt2uaqE51ZP7r1Jt75+4mgo0b0xiHDeqCypsVybQGw3GxPmNlo5QX2NVcuNHd8UapYfdspDsuBcldFhHAEIetTRBxUUYY/njoGs9fuwkX/W2BV5tZ/+4PKC7BqR11UEcq2iMD2mmZMGlJuTX2xZme9I03+6x111n0iEhGOgpVhQ1jC8PUvt2KDGTv217PGO/oPSAtXeWEOqhvb0Lc037p/3XPuRNx8xlgU5gTREjYQDBDOnlSBf360FrXNYVx2/Aj0KclDKEDWcZUla8yAEvzx1DE4a9Ig6zi/nDIcZ0wciAFl/p9RuSZc3W7UYIAsy14gQCjOC2HC4HK8uFBW1T51vNMtlq8F7H9z+6nW93FgeQEe/9mhmPl1leP7pXPjaWPQFjZw9IheCAYIPzpiKF5evAVnTBjkEJ6PXXSoVbDyzIMH4p1l29GvNA/LXUHjxXkhhIIBVPQoxM66FjS3RRz9yzRY5DBxGdmvGCu31VqDX1FeCEII7KxtQV+XuwqQWRJ60Si/VOb2Ei+FvK0TrUipora5DUfeMQMPnH8wIkIgx7xpufurhIwu1kJBcljPvFCWmtL8UFSGm58lB5BZH16uqViDvEpvHdbbvpFf+51RGNarCNe+tATXv7LUEfB6+H49cdm3RgCQAYxXfHuEw5yunswnVEiTuWXJSeGNVH+C9UP/fvlZDdXH4hGXbZEXCvrGYJwwpi8Wb9rrCN7vW5qH/qX5nmnpqcD9+Sq3nfuBQB80jz1AWvfUoK4qc+vTkKgaPl5U1bVgWO8iXHzMftjT2Ippi7c6At11ER8RUuQoi62hWTr7leZjw+5GnDt5sGVZAYB///gQy4rTryQfTa0RyyKmUOJRWSl7Fefh0+u/jeqmVstVt+jGk1BvVkY+c6IUNUSEX7jct0QUU+AATgHolXFY0aPAcc11a43XA9x3DxqA0f1Lon6Lx4/qi+NH9Y1qr+hXmo9/X3iI9XdOMIC3rjg2qt1gzSp14IBSzPvDCfjr2yuxZIuzhIg6r9MnDsSkoeUJlfJIJyxymLj0Ly3ArNW7LHdVYa58GmoJGygvzI2aiqChNewoHJdqY4pd8dh7vZ7GmqmWnPrmMFrCBnbVtyJi2PNGuTXZrvoWa2JKRTAQ8J3+QRERMh29vDA3WuQI/6Dk/qXeA1UskfPjI4Z61kLSY170wn4TBpc73CU5wYBjsFSDl0rPVpYcPTOrK9BddF7CD7CzeX44eXC7jlHRoxD3n+dM6776hJH46ZHD2rW/9uDnitRRA7Byq5V5WHJUFpRiysg+GDuwFA/NlFWQexfl4RdThuOFBZswbfFWbNrTiADJ+4Nec0dNS+K25AD2d2pob6doVMHcgBSJjW3hhCy9ZYU5jgcG9feVMWr5JIouUr0sHbecPs7xAOh2Sbn55wWTOtwnL+bc8G3rPvnWFcdg2dYaSwh6fe8PHy7dlvv1LnIIzUyFRQ4Tl1CQEDGEJR4IZP0oQgGKmlSyoSViTasApN6aogw1fk8Q9VkgcoT1KmMP1E3F3d+65nBUBdcgRRenc6MsNeWFOdjkKqgajkRbcoikwBrd39vCEUvk+A2Sxa4n6ZH9irG6st4zyFIXROpaqCDZqno78Lgr0W/wfudf0aMQG+48zXNde3EPvJ3NhMHl+MEhFVaqtM5bVxxjCXBAuoYG9yywLGF9SvIwvHcRThjTF4e6qkJ/58B+mFBRboucEmkJDppmr8raZgwoK7BcWAolcixLjiZyVGKDW1Dp/OLY4Y6aT+kinovTbU3sE0fkdBa6W3LcoDJHZqXXb/sUV4HATIdFDhOXYECJHGlS1qcFCAbIcRME1Oy9huPvVGK5q3xuIqqfettMwzbFy5t6rhn/4TXr8fSVOy0RAshBIt7Dd8QQEEI+QV563P749yf2nEKGiJ7yQe3bnUWjiBXk7XczL8p13l5OHT8AqyvXeM6p4+WaCQYIBTlB7LJicrr2duWw5GS4Sb4j5AQDuPucCZ7r3KUEcoIBfHq9HeyanxPER9cdDwBRFbF7FeU63HC9ilTgtfy7JWwgPyfaHBttyTGs75+yiPhVkwakBSmTcE/Z4YcSgV7XJF0ENT/sT44cipY2A8ePyqzrGw8WOUxcQgFCRAjLQqIGZrXOjYBznqOUBx7Hya7KBkuOhRDmk6q8mXil23++bjfGDizFim21EEIOEvEGXfvzCeCGU0bj4VnfOKpR+10X96CmiPVU6ha5CpX187Ojh+GMiYOsSSe9RI7K8Pntyc55loryQp0Sk5MIiVhyGJtClzuRiJCfE0RhbhCNrRHr+6APnLmh6M/UnV0VMezrf9uZ4zC6fwkmu6xGmcoXN51kzRQfj8LcEK45aaQj6zDd6PfYcYPK2u2WTScscpi4KEuOLXLsQTJoDnAvXHIEVlfW4abXZQlx3SKR+pgc+eo37rS0Zb4lR3VLQKWQm5NgeqQ97ahtxpQD+mDV9jqEhRREbo3zyynD8dWOOiuAN2JIb39+jmwYJEJYS8l1i5ycIKEtItrlrvJbp1JcB5Tlg4gwpGchnpq3Eb88LtotUpAbxDe3nxr1mRbnBR0p5F2JLuATKVewr6Nb7kryQphsFnt8+uLDcdd7q6ypQvTrmudRKdptydEDj/uX5eM6lxDOZLym9ohFKmKBUokjwzBLfwMscpi4qC+3VajNw5Jz+PBe1jK3JSfldXLiVDx2BjGm9NApQwUcCvNaBgKEAJGnJactYiAYlDU1wobwtJ4V5oZw4RFDHSIHsC0+ARXhCXl9wi6Rc9cPDsLEwT18hURsS47/Ot3f37MoF+9eFZ3VEesYetXhrhY5jjo5meNByFj0z2fZLSdb7ycN6YHnL7GnPdCtkLFETkT7vrIlLT0kUhAz0+GfLhOXoPnlVrVOZEyOHIwdNx/zrRDo1MDjeCnkEYfIyUxLjuqWYZrlg2YhMWUBO2PiQNx42hgAss5IkMgSN8EAYdLQcsf+AuR8Qo6YcVNqmb7O0OauUhTmhmJmSsS25HTebcQhcrrYXaWfFw+y8fGav8sLhyXH4zNVKeTqt2uwyEkbutDP1s+ARQ4TF3VTEtbA7B2To0SHgNNdleIyOXFTyHUrhSEEZnxVGZWGnW5UMLYQ9pNqgGxxeOwBfdBXS+cOBuxqqsEA4ayDndkwgYCz2mrYLKhmbaPdrMKGXTJfEe/2FctUnUgKcntRUwzkhQJdfpPVv1/ZaqrPRILBOJaciHBU7NYDj5muRf/NZetnwO4qJi5ui4k7u0qh3gnhdleltj/xKh7rs56v29WAm15bjpPH9sPDF05ObUc6gLokhpBZUAGS7ip13XKCFDWtgNsq4y7j7rDWCKcI1QcWPahT338sYqaQd6IZW1lyutpVBTgtOX6ZfIyTBy+YhBHaNAtexIvJUXOr2Zac7LUiZDvJVP3OVFjkMHFxP6kLLfA4pA0ESnR0urvKiO2u0i05yoKjV1fNBKwS9ppYDBBZ1y0n6EwTDwbsm4wacAMuEaTfhNQ18LLkRDxicuJ5nNoTeJwKVNXdwjSUjWdLTvKcdlD8Gir6tfRyccnEBsOa4iRsGMgN8VCVDvR7TLbG5PA3h4lL0OUXMgQsd4e+Sv0eBIQjgLazYnL83FWOmBy/0r5pRlg3cF3k2HVycoIBR32hYMB214QskWPvL0BOseFOs9fX6fEOinjVYWMXA+z8mJx0zI0T6AbxCJlI0GHJ8UkhN+s8GYaszs3XPz10h1pRLHKYuMSy5DhM+lrgsZ4KnWqZYaeQx7fkqPeJlHjvSlQPHZacgG3JCQUJelHiYMAWLAHXq3rvZcnRg5V12pKNyUmTu0oVJ1y3q6HTjuGHI4WcB9mUEYoTk6OXOIiYVh2+/unBkV2VpSmG2dlrpktxm+rlXDPmYOy4+ZC5XgYe51rzMaV6WofYwkWfskD1M9PukXphPkBeYz2FPDcYcBajI7LiatQ110+fyCODSgs8dgvCVldl5Q7F5HTixT1z4iBMqCjD2ZMqOu0YfgRZ5HQK+oORV6G8sOaqipjxOXz90wPH5DD7BO4vt6MYoB54bLmrZOXevJwAWiMGfCa8bjdKNPkZELwtOantQ0dRLjcVJB1wuatCAULE0Cw1ATsQWYmdZCw5IU0ghQ0RVXQwrsiJmV3Vec9KRITXfn10WixxTitlhn2Bshj9u5Tn4XPWg47VHFYcE5UeukNMDltymLi4v9yqgB3gfIq33pnuKlXXJPUxOfLVL+PFKyaH4jpkupaowGOCM/DYlTId1ESM220l37ticswMKnfgsQr01LPfgPgiMNYNrrNvfulyNToCj7P0KTYT0a+lV+BxxJE+LtPJg1k6wGY7oW4g9FnkMHFJ1JLjqJPTZljBoqmPyVHCxRu9Bow7iyhTUBWP2yL2ddRTyHODgSh3iSVyPN1V5BCcqqqxOyanvSJHv8G5B6buKgAcxQCz9Aafieii2EvkhA1hF8s03/P1Tw/OmJzs/AxY5DBx8Y7JMS052g1LNTMMpyWns2Yh98Or4nGm3SNtS47bXWUHHkeLHPlz9c+usn/OKoNKiRNL5AS9RU68pzT9ic7tYsjJ0oDEeOin2U1PMS04XCCB6CKP+ndTWXKydYDNdrpDXBr/dJm4uL/cAt7ZVcolJGNyIsg3gwpTXgzQUP3wxjMmJ7Vd6DBK5LTpgcfatA6yTo5b5NjvAacbx23JUSLH15LjismJd330QT7KktNNXQk8rUPnoH9P3WIecH43DSFgGFyMMV10hwxDFjlMXLxictyBrYAWeCwEWiPCGgw7q06O3271iseqXkymmXKUu0rFDKkJOpX7Ksf1hCsDi+X1VK/uwOOAh8hxu7jUZ+JOIY83iOiWHLfIycnSm1883BWnmdTgtg64rTRelhx2V6WH7uCu4uwqJi5R0zoYwnKzeGVXGUIKHbUuxRrHSi/1I5ssOc4Ucnt9ToiiJsdTWlNZdNzuKrclR20n1zvdVW7i3b+CsSw5WXrzi0d3MNVnIvpDUygQbclxVEtXKeTd1FqY6XSH3wCLHCYu7hRhw8+SY89eBQH7R5FqS47anV+sT8QhcuQNM9MeBO1igLZYdMcq6JddPvHGtuQ4qhoLp8gJuSw5buJXPNYsOS6hlK1FwuLRHSYnzESc4j1+TE6ELTlpg0UOs08QK7sq4GHJEaYlx8q2SrUlxzx2IjE5babrKtN+nkr4tWkWF/1aurOrdBHjVwxQHwjUNXfPd+VnyYl3fWLNN5St9TPi4Shpn6U3+EzE7QKJ5a5yu12ZroVjcph9guiYHGGlaXvNbSIgrT2dZcmJ567SKx63hmNP5pkurOwqRwq5vT7kmoVcN+sHLJHjDDz2MumrfXhZcrzS//0Ixkj7zdabXzxY2HQOIVdAd6zA44hKIefPIi0EHII0O+VCdvaa6VLcA6BAtDsE0GNyBISwM3tSbckR8QKPDWEJBsuSk3H3SOcEnQFyuqtyXNM6BALRlpxYMTkKJU7cgcfyGEmIHL1KrTvw2G+m1CwnWwMtM52gKybHPXi6LTmcQp4+2JLD7BO4bzC6uyrkSCGXSHeVPXCmPLsqTgp5xBBaFpFyV2XWD9RdJ8cdk5MTdJrxg2TfZNzBxOq9103IXR1Zd1fp9W3iiUB9325Rk6X3vrhkmvWvuxAVUB8VeGzPqyandWCrWrroDjE5LHKYuETH5GhZQV4xOeb/zsquslPIvXccNoQ1mCuRk2Eax6odZF9HuxZNKEAgl2XHUfGY4sfk6NupfQJOS45XIUc/gpr1yC1yMm2G91TRXWON0o0jJsejTo5e3iAi2JKTTljkMPsEnoHHkehZyNVgJ0x3lXr66qw6OX5EIgK5IVltudWauyqzUAJNiTDdXRVyuZiA5CfoVEQFHjtETuLz0ljHdlmcujP7ynl2NU4XSHR2lU7EMGAI/izShaNwI4scprvi/nLrxQB1/7rurtLnm0n93FWx14cNYcWNtJn+/R21zXhr6bYU96T92CnktkVMicQcK1XcFXisxI/nBJ1ye/eAEXJZcvR4Gr2IX6KBx17F27or+8p5djUB1/c61nW2pjnhzyItdIeq3yxymLhEWXIMPSbHw5Jj/gt1siXHP/DYQE6QQGRbSjbubsTlz36R0n50BK9igEov5oR86uC4MqXcgcdqPzoBtyUn6G3Jieuuso4d+8m7O7GvnGc60KcbiXWd27SK4EzX446fykZY5DBxcWc/CPjE5Kj1piXHdleltj+RODsMm3U1gkR2TI7Vt8yYlVz1I+ya1gGIDjBW793zUDlTyBG1DRCdQq7H0zizq2L3V4/JydabXbLsK+eZDvRYsVhWGpVpxZ9FetAt9dlakJFFDhMXd3kEv+wqR/E/YQ+cqRYWVsVjH0dYJCLMisEUNUdThmgcq+e6WAy4BIn7KSoQJXLs/ZFrW307fV/OFHLdkhPHXaUGpSBbcpiOk6glp5XdVWlFLzyardY0FjlMXKIsOUKv72Iv1+vkGEJY/tzOy67yXq9bctyzbWeIxvFMIVfXTwUe65c9QNGWHLc7C4ie4yd24HG0Fc4P9Tn7BTh3R/aV80wHAcuSE1s0t0ZkOjkHHqcH94NXNsIih4mL97QOhiNYVsdOIbfbp5J47qqIYVipqW53Var70l5UPxwxOdqNH4h2VwVc6xOJyYmZQu5hhfNDBTWHApS1Zutk2VfOMx0kbcnhdP604H6wykZY5DBx8RY50cutMUHNQm4VA0xtf2x3lTfKkhMgO7vKvW26sdxVkWh3VbyYHKVNPC05Pu4qz8DjJLKr1L6CAe/pI7oj2Xxjz3SUlTcUjK54rKNEDlty0oM7ozMbYZHDxMWdymwI01riGgTsuauEI/A41TE58dxVEUNYcz1FxeRkiMPKDjy2b+KWu8orJkevo2MOCu5igPq2ipgp5ElkV6k+BPclSw6LnE4jUUsOp5Cnl6DPw1M2wSKHiYt+g8kJBqyYHD9LjrLcdNbcVWreLD/BYsXkBDxicjJD43gGHtvBvfGyq+QyL0uOOzjQWq5q8AR9YnISuIepTJhsvuElw75ynulAD4iPmV2lHgL4s0gLesJBtpK9PWe6DOe8RQRhZle5b05qfihlaem8isex10cMISe49IoXyhSRY3bELgaou5yUpca27gQ0N1HQismJFilRlpygf0xOThIVj1UfAixymBSgu2RjCRjOrkovHJOTxRDRICL6PRF9QkTbiaiBiFYQ0d+IqJfPNgOJ6EkiqiKiJiJaSETn+LTNI6JbiWg9EbUQ0TdEdCMR5fi0/wkRfWHut5KIHiWiPqk85/aif8FzQwEYQpjWEu+JGg0tmBbojJicBLOrPH6YmeOukq/OaR3kMufEnPYTb+xigN43I/dyZ+BxcjE5+5wlZx9xy6UDy40a5Do5mYy7BEU2FWlDoQAAIABJREFUss+KHADfA3AzgN0A/gbgagBzzNcviai/3piIegKYDeD7AB4CcBWAegAvEtHPPPb/AoCbAHwE4NcAZgL4C4D/uBsS0W8APAGgxtzvwwDOAzCTiIo6dpodR/+C5wQDMiYnEm3JUXnIEVehwK6euyockfFCXgN3qgVXe7FTyKOndXCIDy3Y2A48lq/eMTnOn7SVieUReJxsTI4qWLivDDj7SoB1OtBrPiWSXbWvfOcyDTIfvrL5+ofS3YE08imAoUKIHdqy/xDR55BC5Drzv+IGAPsBOF0I8SYAENF/AcwFcDcRvSSEqDeXnwrgDAD3CCGuNbd/lIiqAVxDRI8IIeaYbXsDuA3AAgAnCCEi5vIFAN6AFD23p/70E0c3JwcDBEMICOGRXWW5q8ztOkn9u8JsPNbHsORkiL/KHZPjmLbBo8qoKm4o3yuRk0BMjjazOdD+WcjVPkLBfSjweB85z3RgB8QHEorJ4c8ifYQCgaxO4d9nLTlCiBUugaN4wXwd51p+AYBvlMAx9xEB8ACAngBOdbUFgPtc+1B//1hbdiaAQgAPKIFj7vtNAOtcbdMOkbRCqFo07nWAbWmx5q5KsfnEdlf5Bx77FRnLDIljXyPdkqMEidekeMFAtH/cK/A4OrvKGb/T3jo5qk28J+/uxL5ynukg6LDkJJBCzp9F2sj2jMp9VuTEoMJ8rVQLiGgAgEEA5nm0V8sO1ZYdCmCrEGKz3tD8e5tHW0BahLz2PZqIihPufScTIBl4HDZE1BdfDZRq4O6suav8Usi/3FyNN5dssyw5XvdFEccK1FVETdAZ0Gch18WLetWmdbAyphDVLrpOjnz1TiFPMibHtOLsK4P/vnKe6UAvbZBITA4HHqePbH+w2ZfdVX7cYr4+oS0baL5u9Wivlg1ytV/ps/+tsIVUIvsms81q90oiugTAJQAwZMgQn8OllgDJOjly2ga3u0ridld1VcXjMx/8DAAwuGeBb4BspgQeu21K+tOSoy5R0K5+bFly1LQPjuwqZ4yDbSFyxuTk+MXkJNDj4L5mycnip9dMR4/JiWWlaeEU8rST7b/5rBc5RFQOGSycKP8QQuzx2de1AM4B8IgQ4iNtVaH52uKxWbOrjXrv1Va1d7dNZt8WQohHADwCAJMnT+6S0ZtIipZwJFadHHteK6LUu4iUxvHbbySiLDleMTkp7kw7cfcjqGdXeVhYAkSYOnYA2iICJXnyZ+sVeBwMEHKCmsiJlV2VpCXHqnicxTe8ZOCBtfNgS072kO0ZlVkvcgCUA/hzEu2fBhAlcojoYsgsq7cBXO5a3Wi+5nnsL9/VRr33aqvau9uqfTclsO+0It1VZlVhd0yOCjw2B1gi270Vj817GjH1vlk4feJA3PH9g2K2jVfxuDUirLmr3GSIxoly4QUC+rQOekyOeiUM6VWIX39rhL2NR0zOaeMHYFivQry4cIu1HWAPEiX5OThkaA8s2VyNih62dqYEHNdK4Kh9jepXgikjeydyugzjwBmT4z+AtnHgcdoJxBGimU7WixwhxAYkZm33hYh+DmkR+QDA2UKINleTbebrIESjlunupm0+bVV7d1u1fK1HW6G1STsBZcnxqJOjBsqIZcmRsicRd9WWvU1oaI3gufmb8cfTDkRxnv9X08td1dgatt7XNrf5Bh5nygSdbreZX0yOuzaOjlPkyNefHjUMayrrokSOHpj8yq+OghACM1dXWdsn5K4yByS1r2d+cTh6F/tpeYbxR/0+KV7FY04hTzvZbsnZ5wOPTYHzKIAPAZwphIhyGwkhtkMKkyM8dqGWLdSWLQAwiIgGu441GDK+xt0WAI702ffXKjU9EyCQOUGnV8VjiZ5NpWJ44qEP+vGEiD1Bp91uW7VtBGsNG1nprtKtNgq7Tk70ueinp5/r4J62hUbtszgvhAAB+aGguS05hE0i7qqfHjUM5x06GEeN6IUfHFKBHoW5cbdhGC/0ytmx6hGxyEk/0nqbvVIhe3ueAojoIsiaOB8BOEMI0Ryj+XMA9iei72nbBwFcAaAawDuutkB0rJD6+xlt2euQbqrLzf2pfX8PwHBX27SjUsjDhuERk2NmVwlh/a3aJ0O8DCgvd9WWvU5PX6YHHrt7EdCmdXDUyXFlVOl4xeQAQH6O9TWy9nn6xIF46dIjUVaYE7XO/d6PH04ejKnjBmB0/1Lcfc4EHniYdqPH4gQ9LJIKq04Of9fShl7eIhvJendVeyGi0wH8F0AtZG2cs8l5o68XQrym/X0nZFDys0R0D6Rl53zIFPCLhRB1qqEQ4m0ieguy8F8ZZHr4kQD+D8DTQojZWtsqIroJwN0APiSi5yDdVNcCWIXoWjtpRVlm1PxQOtHZVYnH5OijfjxLjnJX6a221zj1adCnaF3mWHJc7irSKx4HHMsB75t8LJHymxNH4t4PV6M4X/7E83OCOGRoT0cbP5HEMJ2NY0JaPQg5SGhus59ylm6psdoz6SHbLTn7rMgBMAnSklUOM0PJxUYAlsgRQuwmoqMhxc6vARRDpomfJ4R4wWP7cwDcCFnM70JIUfQnc3sHQoi/E9FuAL8B8A9I4fUigBsyyVUFSIuDqpOTn+O88Vgp4yrwGHY2VjyEz3svvPZX0+QMowr5PH1kjshx/q3X9UnUXRVL5Fx5wgj8+Igh6BUjZsZrgk+G6Qr02cdVbF9uSFY/1kWO1Z5FTtrI9picfVbkCCFuhpy7KplttkIKlkTaNkOKnBsTbP84gMeT6U86kJYcn5gc80+9GGDCMTntsOToG9U3hx1tgr4VjzND5ej9IJKuPfeTLeCcoNONVzFAe58UU+Co49rbZ+9NjMk+gkG70rFyz/7gkAoMLC/Ane+uim6fxYNstpPt89XtsyKHaR9kihavOjkKpUGUJUfXLBFDoC1iOOJGgOQCj73cVfUtTpGT6RN0GtrDql3BWMXkeE3r4BWT0zFLjB56zCKH6Ur0mJwBZfnoUZiDm757IHKCAU+RQx1LoGU6wDmTB6NnUU78hhkKixwmKVRKuGfFY/NPQws8VpYfxSVPLsSMVTux4c7THNvquiaeS8lLqNS3hFGQE0RTm5z+K1sm6ASiZxV3WHJiiBx9EbVDpDi2T3rrfYNzDqnAQYPL092NbkdhbhAFufJB58yJg3DKuAFWjN8blx+NGV/txIbdDThwQCkGlhdgZL+Mmdlmn+P/jtkv3V3oECxymKRQA6OaBNO5zsyu0ooBSkuOPaTPWLXTc7/6oJ+wJUdrVt8cRv+yfKzf1QBABtpmS+CxuqZ2McDomBzv7KqOWWL0OB825Hjzt3MmpLsL3ZLLv30ALjisFYD8HirBAwAHVZTjoAoWlkxqyN6QaabLKckLOWJy/OeuUoHHycTkCO19nLYQjldAWnJ6aOnR4waWegbrZozI0d675/jSJ85Ub72CqGPF5CSC2kTFBDFMVzGovADjK8rS3Q1mH4BFDpMQq/4yFQtuPFGKFkPWyYkOPHYO1jKF3D/Yd/aaXTj6zo/Q1BpJypLjtbq+JYwirUryQRXlnpVUMybwWDsJspbJV+e0Du1LIU8E9XmxvGEYprvCIodJiPycIPJzglZKeMRrgk7z1emu8rfkrN9Vj63VTahrdqZ/x7fkRLerbwmjJN8WOQW5QeSFor/eGWPJ0frhtuTo4kyfoNNNR+vcqG046JhhmO4Kx+QwSREgOcN12GuCTiuFXP0tcyL8gn2V+DEEkioGqHBkVzWHUZwXwl/OGIs+JXJeU93Pn+y+Oxu9F+6A7aBH4HH8uavaE3jsL6AYhmG6AyxymKSwLDleMTnmYCmsmBxY7i0v1KBuCOFKIY/TiegyOWgw3VUXHjnMWuZOU9c2TTsOS05AWXLk3zle0zrEETnt0Slql6xxGIbprrC7ikmKABEEvLOrAGeFY5lC7h8HY1tyhCuFPE5Mjmt/hiFQ3xpGiWvm8gIvkZMhKke3KAVc4jDgclf5BQY7A4/bEZMDZ+o6wzBMd4NFDpMUsSw5gOnO0uauihWTowZ1IdwVj2P3wT0LeWNbBELAmqdJ4WnJyRCV48yukq/K4qULllDAew4uIAXFADkmh2GYbg6LHCYpVEq41yzkgFks0FUnxy8OxumusolvyXG+aTCrHRclYsmJuecuRM+ucgUeO2ZlDpBnKry9rdmOY3IYhmGiYJHDJEXALO5nGH5TDWhzV5kVj700i9BcVIZwCpv4lhxngzpz3qpil8jJ9wg8/s69s3DbWytjH6ALcAQem6/WdBjaZQ2SvyUH6JhQUZuwxGEYprvCIodJClUM0KtODiDjPJzxJt6WGSFcMTnaurh1clyvja2mJSc3viUHAB6dvT7m/rsCw9CvkSsmRxMsQW2OHy/sasnJ90Edhw05DMN0V1jkMEkhLTVSoPhZcgzhtOR4WWbU/FeA06oj/47dBysmx3yjLEfu/viJnEzAMybHCjzW1sV1V5HjNRksgZTFMwwzDMPEgkUOkxREhLBZCMfTkkPOYoDwicnRXVSyue6uSi5yxmrt6k5BbuZ+vfVTtGNy5N8OSw55i0lFR9LAOfCYYZjuTuaOAkxGEiCgzRQ5Qa8UctiWGzV3lZdmkZYc+71OohrHtuio4znJD2WuJcfh0jMvY8TjxAMBiilCOhaTw9M6MAzTvWGRwyRFgAhtkejpBxROd1Xsuaus7CrDnULur3IcE3m63rldNl6Bx5lIrJicvJD39BTubTs2QSfLHIZhuidc8ZhJigARWi1Ljk+dHM1d5Vfx2G3JSTTw2Ct2x8+Sk9ExOR5zV9kTdNpnculxw3HmxIG++0lNCnnSmzIMw2QFLHKYpCDNXeWeuwqQQsMWOc76LzrutHGHeIlxfK91apl7nM9okaOdiZ1CblvAFEN7FWForyLf/djWmOT7wNlVDMN0d9hdxSSFDDz2zmaSDZyWlUSyq9xzV8UqBuh0V9kVk+XxXNlVGeyu0q+JPUGn+jtx1aEyozpSJ4cDjxmG6a6wyGGSQg889q6T45q7KgB42V+E4ZyFPNFpHZyVkdWrls2lkcmBx97uquiYnHikohggixyGYborLHKYpJCBx4b1Pmp9gKwsoQDFtuTYFY9dMTkxVE4y2eX5mZxCrp1xwHLrqb8T34+VQt6OPrC7imGY7k7mjgJMRiKzp+R7v5gcx9xV8IvJEdoEnQKJTuvglallxeS4lucGM/frLTzcVfp0GIlCHRAq1rQOLHIYhummZO4owGQkzikHPOrkkG3JISLfWcgNoU/Q6Vznl3LuRp/FXB4wui+Zii7q1DVVgdI5SYgzOdN7eyset9/VxTAMkw1wdhWTFLorxS8mx/RmmYHHPnNXQUshd6mcWC4pz8k+VZ2cLCpr54jJMTXNX88ah5H9inHU/r0S3o+aOqM9qK1Y5DAM011hkcMkhS4kvOeuIi0QONYs5E5LTqLFAB37cL3JprFaP0N1TXsV5+Ga74xKaj9S5LSvD1zxmGGY7g67q5ik0D1U8eauUq4U/5gc+V64UshjxuR4FQNUx/Zov+72U/GTI4f67zBNOLOrOrav9rrlOjLvFcMwTDbAIodJCqI4lhxoKeQg07ITvR93TE7C0zp4BR7HqC8Tb+6ndKGfY0dihwKB9osk4pgchmG6OSxymKRwxuREf330lHE1d5WnJcdwFQN0FMDxP76zMrJwvPqN1Zk4iOun2BFLToCo3bFIbMlhGKa7wyKHSYpAPEuO5q6CWSfHPyZHvk9q7irXPvRXv7E6I+dm8siuag+piMnJRBHIMAyTCljkMEmhD4jx5q4KEMWJybFTwBOuk+MxC7nf3FVWnzNQ5TgtOe3vn5oEtb3bytfMuz4MwzCpgEUO0268BldHdpXZxkuzGEJYs5O315JjLfMrlBNzKbCmsg5rd9b5HqszccbktH8/Ski2d1v52v7jMwzDZDKcQs4khcOS4+OuCmuzkMtigN5VipW0MQQc6iXWBJ2Ofbizq/wGa5/lJ907CwCw4c7TEjpeKvGqeNweAtR+S5Xaig05DMN0V9iSwySFPp76x+TYbQPk7X4SQrhicjQ3VMLFAJ0qx3esTmK+q64iZe4qtD97jCseMwzT3WGRwySFbjXwjsnRiwFK4eFlmdFTyN3rY8XkeAkWO7vKe7DOQI3jsG51PCan/dvKVxY5DMN0T1jkMEmhj4e+xQATqHjsnIW8fXVyEs2uykhS5q4itPfMLZHT/sMzDMNkNCxymKSIN0FngMjKriLANybHMOCsk6OviyVyvCoex5nWIdEYn64kVe6qjhQD5MBjhmG6OyxymKTQx0O/CTr1CsR+MTmGIybHW7x44ZldZR07e0Zr5yzk7d9PRybo5JgchmG6OyxymKSIVwwQHnNXec5C7orJcbihYkTROOvkOGN6smmsNhzuqo7E5HSgGKD5yiKHYZjuCoscJimc0zrEn7sqdkyO97QOqn6OF54Vj+P0OQO9VSmboFMKyY7F5GSRAYxhGCYpWOQwSRFvgs6AFoOjqvH61clRYkYIJByT495HtqJbqzo0QScRPEKjEoI4JodhmG4OixwmKZKZu4pMd5XftA76LOS6aSPxOjnOZdnkdUmVJUdVlW4vgQ5MC8EwDJPpsMhhkiJuMUDYs5ATyJzmIXp7oWVUJTetg5cYst1j3ttkHs7A445ZcjoiUToyLQTDMEymwyKHSQpnnZzor4++XqU3C8d62cDQJuV0BybHFCV6FpYVeBx9bMcmGahyMmGCzlRszzAMk8mwyGGSIl5Mjr5eBR47JqM0Xw3DP4U86Qk6rWPH633mkLq5qzpmiVHzizEMw3RHWOQwSRF3gk5H2+iYHLW5Pq2Dnmml1vnh0D9RFY/93FWZZ8pJWeBxIBUxOe3enGEYJqNhkcMkRcDhjvIOPNbfE8iREq6EiHOCTndqeIIxOa5l2WSQ0IVcuooBAmbcVPsPzzAMk9GwyGGSIt6Aqq+PVajOHZPjrJOT2LQO7mXZNFg7g7E7VgywY+4ujslhGKb7wiKHSYp446HDkgOPOjkquwpaCrnhdCglOgm5JZLi9C0TA4/hcFe1fy8dFSkck8MwTHcmlO4OMNlFvAFRX0tmoTrPwGNhFwNcvKkaRXn2VzFWTI6O5a6y9p89g3XKLDnomEhStYwYhmG6I2zJMSGiABHNJSJBRG/5tBlIRE8SURURNRHRQiI6x6dtHhHdSkTriaiFiL4hohuJKMen/U+I6Atzv5VE9CgR9UnlOaaCuPEj2ogp2xKc8zTJV70Y4BtLtuG5+ZusNjFjcmIUDcymwVoXfh2JyfnuQQNx1sGD2r19oANzXzEMw2Q6HbbkEFEAwFEAxgHoAcBzEFcIIW7t6DE7icsgz8ETIuoJYDaAvgDuAbAFwAUAXiSinwsh/ufa5AUAZwB4DMBcAEcC+AuAEQAucu37N+Y+PwFwFYAKANcAOJKIDhNCNHT05FJF/Jgc+71MIXelS2uBx35aJmYKOcfkODj7kIoO9YPr5DAM053pkMghorMAPABgQCLNIT0MGSdyiKgCwO0A/gzg7z7NbgCwH4DThRBvmtv9F1LA3E1ELwkh6s3lp0IKnHuEENea2z9KRNUAriGiR4QQc8y2vQHcBmABgBOEEBFz+QIAb0CKnttTfc7tRYkYv6d/p7sK5gSd0VYLw/BP7U7aXWVlV2XPYO0skJi2bnQ4O4thGCaTabfIIaITAbwE6fJqBTAfwFYAzanpWpfyIIB1AO6Hv8i5AMA3SuAAgBAiQkQPAHgSwKkAXtTaAsB9rn3cB2mh+TGAOeayMwEUAnhACRxz328S0TqzbcaIHMWw3kWeyx3FAM0aLM46OarisfAVM4nOXWVnZ5n7TqDfmYLXNUkHAUJ2XTiGYZj/396Zx0tSlXf/+/S9sw/OAIPKjCAIIorKNhBwxTUqgq8aN8QtQaIGFGOSVwzgEqO+GlBBTASMuKBBo8HoS2IEhfgqyCK4sCgCQ2TY12EYZrv3ef84p7pPVVd3V3ff7r7L78unP3Xr1FNVp4ue27/7nGfpgn48OR8gCJyLgSPc/fapmdJwMbM/AQ4DnhFFS5nNjsAq4JySS1watwfQEDkHAGvd/Q+pobv/wcxui8dJbCF4hMqu/QYzW5p5iUbN/9y3AYAjDty59Hgx8NisEJMTt2kxwCJVe1fVxzq2dZiG6VVTVCenf+TJEULMXvoROfsTflW/dQYLnGXAqcAX3P3SNqYr43ZtybFsLI3+XAlc2+JaawkxN1WvbdHmd23mNzTedNAuTEzCmw/epfR4rRB4bFYuMrytJ6daTI4XtjOqQWfy8yhFhioeCyFmM/2IHAPWufstUzWZniZhthw4rotTTnX3++LPnyR4o47vcM7iuN1UcmxjwSb7ucw2sy/adnPtOmZ2NHA0wM47l3tWppqdt1/MSYc9pbVBU+Bxvgt5o05OazHTtq1DyU52nZnkkJiqLuT90m8XcyGEmM70I3KuA/Y1s4XuPso4nOWEgOGqfA24z8yeDbwdeJO7P9DhnA1xu6Dk2MKCTfZzmW1mX7TNrv1IhWvXcfczgDMAVq9ePS0cFsXeVU0xOXGbppAXaZ9dVeIV6jCn6bhaVZZWPwqUXSWEmM30Uyfn8wSR9KYpmktPuPsad7cuXr+Pp34O+CXwczPbPXvFY4vj/oq4f1vclhUkycbS5abbWthm9kXbdtf2xGbak/u+NJpjcuqBx+R6WqVUFSX1+JwOMTnTkemyXDVWs9IeZEIIMRvoWeS4+5eBLwKfMbPXT92UhsbjgX2AGwovgOfFnz8EEGOO1gIHlVwnG7siGbscWGVmO6WGcX9liS2EOjpl1/7tdAk6rkKudxWhr5KXtDDwNp6c9g06U7u+pjpSvMS7NQo+eNhe/Okzdx3hDIQQYnD0k0L+z/HHTcA5ZvZxwpf3Q21Oc3f/s17vOcW8GZhfMv4t4ErgE8Dvk/FvAH9lZocldXLGgGOBB4DzC7ZvJMQKvS8Zz2KH0iyt7xKCn48xs68ndXIOA54AnNjTuxsRqVMi66tUnl3Vrhhg6+uXFgPsUCenVT2eUZLz5IzQk/KipzxmZPcWQohB009MzlsJv6uz39CPj692ODAtRI67/3vZePyivMPd/7Vw6BPAa4Cvm9kpBM/OGwgp4Ee5e13cufv/ja0h/jJmcGUVj/8M+Jq7/7/E9m4zOxH4B+ACM/sGYZnqfcD1NNfamdakYaxZF/KyINvJyd5SyFN5kJn1WyfH3YdeqybnydFqkRBCDIR+RM5HmJ7ZuQPB3e81s2cSxM5fAEsJaeKvd/dzS055DXACoZjfmwii6KR4fvHaJ5vZvcB7CV6ddYSaO++fSUtV0OzJsTa9q8o+PCFQufX18ynk1bqQd8J9+EJjqto6CCGEaE3PIsfdPzSF85g2uHvLbxx3X0vFQOuYcXZCfFWxPxs4u4rtdMYKMTlFT06GtygGWDNru7xUFpPT8OSU/68rioiipph0pzbkyJi8yBnqrYUQYs7Qc+CxmX3HzL5tZopaFHVyyVW15uyqzMIpj8mp1axtQHH7mJzyc/7yRXtw+N4r6/tFs4kRRDCnQk6eHCGEGAz9pJC/HHiJu988VZMRM5/0+9pofIEXC/a1auswZsZkm/WqVBzUKx53iMlZvng+H3vV01pfcwSLrmVp9UIIIaaWfkTOHcCWqZqImB3kUsjNcqIGOhcDHKsVPT+tqS9X1W/Ybl6Nn4uion2g82BIbymJI4QQg6EfkfNjYBsze/JUTUbMfMoqHkMLT05JMUCzThWPWw+2a1CQHpuYdL55eaN3alVRNbVouUoIIQZNPyLnE4Q2BJ8zs1YtDMQcI79cZbkKx9kYBNFTFpDc6Qs/f0r17Krisb/59q/qP0+MQOWkt1TgsRBCDIZ+UsgfBt5BaO/wGzP7HKEezN3ARKuT3P1/+rinmPaky1VJXZyiJ2eyuQu5lfS6KuI91slpJ4DaVVgeFLnaQVI5QggxEPoROWnA8ROAUyqc433eU0xz8rEvaRuHvF1Z4HEWqNztclVjKazaclWRUSxX5RqzS+MIIcRA6Edw9PKrWb/OZznF5ap6TE78Wq9nW9EsLkKgcheBx4Vtr56cUQceKyZHCCEGQz/FAPuJ5xGzlNRjUsstV+Xtgvel2ZNj1j6lO1fxOO7Ul6vaZle18eSMJCYnDTwe+u2FEGJOIKEippScJ8fSwONidlVzTA7QskJyRmmdnOx+bbOrWjOa7KoG7eYthBCidyRyxJSSekxC76qAx3TxdsUAs0DlXmNy2mmF6bxcJYQQYjBI5IippeDJKcbkZF6LSfemZaIQw9N9McDG/dpMq91y1YjbOgghhBgMPcfkmNmPejjN3f0Fvd5TTH+KUiJLj54sxM24l3gzrEIxwJKfq6SQt6OsKOGgSe+puGMhhBgM/WRXHVLRLk1+0Z+vs5zMY5J5cNI2Drn9yea2DlngcbtPSWlH83qDzt7Ugjw5QggxO+lH5Lytw/FlwAHAq4ENwIeAh/q4n5gB1MVNFBzFwOOMEJOTP7dSTE768xSJk1HH5KhBpxBCDIZ+Usi/XMXOzD4M/BfwVuBZvd5PzAyyr+tM7NQDkevLVVmdnDJPTueYnPLA4/y9u2U0nhwhhBCDZuCBx+7+e0L7h/2A4wd9PzFa6h4c8stWzV3IywOHO8XklMmDKr2r2jGSisfJe5QfRwghBsOwsqt+CGwEXj+k+4kRkX1hm+W3mXBpBAu3iMmhm2KA+W2v9WZGvVwlhBBiMAwzhXwS2GmI9xMjoBGLk9+vi5y4nfTy0NuaWdug3Hx2lee2PXtyRpBdpd5VQggxeIYlcp4BLAbWDel+YkTUxU19uSrG4GRel2hXXgwwxuRUFB1FT06vjMaTI1eOEEIMmoGKHDMbN7NXAucQvt8uGOT9xOhpDjwO26IgmZz05pgcKtTJaaMNeo/JGUXvqsbPcuQIIcRg6KcY4E0dTBYCj6YrFOHsAAAgAElEQVQRanEPcGKv9xMzg1ohdbw5JidsJ8qifesp5K2vn3pAGsIpX025W0YSeJz8rBRyIYQYDP3Uydmlot0m4LvA8e5+cx/3EzOAYsBxrSkmJ4xvLVEWjS7kXcbkVOhC3o5ReHIUeSyEEIOnH5HzvA7HtwIPAL9z9y193EfMIBoxOdl+VhcnUF+uKvmSz2Jy2iaQl9XJyc7vdrKRYg+tYTDqzudCCDEX6KcY4MVTORExW8gvVzVicvLf6qWeHAv27Ssely1XZefPpOWqpE6OVquEEGIg9Bx4bGY7m9mqLuxXmtnOvd5PzAyKAceNruN5u4mJVstVHbqQJ0tTde9QvcN5b4y6To40jhBCDIZ+lqvWALcDVYXOTwl1cvq5p5jmFOvjNCoe5+vklHtyjFrFmJxUGMzEmJzcLeXKEUKIgdBvCnm3v53123yWU2znYC3q5EyUFMNpeHI6p5DXEldOo61Dj8tVIygGOJJgZyGEmGMMs+LxYkIwspjFNHRGK09O2C9ZrarbV/n+DxpnaqoBjlpwSPkLIcRgGIrIMbPdgRXAHcO4nxgdtUJ9nGZPTlYnp8STYxU8OfUWDpbzDvWz4jPq5SqtVgkhxGCoHB9jZq8AXlEYXmZm/9zuNGA58Ky4/+PupidmKsUA5KY6OaWuHIvZVa2v22jGmR/rRyeMpExO20R5IYQQU0E3QcD7AG8tjC0qGWvFjaji8ayneu+qVinkVurlycjOSuvpON5X1eDS6ssDRnVyhBBi8HQjci4q7H8QWA+c3OacSUJTzmuAi9xdMTmznObA47DtpuJxlbYOxSysfjw5o27Q2Ws7CiGEEO2pLHJi8b96AUAz+yCw3t0/PIiJiZlJMasq2zaES+veVZknp1IKeeK56b8LeX/n94IyyIUQYvD0U7NmV2BiqiYiZgfNvavC1ivE5BjWYzHAmRd4nKocaRwhhBgM/bR1uGUqJyJmB8Xu4/WYnIJda09Op2KA2XKV5do69LPkMwqRM+q0dSGEmAv0nUJuZrua2almdp2ZrTezrYXjy83sJDM70czm9Xs/Mb2pN+YkL3ayJpjZV/vWFsUAa508OZltommc/tKrtFwlhBCzk75aLJjZK4GvEAr9Zb+qc18Z7v6AmT0feDZwLfDtfu4ppjfFdg7F3lWZl6ZVRpPRoUFnkkKehvn0l0I+4rYOQgghBkI/DTr3BM4BlgBnAM8B7mlhfibhe+jlvd5PzAxa9a6qx+REu4nSFHLLFfkrI9/WoXHNfrwho0ghz3UhV1SOEEIMhH48OX8NLAQ+7e7vAzCzVoHIF8TtgX3cT8wA6stVWUxOLR+TU2/r0KIUTigGWCW7Khlz7zMmp+dTe7/nCPplCSHEXKOfmJwXEL5zPtnJ0N3vBB4mdCEXs5h6W4f6ftgWu5C3autQ6+jJSdo61MdmYHZVihw5QggxEPoROY8FHooCpgqbgPl93E/MAIrLVRRjcuJoaTFAg1qtmicnbeTpzMSYnKkpZCiEEKI1/Yich4ElZjbWydDMtiH0sLqvj/uJGUDRg1P05FBfrmpRJwdjwp3NWydLxUcak5PFtQRPTj9tHXo+tWfSt9/P3IUQQrSmH5FzTTx//wq2r4u2V/ZxPzETqC9X5XtXUfTklBUDtBDD8+CGLexxwn/w+YtuLLlBXK7KjfiMauvw8Kat3L9h81DvKYQQc5F+RM43Cd81f2dmLa9jZk8DPkH4djqnj/uJGUCxZ1UmcopCotyTA+M1496HgwD49pW3NtnUU8gLxQD7UTnDXq464bzfsGmrIo+FEGLQ9CNyvgD8CnghcGGsmTMOQdiY2cvN7HTgUmA74KfAuX3OV0xzillOjQadYZsJinUbtwDwyVc/nT/e6zHR1hqen3Cx1vdJYnI6mHakqLeuvW0df3nu1VOeWr5h81Y+9YPrue72dblxLVYJIcRg6FnkuPsW4CWEJajnAv9KEDMAVwPfBd4BLCIInVf7KCI8xVBZtihUJXjctouAki7k0W7D5lBtYPnieey83eJgC4wln8iyL/+WKeR9xeTkP5aX3HQv37lqLQ9M8ZLSP110I6f/+Eauv+Mh9t5pOef9xTMBeNYTV0zpfYQQQgT6qnjs7neY2TOAtwJvAQ6gkUE1AVwBnA180d23ll1DzC7e8Ec784zdV/CEFUuApHdVsrS0/+O35cpb7gdgp+0W138GGKu11935wOM4xtSmkGctKMoKFvbDpiTCebxm7LPTctZ84tApvYcQQogGfYkcgChezgLOiplW2xE8RPemwsbMDgROdPfD+r2nmL4sGB9jj8dsU99viJzMk+Psu9Nytl8yn0Oe9GievOOjOO/qtcHY8p6cMvINOpPsqj7mXNQyWXr7VBfsS5fixpRRJYQQA6dvkZPi7hPA3emYmT0HOIFQPFDMMZpjcmCsZpzx5tUNm6yZJ/kv/7IlqLR3VX2MPperip4cH4wnJ31vYzWJHCGEGDRdixwz2x54NfAUYAy4CTjX3W8r2D0b+HvgmTS+k67qa7ZixtFU8Ria3C5pAcGOy1WFc6B/T06rzK/JKQ48TucskSOEEIOnq8BjM3s1cDPwj8CxwLuAfwBuMrM3R5tlZvYvwEXAswjfPxcAL3b3KjV1hoqZLTazk8zsGjN7xMzuM7NLYrZY0fZJZnaemd1vZg+b2U9ih/Wy6y4zs9PMbK2ZbYzXf6eVuBzMrGZm7zWz66PtH8zsZDNbMoj3PEyyt5vvGF7IwEq2HQOPPV2uSu/T+xxbLVdNdXaVyZMjhBBDpbInJ+k6ngUWryd8Dy2JY180s98AXwT2JgQenwv8g7tfPZWTnirMbFvgQuCJwJeAUwjv58nA4wu2uwE/A7YS+nU9CLwd+IGZvdTdL0hs5wM/BPYFTgOuA14KfB54DPChwlQ+Dbwb+Dfg5Hj/dwP7mtkL3X3GFlUpi8kpCpJ6vytrNPTM9ttdt17xuM85Fj02gwo8rsmTI4QQQ6Wb5apjCWLmZuBId78EwMyeCXwV2AX4AbB93L7b3W+Y0tlOPacCuwN/5O7XdrD9OKE1xf6ZaDOzrxAqP59uZnsmKfJHETLN3u3up8WxM83s28AHzOxL7n5LvMZehGf7HXd/dXYzM7s5zu/1wNen4L2OhOyrPF0SKn6915erMMYrfvmndXK8bA2sC4piZmuL5aoHNmxmn4/8kE/+ydN57erue83W5MkRQoih0s1y1XMJfzS/MxM4AO7+U+CdcXc74Fvu/tLpLnDMbBfgCOBMd7/WzMbMbGkL2yXA4cBFqVfK3dcTMsv2IIiajCOADcCZhUt9BphHaHOR8QbCN/RnCrZnxmsc2dUbm2bUKx5HX1SZc6S+XGWFwOMS4ZKe78kaWH8p5MX9ck/OLfduAOCrl9zS031ynhxlVwkhxMDpRuTsDEwSlneKXBiPAXy030kNiZcQ3v+1ZvZVgqB4yMxuNbP3FmyfDiwALqGZS+P2AAjxNcB+wFXuvrFgexlBKKaC6ADCs7ssNYznXl2wnXEUWleV17RJBmodPBy5FPJsrO8U8oInZ6I8JiftgN4LuZicMYkcIYQYNN2InKXAPTFNPEesh3NP3L1+KiY2BJ4Utx8nNBl9B8FrcjNwipl9OLFdGbdrS66Tja2K220JVZ6bbN19E+E5rUqGVxKe66YW114RY3yaMLOjzewKM7vi7rvvLjMZOZloqWdXubcMPAY6Llc1elflx6a0GKCX18nJxntNV0+Xq6ouywkhhOidblPI20ViOtTbPQwNM1sOHNfFKae6+31AVrFuPvBsd783Xu+bwLXA35jZZ9z9fmBxtC0TIpm3ZnFhW2ab2S9O9hd3sM1smnoMuPsZwBkAq1evnpYtM7Kvck9SyFsFHkPnwONcxeM0mLmfmJzJ4n75cpXXRU5v9zEtVwkhxFCZ0mKAI2I58MEu7L8G3Ac8Eve/nwkcCCLNzL4OnAQcBPwHYSkLwpJVkYVxu6GwLbPN7Dck+xuAR7exTa8542h0IQ/7ZUtL3Xz5p0tGueWqPjRD1iw0o1UKeba7fuNWfrP2QZ66allX91F2lRBCDJduRc52ZvajVscA2hwHcHef0srH7r6G3kIybo3bO0qO3R6328ZtVuhwVYltNpYtT91PEFBNtma2AFgBXJwM3wY8xcwWlCxZrSIsZU1tp8ghkn2X55wi1nq5aiznySkLPG5er3L6i8m5/YFHcvtZVlVxGSvbveGu9bz2C5dw7Ude0tV9lF0lhBDDpVuRMx84pINNu+PTaUklC/R9XMmxbOyuuP01YUnp4BLbg+L2CgB3nzSzXxBq3BSFy4GE7+MrkrHLgRfHYz/JBs1sIbAP8N9V39B0xOqeHG8s9zTZNH7u9OWfC/5NvUM9unK2WTDO7Q/m48Nbe3Ia+1kX9W5QMUAhhBgu3YicLw9sFqPhv4FbgMPMbJW7r4V6uvibgQeI2VTuvt7Mvge8ysz2dvdfRtulhJo4N5DPjvoGoZ3F0YRigBnHEYoJnpuMnQt8IB77STL+dkIszjlT8m5HRD27yr00aDjsd/HlX9qFvHftvOPyhdyxLi9yGoHHrUUOxCDqiuLqSz+9mYt+e1d9XyJHCCEGT2WR4+5vG+REho27T5jZu4B/By4xs88TgnvfBuwE/Jm7P5yccjyhyeh/mdmngXUEIbIKODQpBAihxs3bCFlauxAqHr8MeCXw0bjEls3j12Z2OnCMmX0HOJ9GxeOLmcGFACEfk1PvO1XMrkqWtHLLVW2uayRLV33E5Kxcvojf3bmeRzZPsGj+GNDw5Fx/x0PsusMSdly2qH6flEmHqpngX/rpGv7nvkZolUSOEEIMntkQeNwz7n6+mb2AELj8t4SGo1cBh7v79wq2v4/VnT8BvJ+wdPcL4CVpS4dou9nMXkioGfQGQhXoGwmVjU8vmcpxwBqC5+dQQpr5acBJM7mlA6QxOUnF46InJ5EznQOPmzOcSmvvVGTl8iBgbn/wEZ6wQ6gFmXlwPvL9a7nmtnWc/Nq9gfJu5WMVo4GKXiBlVwkhxOCZ0yIHwN0vBkqbbJbYXge8oqLtA8Ax8dXJdoLQs+rkKteeSVjqyWnRCyr9vu9YDLC+5JUWA+w9hXzlspDAdseDG+siJ43F2bB5a/3nYmXkblpbFW1VDFAIIQZPV13IheiWTMBMuifLVQWbuHU8VySvtE5O3NbS3lUtbKuw3ZKQ6X//hkYa+dZEzaQ/tyoaWAV5coQQYvhI5IiB0uhCXl6tuLg/VrEYYOq5qdrW4fNv3I9VcXkqIxNVafByKkhyGVZ9eHKKIkcVj4UQYvBI5IiBUo/Jif9Bc7p3KoTSWjKlDTqz3lW1xs9ecs0yXva0HfmT/fMVAxptJxpjrTw57VLKO1Fc6uq0LCeEEKJ/JHLEQMllV1XQBFV7V4W2DtmYV47IKWqhuicnmdxkTtg04r639iFyivFI8uQIIcTgkcgRQ2GyXXZVV13IW4z1qBmKDUQBtibCZstEu5ic6veRJ0cIIYaPRI4YKKUxOW26kKcBue1WoCzx5BSv0Y7ivTOPStqkM+0+PtFi6QpaZ4uVoZgcIYQYPhI5YqCkdXLKatwU9zumVkexkNMIXXhUWnVAzwUbe7mwSZeuwjnV71usnjxW0z89IYQYNPpNKwZKsQs5NHtd6t4eCp6ckuuVpaE71dsrFK3KYnJaCZutE/3E5OT3VSZHCCEGj0SOGCi5OjktNEHLBp2lXcjDNgQee32s18DjzHOUirDU67K1bUxOH3VyxvRPTwghBo1+04qBkqt4XB8r2MStu+dSyMuodzLPVTyuXgyw6PEZK1muapU23hyTU+2e4fr5fRUDFEKIwSORIwZOLXTTbAiUot8l+cIf77COU17xuPe2DmMldXImW4ic/urkKPBYCCGGjUSOGDg1s0qenMw2oyx7qaxqcneenPz+WGlMTnltnGaRU+2e2RxTlEIuhBCDRyJHDByzajE5Tj4mpygqMhuIMTlJxePKcyl4fOqenFyPqsbxtp6cLlSOPDlCCDF8JHLEwLHoycEb+ymp92a8k8ipp5CnFY+rtXUI987vl2V/5eNwWlc87oaiyJEnRwghBo9Ejhg4NSv0riocb71c1eaiuYtUb+tQZLyk4nEr781U9q6SJ0cIIQaPRI4YOJnXpdsu5BNtRIRBb9lVhf1GTE5jrFVGVa8xOWWxRZ2yyIQQQvSPRI4YOEaIXykr5Bf2GyOpyCmLeSlt0En/gcctU8gnyseL57SjTAzJkyOEEINHIkcMnCy7KqMpfqZeKKezJ6esNUToQl614nGLwOM0hbxiW4eqvavKxNCYRI4QQgwciRwxcCyLyWkhCtKlm7RIXnngcXpOI7uqV09OWe+qrUm3znxMTv7cqstVEjlCCDEaJHLEwKnVYkxO3G/jyMk16Cxdrkqukcuu6nFuZb2r0ttumUwFT7FBZzWVU2am5SohhBg8Ejli4Bj5OjlNMTlp4LF1WK5KY3KyseJF2s2l2NahZLkq9d64N8RWU0xOwbPTijIxpBRyIYQYPBI5YuDUs6sahXJyx9PdWvKJLFsOKktDDzE51WjqgN4hhRwa4qbXFHIFHgshxGiQyBEDJxQDbKxXtcqucnfGE5XTrqJwWK7y3H61ueT3Gw06G2NFD9JEC5FTtUyOPDlCCDEaJHLEwKlZhy7k/S5XdRGTU7ZUVksEk7uXeHLCulSvnhwvWdaSJ0cIIQaPRI4YOJnXpRGTU1yuauyny1Vl2VXpNXubS+HeZCnu4V5lt5xoFZPTRwq5igEKIcTgkcgRA6cYk9OuC3mn5arM42K5YoBeuXdVETOjZlZPD99aEk2ciZvifPpJIR8fk8gRQohBI5EjBk7qKYH22VU5T07b5ap0iamL5aqSpbI0vqcsY6qVJ6d6McDmsTF5coQQYuBI5IiBY1lMTgtNkGvrkHz5lwmORmuIfCPPXntX1cwYqzVEWJmwapVdVdGRUyqGVAxQCCEGj0SOGDj1mJxkPyX7vncKvas6eXKyMaq3dWhKXyffdiLtVZWRjRWXstplf+Xsyjw5EjlCCDFwJHLEwMkyoerxNE2Bx2EbPDJWFz3te1c1VI47lderypbKgqepnScny67Kj6utgxBCTG8kcsTAyWJyvLHWVKC8CrF781JPq4rHvcfkWK6jeVngcaNOjhp0CiHETEIiRwycLCanvl9yPCXXibyFuyR3TlcxOc1epFriySmLA9raMoW82j3LtJBEjhBCDB6JHDFwmnpXlcTFpLQrCJju1bOruojJKUtfT7O/2nlyih6ZfurkKLtKCCEGj0SOGDi1GD9T1neqfpzG8bTlQZPm8MY1chWP+8iusiTwuK0nZ6JXkdM8ltYDEkIIMRj0m1YMnGJMTru2DpBveVDmycmChYtjVSi7d1pzpzTweKK8rUM/vavGVAxQCCEGjkSOGDhp9lK2Xzye0i6NPC38V6947F0sVxVjcgiBx5kHpxhcDO1icir2rtJylRBCjASJHDFwsuWgVpKgKDzSvk7FWjRZCwczqy9vdePJaZ5bPvC4mCYexlrF5FS7R5mdVquEEGLw6FetGDhhOah1nZxsN9MQ422yqzJPjhXGKlPa1qERk9Oud1XvMTl5u+Ne+EQWjI9VnLAQQohekcgRAyfUoWlX8bhRFwfgUYvm1W1axeSk9mGs6nJV871rtU69q1rF5FQUOck1n7BiCce9cI9K5wkhhOgPiRwxcLLloNa9q/Kc+ebV/NWLnwTAI5sneHjT1oK9QdLWAfcuigG2auvQOoU88+AUBVcvFY8ViiOEEMNjfNQTEHOA+nJQ0pIhfzjHTtstZsXS+QAc8g8X4Q5rPnEo0PDe5Bp0llyj5VSapma53lVlS1ATk87GLRM8sGFLbrx64HHj55pUjhBCDA15csTAyZppNgRKnrLMqOISVoaTpldRt+m1rUOt2LuqRZ2cP//qldyzflN+LhU0zs9vupfXnXFJcj+JHCGEGBYSOWLgdIrJKfveL7Y92JKpjyzw2Eiyq7x6TE4Pvau2TExy8e/ubhqv4sn51a0PsmHzRMv7CyGEGBwSOWLgFGNyWnUhz5+TH7zroeBFqRcDJHhSfn3rg/zuzvWV51LuNWrfu+q629cBsM2C/OpuFU9OsbaOEEKI4SGRIwaOEYrt1ds6NGWQlwiPgifnjgcfARqF/7JrfPDff8PmrZM9L1dB58DjS2+6D4Dz3/NsXrLXY+vjVTw5RZuqHichhBD9I5EjBk66tASdu5BDc0XgOx6MnpykT5UDG7dMtrxG9flZPRanTLjcG2Nxdly2MFfEr4qTplhbp2rauRBCiP6RyBEDJ8teqppCDjBW+GTennlyyIoBhjifRu2a3lVO2ruqKEoANm2djHOynNepiienrBeWEEKI4SCRIwbOwnk1Htq4tU2DziyTqiEIijE5dzy4MdoQ2zqE8Wx5qXqDzmbDsZpx4fV38c6vXVkqXDZtnYxZWJa7TxWvTFkvLCGEEMNBIkcMnL1WLuN3dz7EI1uyon7FXlVhm0qGYnbVw2mGEg37zJNTOSanbCwql5/ffF992eqpqx7Fwnnhn8emrROMx3WqXF+tCk6aspR0IYQQw0EiRwyc/R6/nIlJ51e3PghUSyEvBh5nHpF68DLBq5MtB1X35JTcK/MKTUzWPUOfff2+XH3SiwHYMuF10ZVOq9JylTw5QggxMiRyxMDZZ6dtAbjylvuBMm9K88h4k8gJW68H5YTjExMtmn62oF3hwYlJrwuXMbOcN2m8LnLkyRFCiJnCnBY5ZjbPzN5lZlea2QPx9Qsze4+ZzS+xf5KZnWdm95vZw2b2EzN7fotrLzOz08xsrZltNLNrzOydVhIUYmY1M3uvmV0fbf9gZieb2ZJBvO9hs92S+WyzcJw714W4mk5tHaB5uSr1iKRHsjo0U+LJmfR64PFYzXIZXplnKZ27YnKEEGJ6M6dFDnA2cDpwM3A8cAJwN/AZ4KupoZntBvwMOBj4JPDXwFLgB2b2woLtfOCHwDuAc4Fjgd8Cnwc+WDKPTwOnANdG228B7wa+Z2az4v/ReM3YMlEeP1OmT+YV0qsyMeMeqhtn50x0K3Lids/HbsM1H/7jeG6JJ6dm1GpWF0DjZctVFVw5TV3UlWwlhBBDY8426DSzlcARwHnu/ifJ+OnAfwOvMbN3uPv98dDHgeXA/u5+dbT9CnANcLqZ7emNP+2PAg4A3u3up8WxM83s28AHzOxL7n5LvMZeBGHzHXd/dTKPm4FTgdcDXx/AIxgq42O1lplQZX2qmj05WQuHWPE4Hs7aPVRerspEy5ixJFYwznlyJhsiB2C8VmPzxGQSk9PtcpVUjRBCjIpZ4SXokW3i9rZ0MAqV24FJYCNAXDY6HLgoEzjRdj1wFrAHQdRkHAFsAM4s3PMzwDzgdcnYGwgOhs8UbM+M1ziyy/c1LRmvWX0pqErgcXNMTubJadTJScerl8lpHZMDsCWpiZNu656cXDHAKstVEjlCCDEq5qwnB7gxvv7UzK4CLgDGgFcArwI+7u6PRNunAwuAS0quc2ncHgBcFpeX9gN+4e4bC7aXEZwRqSA6gCCoLksN3X2jmV1dsJ2xjNWs0WSzQJkXprUnJ9+Mc0u3KeQd+mRtjnPM4nEycTM21hyTU4Vi7ypHokcIIYbFnBU57r7VzA4Hvkze47IFONbd/zEZWxm3a0sulY2titttgUVltu6+yczuSWyza9/j7ptaXPsZZjbf3TcXD5rZ0cDRADvvvHPJ6dOH8Zo1goRbNOhMBcB4rTwmJ5zfOGdrtlxVtQt5fduwT0/dFNtEZKKmvrXeUsirxO0IIYQYDDNe5JjZcuC4Lk451d3viz8/AtwAXA78CFgMvAX4nJk97O5fiXaL47ZMiGws2LSzzewXJ/uLO9hmNk0ix93PAM4AWL169bT+Nh0fq/FIVtCvgh5p6ckprE51vVoVSYVNe09OLTefbmNy1IVcCCFGx4wXOYRg4LKMpVZ8DbjPzB5LEDdnufv7s4Nm9jXgpwSh870YeLwhHl5Qcr2FcbuhsC2zzew3JPsbgEe3sU2vOWMZr1ldQBQFSVng8byx9oHHRfpp65DqqU2FmJzxWl7s5EVO913IhRBCDI8ZH3js7mvc3bp4/T6eejSwPSFdO73eJPCvhMDk/eJwFpycLjNRGMuWp+4neIiabM1sAbCC/FLWbcCKeKzs2veULVXNNMZq1nJpqVqdnNSTY83ByxXnUWaX8+S0CDweq9fJaZxXRb8UA4+leYQQYnjMeJHTB5kIGSs5Nl7Y/pqwpHRwie1BcXsF1EXSL4B9S4TLgYTv2SuSscsJ/x8OTA3NbCGwT8F2xjI+VmtkVxWOlWdXFWNysqBljynkRaHUXQp5q3M3bQ1LavXlqrH8NufJqVInR8tVQggxMuayyLk2bt+aDprZPEIK+FbgKqinin8POMTM9k5slxJq4txAPjvqG4Q4mqML9zwuXvfcZOxcwipMMa7o7fEa53T3tqYn4zVjS4s6OV1lV3mLJpsV59Gu4jGE5SqzRoXjYixOPvC48/0kcoQQYnTMhpicXvkS8B7gnWb2OOAHBFFxJCFl/FPufldifzzwAuC/zOzTwDqCEFkFHJoUAoSQrfU24BQz2wW4DngZ8Ergo+6+JjN091/HAoTHmNl3gPOBJxMqHl/MLCgECFkKefvsqpSmOjmeiJxuo4zTe8V7p5coLlel7RzGC7E51mVMTnMKuRBCiGExZ0WOu68zs4OAk4BDgZcQ0sevIXhgzirY/97Mngl8Ang/MJ+wLPUSd7+gYLs5tnr4KKHY3/aEmjzHEtpIFDkOWBPveyhwD3AacFJc/prxjNesZQuGTM+kAmCsEHicLXU5jpXE5PQTlJOujG3aOpnrgD5WyK7Kx+Qo8FgIIaYzc1bkAERPzTHxVcX+OkKxwCq2D1S9trtPACfH16xkfKzdymiz8qFyOK8AABvFSURBVGhb8dhKlrgqaonSpa6CJye9d92TUxaTUyWFfEIiRwghRsVcjskRQyQVDr0EHk8UigEWqeoxKU8hzwcep8tVjeyqLIW8u3vKkyOEEKNDIkcMhVwgcYv071QPtIzJyc4pXKOqw6Q8hbzx8+atk7mlsnpbB8ts+ysGWGWJSwghxNQgkSOGQlrcrznwuMS7UhA59ZgcD/bFM6q2T6jfKvXW5Dw5k209OelcK8XkKLtKCCFGhkSOGApjyfJTq8DjdoE1aYPOdserkk6hGJOTep3qdXLqqeSN83rJrhJCCDE8JHLEUGgbk1MhNaouFrLA48IplWNySu6VW66ayIucenZVSeBxTxWPK81SCCHEVCCRI4ZCKhyqtHVImT9eq4uYrHdVUaxUDzxuHssFHm+ZzO0X6+SoGKAQQswcJHLEUMjF5HRZzG/BeK3e98rdS70xVcVEaeBx8q9g88RkfYkKkpgc660Y4ETBpo86hkIIIbpEIkcMhbEuU8hTFozXmrqQ95pdld08PT/Xu2rLRGnF42J7B6gWeCxPjhBCjA6JHDEUxtsGHoeBVpph/lgtF8BbpomqpmZ3H5NTLAbYsO1luUqSRwghhodEjhgKxYabKVVictKKx+Gc8orIneh0ry0TnpvrvLF8W4dat8tV8uQIIcTIkMgRQ2E814uqEHgc91vJgQXjY7ligGV1dfqJySmeWurJqdfJaX1eGRI5QggxOiRyxFDIpZAXKx5X8OS4h8J6IfC4Waz009ahuNSVq5NT8OD0HZMjzSOEEENDIkcMhVwxwMKxThlH88fDuVsnYynAssDjLper0tMnC33eUyHTPian++wqIYQQw0MiRwyFeW3r5GSBx+WCYH6Mi5mY9FAMsMSm21WhdqngZV3I6zE5tfS8zveZUBdyIYQYGRI5YiiM5XpX5emYQj4vihx3HC/vXVU5u6qZoliplVQ8zsROzgPUgydHkkcIIYaHRI4YCm1jcjqcW/fkTHho0Env2VVlVkUPUs6TU2jnkG/Q2fl+6l0lhBCjQyJHDIV8TE75clUrGjE5k7ELebNNPw06ix6Z8uyq3lLI1YVcCCFGh0SOGAr9tHXIRE4mZAzruUFnGU3LVWUVj3ssBihPjhBCjA6JHDEU2hUDzGhXJwcaMTnQvMTVTz2adoHH7Tw5nVLIy7w4VSszCyGE6B+JHDEUxttVPO5w7oJsuSqLySk5oR+HSVF31Eqzq5qLAXbSK/LiCCHEaJHIEUOhXe+qjJa9q5LlqrpJr4HHJWbtPTmxrUMc6iYmp58lNCGEEP0jkSOGwnguhbwYeNz+3Cy7autk5snpPYW87J6VPDlxDolW63jPMk+OZI8QQgwPiRwxFMbapJB3IluuCqIitnUoBh6PICan0y3Vt0oIIUaLRI4YCu3q5GS0rHhcISanavuEsns0NehMs6vG8hWPrYvAY4kcIYQYLRI5YiiMt6uT0yH0uBiTY9Z8zsRkyYltSM8vipVaW09Ow06eHCGEmN5I5IihMNamTk4mYp79xB1Kz02LAUJ/dXLKrLrqXdVF4HGZyFEsshBCDI/xUU9AzA1yy1WFY4vmj/HjvzqEHZctLD03q5Mz6d5yiajrTKY2Hpl84HHMrip4cswqeHKkaIQQYqRI5Iih0CnweNcVS1qem4vJIVuuyjOoYoBZTM54ISZnvGadY3LUgVwIIUaKlqvEUJg31vtHrd6gczJt0Jm36Se7qimF3JpjcrJ6OTtss4CawfZLFnRerio57koiF0KIoSGRI4ZCvq1Ddznk9YrHWTHAEldQP0tD7Rp0jhcCj/fbeVuuPOFF7LTdIiY7BDtPdDIQQggxUCRyxFCokkLeikzkTMSYHKM5u6qqI6fXisdpnM62S+ZjZhUCj6vNSQghxGCQyBFDIZ9CXo1MDNVTyGOMi1nzRbpdrkpPbx94nPfk1G2sSu8qqRwhhBglCjwWQyHX1qFLV8788UJbB5qF0sJ5Yz3PrRhAXFbxuNhFvWbGBOUiZvPWSR58ZEvpcpYSroQQYnhI5IihsHzxvPrPVSXOaW/Yl8//+MZCMUDHzNhx2SIA3nDgTuy2w1Keu0d5jZ0q7LbDUi5fcz8Lxmts2jqZE2F77rgNBz1hO5746KW5c2pmpUtkd63byBvP+jk33LWe5z0pzOnMN69mtx2W8PyTL+55jkIIIbpHIkcMhUdvs5AVS+dzz/rNlWNyXv70lbz86Sv5/V3rAdi4ZYI7121i+aJ5PHP37bnh71/addZWWXbThw7fi0OfviPjtRr/ePGNHPyE7XPz/pejD246Z8XS+fzw2jv5n3s3sPP2i7np7vWYGf900Y3cct8GHrftIn7827uB4InKhNqiPjxOQgghukMiRwyN/zzuOXznF7ey83aLuzovWz5637d+CcDej1uGmTFvrMsIZqiXPE6F1sJ5Y/Vqywfvtn3JSc389Uv25MLr7uKj//davvCm/XnJZ3/C5q1hfeotBz+e/XfZjnd/4yoAnrryUWy3ZD5/9eI9eMU+q7qfsxBCiJ6QyBFDY8XSBRz9nN26Pq8Yb/PLWx/sey6d+mV1YtXyRbztWbty6oU3sPqjF9QFziFP2oFjX/BE5sVA61ftt4rtly4A4JjnP7G/SQshhOgKiRwx7XnssoWcfsR+LF88jzee9fNRT6fOnz5zFy698V4uW3Mf88aMq056MUsXNP5J/fwDL2D7JfNHOEMhhJjbSOSIGcGhT9+x/nMaxDxKli+ezzffcTD3PbyZBzZszgkcgMc8qrwXlxBCiOEgkSNmFL886cXdFkweONstmc928tgIIcS0QyJHzCiW9enFUZkaIYSYO6jisZhTLFsURNIubbqeCyGEmB3IkyPmFE9dtYx/futqnrHbilFPRQghxICRyBFzjufv+ZhRT0EIIcQQ0HKVEEIIIWYlEjlCCCGEmJVI5AghhBBiViKRI4QQQohZiUSOEEIIIWYlEjlCCCGEmJVI5AghhBBiVjLrRI6Z/bmZnWNm15vZhJm1reRvZk8ys/PM7H4ze9jMfmJmz29hu8zMTjOztWa20cyuMbN3mllTNyUzq5nZe+M8NprZH8zsZDMrLbVrZi8zs5/FOdxnZt8ys117ewpCCCGEmHUiBzgeOBy4C7itnaGZ7Qb8DDgY+CTw18BS4Adm9sKC7Xzgh8A7gHOBY4HfAp8HPlhy+U8DpwDXRttvAe8GvmdmueduZq8Cvg8sinP4FPAc4KdmtrLi+xZCCCFEgrnPrpaFZrYL8D/uPmlm3wcOdffSvtVm9k3g1cD+7n51HFsKXANsBPb0+IDM7F3A6cC73f205BrfBg4Dnujut8SxvYBfA//m7q9ObI8FTgXe6O5fj2PzgDXAVmAvd18fx/cBrgS+6O5Hd3rfq1ev9iuuuKLSMxJCCCGmG2Z2pbuvnsprzjpPjruvcffJTnZx2ehw4KJM4MTz1wNnAXsABySnHAFsAM4sXOozwDzgdcnYGwCLx1LOjNc4Mhl7LrASOCsTOHEeVwMXAa+LQkgIIYQQXTDrRE4XPB1YAFxScuzSuD0AQnwNsB9wlbtvLNheBjh5QXQAMBmP1YnnXl1iS5t5PIoguIQQQgjRBXNZ5GSxLmtLjmVjq+J2W0K8TJOtu28C7klss2vfE4+VXXtFjPHpdh45zOxoM7vCzK64++67y0yEEEKIOcu07EJuZsuB47o45VR3v6/L2yyO2zIhsrFg0842s1+c7C/uYJvZbO5yHjnc/QzgDAAzu9vMbmlxz25ZQRBuonv07HpHz6539Ox6R8+ud6b62T1+Cq8FTFORAyynPGOpFV8DuhU5G+J2QcmxhQWbdraZ/YZkfwPw6Da2Va9dtG2Ju+/QyaYqZnbFVAd/zRX07HpHz6539Ox6R8+ud2bCs5uWy1UxeNi6eP2+h9tk6eVlS0HZWLZcdD/wSJmtmS0gqNl0uek2wpJUmXBZRVjK2tzDPIQQQghRkWkpcobErwlLRAeXHDsobq8AiNlavwD2LREuBxIyqdL87csJz/bA1NDMFgL7lNjSZh7rgN91eC9CCCGEKDBnRU5M1/4ecIiZ7Z2Nxzo5RwE3kM+O+gYhNqZYs+Y4Qo2bc5OxcwkZV8W4orfHa5yTjF0M3A4cFe+dzWNv4BDgW+6+pcu31y9nDPl+swk9u97Rs+sdPbve0bPrnWn/7GZjMcDDgEy0HAk8CTgx7j/g7p9LbHcnCJkthArF6whC5GmEIoI/SGznE6oj700o6Hcd8DLglcBH3T27R2Z/GnAM8G/A+cCTCRWPfwo8P63lY2avIQijXxJq6TwKeC9BKO3v7lquEkIIIbpkNoqcs4G3tDh8i7vvUrB/MvAJQlG++YRlqQ+5+wUl114OfBR4FbA9cCOhrcPpXniQZjZG8OQcDexCiEA/FzgpLfqX2L8cOIFQv2cTcCHwv939xgpvWwghhBAFZp3IEUIIIYSAORyTI4QQQojZjUSOwMxqZvZeM7vezDaa2R/M7OTY32tGYWbHm9m3zOwmM3MzW9PB/o/M7AIze8jM1pnZf8bmqGW2K83sK7Hw4iOx2vRrWtguMLOPmNnNZrbJzG40sxNa9SEzszeb2VXxunea2VlmVlr7qJs5V8XM9ojzvTS+v4fM7Goz+9uyz4GZPcnMzjOz+83sYTP7iZk9v8W1l5nZaWa2Nn6+rjGzd5pZU+Pcbj+LZvYyM/tZnMN98f/9ri1sK8+5G+J1zzGz68zsQTPbEOd/ipnt2M88Zvuza3Gvxcm/38+VHNfzy1/bW7zKwiLm3rNzd73m+Av4LCHI+TuEwOtTCMHYPwJqo55fl+/FgXuBHxIKRK5pY3sQoar0jYRA7/fGnx8Cnlaw3Q64CVgPfIQQa3VRvN/bSq59Xjz2RUK23hfj/tkltlmQ+UXxuh+J97kGWNLrnLt8bp+I1zgHOBZ4B40swV8CixLb3eIzvhM4HngXcFX8zLywcN35NIL7T4mfr+/E636on88iITZuMt77XXEudxJqT60s2Faecw/P7gVxfh+L1z0aOC3+P7wNeLSeXVfP8x/iZ9GBz/U6l7ny/OKc/5uQaJO+Xqdn5xI5c/0F7BU/cN8ujB8bP7RHjHqOXb6fJyQ//4b2IucyQkbdqmRsVRz7r4LtJ+PzOCwZG4vXuBdYmoy/LNqeXLjGyXH8GcnYCuDheJ2xZPywaPuBXufc5XNbDSwrGf9onMcxydg3gQlgn2RsKXAL8FtirF8cf1c8/9jCdb9NaGvy+F4+i8A8QpHMWwrPfp84tzMK16g85yn8LL4mzvtv9OwqP7P9CCU5/pJykaPn1/zMSv94KrGbk89uSv9R6zXzXjS+xJ5dGF9I+PI9f9Rz7OO9tRQ5wO7xfX+x5NgX4z/axyZjtwK/L7F9U7zOa5Oxr8WxnQq2O8XxzydjR8WxN5Vc+0bg2l7nPEXP8Gnxnv8U95cQPEkXltieGG0PTMb+X/wcLSzYPptmAVD5swi8MNqeWDKPC4EHgXm9zHkKn92B8dof17Or9LzGgCuB7xMyUnMiR8+v5XNz4GyC92VpC5s5++wUkyMOIHw5poUPcfeNwNXx+Gwke1+XlBy7lFDFen+AGFexKo6X2abXy35e6+5/SA3j/m0ltu3msac1ikRWnvMU8ri4vTNun07os9ZqDhDnaWY1wl/mV8XPU8plhF9SxWdR9bPY6Vk8Ctij2zn3g5ktNLMVZvY4M3sx8IV46Pxu5zHXnl3kvcCehPpiZej5teZPCD0OHzKzu2IszbLk+Jx9dhI5YiWhl1ZZF/S1hB5c84c8p2GwMm7LCi1mY6t6sM3sWxVwXFti2+7alth0O4++sFDr6UTC8sHXe5jDtsCiMtv4ebuH5mdR9bM4yP9/vXIUcDfwB+AHhEbDR7r7T3qYx5x6djHo9MPAR9x9TQszPb9yLgM+RBA6byHEwRwD/CT5A2nOPrvp2oVcDI/FhOKDZWxMbDa3sJmpLI7bsve+sWDTjW32c7tnWrQd1Dz65TOEnmofcPff9jCHdraZfTfPLbPZPIXzmMrndh5wPSFmYF/gcELMVYaeXWv+iRDYf0obGz2/Etz9jwpDXzGzXwF/D7wnbufss5MnR2wguATLWJjYzDay91T23ovvuxvb7Od2z7RoO6h59IyZ/R3hr8Ez3P3jyaGpmm9m381zq3rtkTw3d7/V3S9w9/Pc/YOEv6o/aWbHT/GcM/tZ8ezM7EjgRcA7vX2fPj2/6nyKICoO7WEes+rZSeSI2wjuxLIP0iqCG3K2eXEgvG8od3dmY2t7sM3sW7lRV5XYtru2JzbdzqMnzOxDhBYjXyKkkqd0M4f7gUfKbOPnbQXNz6LqZ3GQ//+mBHf/FY002W7nMSeeXZzvKYS4pTvMbHcLPQUfH02WxbHlXc5lTjy/VkSxeBsNT+KcfXYSOeJywufgwHTQzBYS0vquGMWkhsDlcXtwybGDCOLiSgB3v53wj+mgFraQf06XA6vMbKfUMO6vLLFtN4/feqPXWeU590oUOB8Evgwc5TGVIeHXBPdxqzlAfH8emtD+Ati35BfggYR4o+KzqPpZ7PQs1gG/63bOA2ARocZSV/OYQ89uEbADweNwQ/K6KB4/Mu4f1c1c5tDzKyXO+3E0Egbm7rPrJ3VNr5n/IqQIt6txcOSo59jHe+tUJ+fy+I9qZTK2Mo5dULD9FK3r5NwPbJOMH0r7OjnPSsZ2ILhcf055nZwTep1zD8/rpHjPr9CmCCTwLULtir2Tsax2xe/I19v4C1rX29gC7NLLZ5FQb+M2mutt7B3ndlavc+7huZWm7QPPi/e8sJd5zJFnN48QMFt8vTPO+z/i/h56fqXPb/sW49nvq7/pZR6z6dn1/AtRr9nzIlRndUK1yqMIX8ZbCH9NzbSKx28iLLWcQPgr5v5k/00F22cQ/lK4kdAx/rj48/r0H1W03R5YQ6jE+mFCVdsfx+f2ZyXz+F48dhbwZ3HrwFdLbN8Xj/04XvfDcQ7XUah70c2cu3xu2S+1W4A301w99UWJ7e6EatJ3Au+nUYV0K/DHhevOJ/y1tSV+ro6iUTn17/r5LBKK7aWVU98f53QHSbHEbufcw7P7N0JK68eAPycEe36FEBPxAPlCZnp21Z7pLpQXA9Tzy1/704QU648Rlpb/ipBd5fEzuWiuP7sp/3DqNfNeBI/E+wgVJDcRlmZOoUVhqen8otFqoex1UYn9wYQiVOsJAuYHwH4trr0K+CohhXIjwaX7uha2CwlFstbEZ3oTIR17Xgv7txLaJ2wE7gL+maQdQK9z7uK5nd3muTU9O+DJwHcJX+IbCMXDSsusE1KpP0f4C24TcC0hqLnpr7BuP4vAywm/zDcQBO2/Aru1sK085y6f3WsJBez+EP//PULIsjoN2Lmfecz2Z9fmme5CicjR82u67isI//7Xxs/ew4TaNB+gUMhvrj47ixcRQgghhJhVKPBYCCGEELMSiRwhhBBCzEokcoQQQggxK5HIEUIIIcSsRCJHCCGEELMSiRwhhBBCzEokcoQQQggxK5HIEUIIIcSsZHzUExBCiG4ws3FCq4nXE3rebE+o9HoHobL0T4AfuftlyTn7AP+L0Mvs7GHPWQgxGlTxWAgxYzCzHYDzgdXJ8EZCKflHETokAzzo7suT894KfAm42N0PGcpkhRAjR8tVQoiZxNcIAuch4G+AHd19URQ0y4AXAZ8n9LkRQsxxtFwlhJgRmNmewIvj7p+6+7+mx939IeAC4AIze9+w5yeEmH7IkyOEmCk8Lfn5++0M3X1j9rOZOWGpCuC5ZuaF1yHF883sWWb2L2Z2q5ltMrN7zewCM3uDmVmJ/SHxWmvi/mFm9mMzu9/M1pvZJWZ2RKv5mtk2ZnaimV1pZg+Z2WYzu83MrjCzT5nZU9s+GSFEKfLkCCFmIquAGyva3gksIsTsbAHuKxzfnO6Y2f8hLIVlrAO2BV4QX4eb2RvdfbLsZmZ2HPBpwIEH470PAg4ys2e4+zEF+2XAz4CnxKHJeN5jgB2B/YEJ4P0V368QIiJPjhBipnBl8vPpMQi5I+7+WOA9cfdn7v7Ywutnma2ZvYcgcO4EjgaWu/syYAkhm+uOuP3fLW63A/BJ4CuEeKFtgRXAyfH4X5R4dN5DEDh3Ay8HFrj7dsBCYA+CuKkq6IQQCcquEkLMGMzsy8Cb4+5mQrr4pcDlBAFzd4vz3kqH7CozWw78geDhPsjdf1liczDwU0Jg82PdfXMcPwT4cTT7IfDHXvjlamZnA28Bfg/skR03s/OBlwLvd/f/0+kZCCGqI0+OEGIm8XbgFILAmU9YPvpb4DzgLjO7zMzeWBY3U4FXA0uBC8oEDoC7XwLcTFi+2r/FdT5eFDiRv4/b3Qn1fTLWxe2OXc9YCNEWiRwhxIzB3Te7+/uAnYB3AN8AbiDEvwAcQEgzP9fMuv399oy4fb6Z3dHqFe9Nsk3ZQvD0lM39BuD2uLtfcuj8uH23mX3VzF5qZtt0OXchRAkSOUKIGYe73+XuX3D3I9x9D4IX5O2E5SaA1wDHdnnZzJOymBD02+o1L7Erck+2hNWCtXFbjydy968AZxAKGR5JED0PmNlVZvYRM5OHR4gekcgRQsx43P1Odz+L4CG5Mw7/aZeXyX4fftbdrcLr7Cmc/58DTwU+AlxEqOC8D3AicIOZvWiq7iXEXEIiRwgxa3D3e4Dvxt09ujw9E0c79zGFFWY2v83xlXHbFCDt7te4+wfd/XnAcuAw4NeEzK4vm9m84jlCiPZI5AghZhsPx226bJTVtGkXkHxJ3B5iZot6vPc84OCyA2a2Ow2R84t2F4mxR98nLLtBWEp7Yo9zEmLOIpEjhJgRmNmuZrZbB5vFhG7jAFcnh7IMpuW05lsEgbQtcFKH+2zb5vDxLbK7jo/bG9y9PrcOnp9Hkp8XtJuTEKIZiRwhxExhL+C3ZvYdM3ttGpBrZkvM7DBC3Zxd4/Bnk3OvidunmNkflV3c3e+lIUTeb2Znmll9ycvMFpnZs83sHwkVisvYQEhr/6KZPTqetzxWUc5ihD5UOOcCMzvVzJ6TepDMbC/g7Lh7O2HpSgjRBSoGKISYEZjZHwP/WRh+hLAstSwZmwBOcvePFc6/GHhO3L2P0Mkc4PXufmlidwIhADjzxjyc3CP7w3CNu++anHMIoRjgLcBnaLR1eKBw3uklbR2uplE3J2vpsIhQ8RiCcDrc3S8sPhMhRHskcoQQM4boWTkMeBYhG2kVoSjgQ8BNwH8DZ7n7NSXnbk8QLy9NzgN4nrtfVLB9GnAM8DzgccAYIVj4N8CFwDfc/dbE/hCiyHH3XaJX6S+BfQlxOr8CPufu55TMazXwMuAQghfqsfHQGkJX9VPc/eZqT0gIkSKRI4QQfVIUOaOdjRAiQzE5QgghhJiVSOQIIYQQYlYikSOEEEKIWYlEjhBCCCFmJQo8FkIIIcSsRJ4cIYQQQsxKJHKEEEIIMSuRyBFCCCHErEQiRwghhBCzEokcIYQQQsxK/j/npytjnMJsHwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"a_DIEOFYEDsb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600138096773,"user_tz":-540,"elapsed":67596683,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["#trainer.visualize()"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"99-3qSCvJQgJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600138096774,"user_tz":-540,"elapsed":67596673,"user":{"displayName":"山田悠貴","photoUrl":"https://lh4.googleusercontent.com/-qjO3eS8zVqE/AAAAAAAAAAI/AAAAAAAAAYE/46U-7XBkpHM/s64/photo.jpg","userId":"04773754472221904960"}}},"source":["del env\n","del env_test\n","del algo\n","del trainer"],"execution_count":24,"outputs":[]}]}